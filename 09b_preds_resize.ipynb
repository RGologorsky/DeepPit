{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unable-instruction",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "Resize preds from Iso(2) back to full size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a54b2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Valid/Test: 0.60 (n=201), 0.20 (n=67), 0.20 (n=67)\n"
     ]
    }
   ],
   "source": [
    "# DATALOADER PARAMS\n",
    "bs          = 4\n",
    "nepochs     = 30\n",
    "num_workers = 4\n",
    "\n",
    "# PREPROCESS (Isotropic, PadResize)\n",
    "# iso       = 3\n",
    "# maxs      = [87, 90, 90]\n",
    "\n",
    "iso       = 2\n",
    "maxs      = [130, 134, 134] # on all, 131, 134, 134\n",
    "\n",
    "# Train:Valid:Test = 60:20:20\n",
    "train_pct, valid_pct = .60, .20\n",
    "\n",
    "#train_pct, valid_pct = 100/335.0, 20/335.0\n",
    "\n",
    "test_pct = 1.0 - train_pct - valid_pct\n",
    "\n",
    "def pct2int(pct, tot=335): return int(pct * tot)\n",
    "print(f\"Train/Valid/Test: {train_pct:0.2f} (n={pct2int(train_pct)}), {valid_pct:0.2f} (n={pct2int(valid_pct)}), {test_pct:0.2f} (n={pct2int(test_pct)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96384183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#GPU = 2, #CPU = 40\n"
     ]
    }
   ],
   "source": [
    "# CHECK HARDWARE \n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "gpu_count = torch.cuda.device_count()\n",
    "cpu_count = os.cpu_count()\n",
    "print(\"#GPU = {0:d}, #CPU = {1:d}\".format(gpu_count, cpu_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593734a2",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af85702f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders in data src: ICMB, ABVIB (1).zip, central.xnat.org, ADNI, PPMI, Oasis_long, samir_labels, ACRIN-FMISO-Brain, LGG-1p19qDeletion, REMBRANDT, AIBL, CPTAC-GBM, TCGA-GBM, TCGA-LGG, ABVIB, ABIDE, AIBL.zip\n",
      "Folders in label src (data w labels): 50155-50212, 50313-50372, 50213-50312, 50373-50453, 50002-50153\n",
      "Folders in ABIDE src (data wo labels) PAD, ABIDE_1, ABIDE\n"
     ]
    }
   ],
   "source": [
    "# Paths to (1) code (2) data (3) saved models\n",
    "code_src    = \"/gpfs/home/gologr01\"\n",
    "data_src    = \"/gpfs/data/oermannlab/private_data/DeepPit/PitMRdata\"\n",
    "model_src   = \"/gpfs/data/oermannlab/private_data/DeepPit/saved_models\"\n",
    "\n",
    "# UMich \n",
    "# code src: \"/home/labcomputer/Desktop/Rachel\"\n",
    "# data src: \"../../../../..//media/labcomputer/e33f6fe0-5ede-4be4-b1f2-5168b7903c7a/home/rachel/\"\n",
    "\n",
    "deepPit_src = f\"{code_src}/DeepPit\"\n",
    "obelisk_src = f\"{code_src}/OBELISK\"\n",
    "label_src   = f\"{data_src}/samir_labels\"\n",
    "ABIDE_src   = f\"{data_src}/ABIDE\"\n",
    "\n",
    "# print\n",
    "print(\"Folders in data src: \", end=\"\"); print(*os.listdir(data_src), sep=\", \")\n",
    "print(\"Folders in label src (data w labels): \", end=\"\"); print(*os.listdir(label_src), sep=\", \")\n",
    "print(\"Folders in ABIDE src (data wo labels) \", end=\"\"); print(*os.listdir(ABIDE_src), sep=\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02841785",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rough-climate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from transforms import AddChannel, Iso, PadSz, MattAffineTfm, PiecewiseHistScaling\n",
    "from helpers.metrics import dice_score, dice_loss, dice_ce_loss, log_cosh_dice_loss\n",
    "\n",
    "# Utilities\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Input IO\n",
    "import SimpleITK as sitk\n",
    "import meshio\n",
    "\n",
    "# Numpy and Pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as DF\n",
    "\n",
    "# Fastai + distributed training\n",
    "from fastai import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.basics import *\n",
    "from fastai.distributed import *\n",
    "\n",
    "# PyTorch\n",
    "from torchvision.models.video import r3d_18\n",
    "from fastai.callback.all import SaveModelCallback\n",
    "from torch import nn\n",
    "\n",
    "# Obelisk\n",
    "sys.path.append(deepPit_src)\n",
    "sys.path.append(obelisk_src)\n",
    "\n",
    "# OBELISK\n",
    "from utils import *\n",
    "from models import obelisk_visceral, obeliskhybrid_visceral\n",
    "\n",
    "# 3D extension to FastAI\n",
    "# from faimed3d.all import *\n",
    "\n",
    "# Helper functions\n",
    "from helpers.preprocess import get_data_dict_n4, paths2objs, folder2objs, seg2mask, mask2bbox, print_bbox, get_bbox_size, print_bbox_size\n",
    "from helpers.general import sitk2np, np2sitk, print_sitk_info, round_tuple, lrange, lmap, get_roi_range, numbers2groups\n",
    "from helpers.viz import viz_axis, viz_bbox\n",
    "#from helpers.nyul_udupa import piecewise_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0ec723",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "672509cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iso_2mm_pad_130_134_134_bs_4_test_sz_67_epochs_30_time_Mon Jun 28 16:10:23 2021.pth\n",
      "iso_2mm_pad_130_134_134_bs_4_test_sz_67_epochs_30_time_Mon Jun 28 18:00:05 2021.pth\n",
      "iso_3mm_pad_87_90_90_bs_20_test_sz_67_epochs_30_time_Mon Jun 28 10:34:06 2021.pth\n",
      "iso_3mm_pad_87_90_90_bs_20_test_sz_67_epochs_30_time_Thu Jun 24 14:21:03 2021.pth\n",
      "iso_2mm_pad_130_134_134_bs_4_test_sz_67_epochs_30_time_Mon Jun 28 15:31:38 2021.pth\n",
      "iso_2mm_pad_130_134_134_bs_5_test_sz_67_epochs_30_time_Mon Jun 28 11:58:20 2021.pth\n",
      "iso_2mm_pad_130_134_134_bs_4_test_sz_67_epochs_30_time_Mon Jun 28 12:16:16 2021.pth\n",
      "type_unet_iso_3mm_pad_87_90_90_bs_2_test_sz_67_epochs_30_time_Sun Jul  4 16:21:20 2021.pth\n",
      "type_unet_iso_4mm_pad_65_67_67_bs_2_test_sz_67_epochs_30_time_Sun Jul  4 16:44:34 2021.pth\n",
      "iso_2mm_pad_130_134_134_bs_4_test_sz_67_epochs_30_time_Mon Jun 28 17:33:56 2021.pth\n",
      "iso_2mm_pad_130_134_134_bs_2_test_sz_67_epochs_30_time_Sun Jul  4 15:53:56 2021.pth\n"
     ]
    }
   ],
   "source": [
    "model_fns = os.listdir(model_src)\n",
    "print(*[model_fn for model_fn in model_fns if model_fn.endswith(\".pth\")], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12fbebae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iso: 2. PadResize to: [130, 134, 134]. bs = 4. nepochs = 30.\n",
      "Num test items: 67\n",
      "Num items: 335\n"
     ]
    }
   ],
   "source": [
    "model_fn = \"iso_2mm_pad_130_134_134_bs_4_test_sz_67_epochs_30_time_Mon Jun 28 18:00:05 2021.pth\"\n",
    "test_fn  = model_fn[:-4] + \"_test_items.pkl\"\n",
    "\n",
    "# get parameters\n",
    "\n",
    "def get_param(fn, prefix, suffix):\n",
    "    start = fn.index(prefix)\n",
    "    end   = fn.index(suffix)\n",
    "    ints = fn[start+len(prefix):end].split(\"_\")\n",
    "    if len(ints) == 1: return int(ints[0])\n",
    "    return [int(x) for x in ints]\n",
    "\n",
    "iso_sz  = get_param(model_fn, \"iso_\", \"mm\")\n",
    "maxs    = get_param(model_fn, \"pad_\", \"_bs\")\n",
    "bs      = get_param(model_fn, \"bs_\", \"_test\")\n",
    "nepochs = get_param(model_fn, \"epochs_\", \"_time\")\n",
    "\n",
    "# get test items\n",
    "with open(f\"{model_src}/{test_fn}\", \"rb\") as input_file:\n",
    "    test_items = pickle.load(input_file)\n",
    "    \n",
    "# get all items\n",
    "data = {}\n",
    "folders = os.listdir(label_src)\n",
    "for folder in folders: data.update(get_data_dict_n4(f\"{label_src}/{folder}\"))\n",
    "items = list(data.values())\n",
    "\n",
    "# print\n",
    "print(f\"Iso: {iso_sz}. PadResize to: {maxs}. bs = {bs}. nepochs = {nepochs}.\")\n",
    "print(f\"Num test items: {len(test_items)}\")\n",
    "print(f\"Num items: {len(items)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0946ae6",
   "metadata": {},
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "81e0824b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.68 s for 335 items\n",
      "Get One Batch: elapsed time: 1.93 s for 335 items\n",
      "<class 'tuple'> torch.Size([4, 1, 130, 134, 134]) torch.Size([4, 1, 130, 134, 134])\n",
      "bs = 4, n_train = 335, n_valid = 0, n = 335\n"
     ]
    }
   ],
   "source": [
    "# time it\n",
    "start = time.time()\n",
    "\n",
    "# load standard scale\n",
    "save_loc = f\"{deepPit_src}/saved_metadata/\"\n",
    "percs          = torch.load(f\"{save_loc}/nyul_udupa_percs_335.pt\")\n",
    "standard_scale = torch.load(f\"{save_loc}/nyul_udupa_standard_scale_335.pt\")\n",
    "\n",
    "# tfms\n",
    "item_tfms  = [Iso(2), PadSz(maxs), PiecewiseHistScaling(landmark_percs=percs, standard_scale=standard_scale)]\n",
    "batch_tfms = [AddChannel()]\n",
    "\n",
    "# tls\n",
    "tls = TfmdLists(items, item_tfms)\n",
    "\n",
    "# dls\n",
    "dls = tls.dataloaders(bs=bs, after_batch=batch_tfms, num_workers=num_workers, drop_last=False)\n",
    "\n",
    "# GPU\n",
    "dls = dls.cuda()\n",
    "\n",
    "# end timer\n",
    "elapsed = time.time() - start\n",
    "print(f\"Elapsed time: {elapsed:.2f} s for {len(items)} items\")\n",
    "\n",
    "# test get one batch\n",
    "\n",
    "start = time.time()\n",
    "b = dls.one_batch()\n",
    "elapsed = time.time() - start\n",
    "print(f\"Get One Batch: elapsed time: {elapsed:.2f} s for {len(items)} items\")\n",
    "\n",
    "print(type(b), b[0].shape, b[1].shape)\n",
    "print(f\"bs = {bs}, n_train = {len(dls.train_ds)}, n_valid = {len(dls.valid_ds)}, n = {len(items)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e9d75e",
   "metadata": {},
   "source": [
    "# Metric\n",
    "\n",
    "Linear combination of Dice and Cross Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97e0a9b",
   "metadata": {},
   "source": [
    "# Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ac85b0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7dddef63f1d0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "full_res = maxs\n",
    "\n",
    "learn = Learner(dls=dls, \\\n",
    "                model=obeliskhybrid_visceral(num_labels=2, full_res=full_res), \\\n",
    "                loss_func= log_cosh_dice_loss, #loss, \\\n",
    "                metrics = dice_score)\n",
    "\n",
    "# load model fname w/o .pth extension\n",
    "learn.load(f\"{model_src}/{model_fn[:-4]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "96ba959b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/data/oermannlab/private_data/DeepPit/saved_dset_metadata/preds_iso_2mm_pad_130_134_134_bs_4_test_sz_67_epochs_30_time_Mon Jun 28 18:00:05 2021\n"
     ]
    }
   ],
   "source": [
    "save_loc = \"/gpfs/data/oermannlab/private_data/DeepPit/saved_dset_metadata\"\n",
    "save_preds_loc = f\"{save_loc}/preds_{model_fn[:-4]}\"\n",
    "print(save_preds_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a790221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# xb,yb = dls.one_batch()\n",
    "# res = learn.model(xb.cpu())\n",
    "# elapsed = time.time() - start\n",
    "# print(f\"Elapsed time: {elapsed:.2f} s for {len(items)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfb24a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_pred =  torch.argmax(res, dim=1)\n",
    "# print(res.shape, res_pred.shape, res_pred[0].shape)\n",
    "# print(mask2bbox(np.asarray(yb[0].squeeze().cpu())))\n",
    "# print(mask2bbox(np.asarray(res_pred[0].cpu())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cad67d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 60.54 s for 84 items.\n"
     ]
    }
   ],
   "source": [
    "learn.model = learn.model.cuda()\n",
    "\n",
    "pred_batches = []\n",
    "\n",
    "# start timer\n",
    "start = time.time()\n",
    "        \n",
    "        \n",
    "learn.model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in dls.train:\n",
    "        # get predict`ion for batch\n",
    "        pred_cuda = learn.model(batch[0])\n",
    "        pred_batches.append(pred_cuda.cpu())\n",
    "        \n",
    "        # clear cuda memory\n",
    "        del pred_cuda\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "# print time elapsed\n",
    "elapsed = time.time() - start\n",
    "print(f\"Elapsed: {elapsed:0.2f} s for {len(dls.train)} items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "19f0768a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([335, 2, 130, 134, 134]) torch.Size([335, 130, 134, 134])\n"
     ]
    }
   ],
   "source": [
    "# start timer\n",
    "start = time.time()\n",
    "\n",
    "pred_batches_cat = torch.cat(pred_batches)\n",
    "res_pred =  torch.argmax(pred_batches_cat, dim=1)\n",
    "print(pred_batches_cat.shape, res_pred.shape)\n",
    "\n",
    "# print time elapsed\n",
    "elapsed = time.time() - start\n",
    "print(f\"Elapsed: {elapsed:0.2f} s for {len(dls.train)} items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "de1cc0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(res_pred, f\"{save_preds_loc}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c6f8b7",
   "metadata": {},
   "source": [
    "# Resize Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "540052ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/data/oermannlab/private_data/DeepPit/saved_dset_metadata/preds_iso_2mm_pad_130_134_134_bs_4_test_sz_67_epochs_30_time_Mon Jun 28 18:00:05 2021\n"
     ]
    }
   ],
   "source": [
    "save_loc = \"/gpfs/data/oermannlab/private_data/DeepPit/saved_dset_metadata\"\n",
    "save_preds_loc = f\"{save_loc}/preds_{model_fn[:-4]}\"\n",
    "print(save_preds_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7601e5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([335, 130, 134, 134])\n"
     ]
    }
   ],
   "source": [
    "preds = torch.load(f\"{save_preds_loc}.pt\")\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a350ca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad to new size\n",
    "class ReverseTfm(ItemTransform):\n",
    "    def __init__(self, iso_sp, const_sz):\n",
    "        self.iso_sp   = iso_sz\n",
    "        self.const_sz = const_sz\n",
    "    \n",
    "    def encodes(self, item):\n",
    "        \n",
    "        # decode item\n",
    "        pred, im_path = item\n",
    "        \n",
    "        # Get shape post-Iso\n",
    "        mr = sitk.ReadImage(im_path, sitk.sitkFloat32)\n",
    "\n",
    "        # iso resize\n",
    "        orig_sp = mr.GetSpacing()\n",
    "        orig_sz = mr.GetSize()\n",
    "        iso_sz = [int(round(osz*ospc/self.iso_sp)) for osz,ospc in zip(orig_sz, orig_sp)]\n",
    "        \n",
    "        # Pads used to go from iso_sz => const_sz\n",
    "        pad = [x-y for x,y in zip(self.const_sz, iso_sz)]\n",
    "        pad = [a for amt in pad for a in (amt//2, amt-amt//2)]\n",
    "        pad.reverse()\n",
    "        \n",
    "        # Undo pad: const_sz => iso_sz\n",
    "        shape0, shape1, shape2 = pred.shape\n",
    "        a,b,c,d,e,f            = pad\n",
    "        pred_no_pad = pred[e:shape0-f, c:shape1-d, a:shape2-b]\n",
    "\n",
    "        # Undo iso (add batch dim for interpolate)\n",
    "        while pred_no_pad.ndim < 5: \n",
    "            pred_no_pad = pred_no_pad.unsqueeze(0)\n",
    "            \n",
    "        return F.interpolate(pred_no_pad.float(), size = orig_sz, mode = 'nearest').squeeze().long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ef31f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RTfm = ReverseTfm(iso_sp = 2, const_sz = [130, 134, 134])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca921fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/gpfs/data/oermannlab/private_data/DeepPit/PitMRdata/samir_labels/50155-50212/50201/MP-RAGE/2000-01-01_00_00_00.0/S164577')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(items[0][0]).parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9ffb978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 125.26 s for 335 items.\n"
     ]
    }
   ],
   "source": [
    "# save each orig size pred\n",
    "\n",
    "# start timer\n",
    "start = time.time()\n",
    "\n",
    "for i, item in enumerate(items):\n",
    "    nii,seg = item\n",
    "    loc = Path(seg).parent\n",
    "    torch.save(RTfm((preds[i], nii)), f\"{loc}/pred1_{model_fn[:-4]}.pt\")\n",
    "\n",
    "# print time elapsed\n",
    "elapsed = time.time() - start\n",
    "print(f\"Elapsed: {elapsed:0.2f} s for {len(items)} items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f765b0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(res_pred, f\"{save_preds_loc}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39afb842",
   "metadata": {},
   "source": [
    "# Get sizes of masked input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0265fcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_item(x):\n",
    "    im_path, segm_path = x    \n",
    "    mr = sitk.ReadImage(im_path, sitk.sitkFloat32)\n",
    "    im = torch.transpose(torch.tensor(sitk.GetArrayFromImage(mr)), 0, 2)\n",
    "    # im = torch.swapaxes(torch.tensor(sitk.GetArrayFromImage(mr)), 0, 2)\n",
    "    mk = torch.load(f\"{str(Path(segm_path).parent)}/seg.pt\").float()\n",
    "    return im,mk\n",
    "\n",
    "# path should be Path(segg).parent\n",
    "# missing [:-4]\n",
    "item = items[101]\n",
    "mr, seg = load_item(item)\n",
    "pred1 = torch.load(f\"{Path(item[0]).parent}/pred1_{model_fn}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25919768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 146, 128, 158, 21, 38)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-32a896296f4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask2bbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask2bbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/DeepPit/helpers/preprocess.py\u001b[0m in \u001b[0;36mmask2bbox\u001b[0;34m(mask)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mimin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m     \u001b[0mjmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mkmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "print(mask2bbox(np.asarray(seg)))\n",
    "print(mask2bbox(np.asarray(pred1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e10d18d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox_size(imin, imax, jmin, jmax, kmin, kmax):\n",
    "    return imax - imin, jmax-jmin, kmax-kmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87055bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_szs = [get_bbox_size(*mask2bbox(np.asarray(torch.load(f\"{Path(items[i][0]).parent}/pred1_{model_fn}.pt\")))) for i in range(len(items[:100]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34cc4ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({38}, {32}, {24})\n",
      "({32}, {30}, {24})\n",
      "({31}, {30}, {24})\n",
      "({31}, {32}, {24})\n",
      "({40}, {30}, {26})\n",
      "({36}, {32}, {26})\n",
      "({33}, {34}, {30})\n",
      "({36}, {30}, {22})\n",
      "({40}, {34}, {24})\n",
      "({34}, {28}, {22})\n",
      "({38}, {92}, {70})\n",
      "({40}, {32}, {22})\n",
      "({36}, {32}, {24})\n",
      "({36}, {32}, {22})\n",
      "({38}, {32}, {24})\n",
      "({46}, {92}, {56})\n",
      "({38}, {36}, {26})\n",
      "({29}, {32}, {22})\n",
      "({34}, {30}, {26})\n",
      "({33}, {34}, {22})\n",
      "({36}, {30}, {22})\n",
      "({36}, {32}, {28})\n",
      "({92}, {52}, {26})\n",
      "({36}, {30}, {24})\n",
      "({40}, {32}, {26})\n",
      "({38}, {38}, {28})\n",
      "({40}, {32}, {30})\n",
      "({33}, {30}, {22})\n",
      "({34}, {28}, {24})\n",
      "({38}, {30}, {24})\n",
      "({36}, {32}, {26})\n",
      "({38}, {34}, {22})\n",
      "({36}, {36}, {26})\n",
      "({33}, {32}, {28})\n",
      "({37}, {36}, {26})\n",
      "({31}, {30}, {26})\n",
      "({35}, {30}, {24})\n",
      "({34}, {34}, {24})\n",
      "({38}, {32}, {24})\n",
      "({40}, {36}, {30})\n",
      "({38}, {30}, {24})\n",
      "({34}, {34}, {24})\n",
      "({38}, {36}, {28})\n",
      "({35}, {34}, {24})\n",
      "({30}, {30}, {24})\n",
      "({38}, {30}, {24})\n",
      "({32}, {30}, {26})\n",
      "({38}, {32}, {24})\n",
      "({41}, {35}, {20})\n",
      "({39}, {34}, {18})\n",
      "({37}, {32}, {20})\n",
      "({37}, {33}, {17})\n",
      "({39}, {33}, {17})\n",
      "({37}, {31}, {17})\n",
      "({33}, {30}, {21})\n",
      "({35}, {30}, {20})\n",
      "({34}, {34}, {19})\n",
      "({35}, {32}, {19})\n",
      "({35}, {32}, {16})\n",
      "({37}, {31}, {22})\n",
      "({41}, {33}, {22})\n",
      "({31}, {33}, {20})\n",
      "({33}, {31}, {22})\n",
      "({37}, {30}, {19})\n",
      "({37}, {31}, {18})\n",
      "({37}, {32}, {20})\n",
      "({34}, {30}, {15})\n",
      "({39}, {33}, {24})\n",
      "({35}, {29}, {18})\n",
      "({38}, {32}, {19})\n",
      "({37}, {30}, {22})\n",
      "({31}, {29}, {20})\n",
      "({37}, {31}, {20})\n",
      "({39}, {32}, {24})\n",
      "({40}, {30}, {22})\n",
      "({36}, {30}, {17})\n",
      "({37}, {31}, {20})\n",
      "({31}, {30}, {19})\n",
      "({33}, {34}, {20})\n",
      "({35}, {27}, {20})\n",
      "({36}, {34}, {20})\n",
      "({35}, {29}, {21})\n",
      "({37}, {33}, {19})\n",
      "({35}, {28}, {16})\n",
      "({35}, {32}, {22})\n",
      "({39}, {33}, {21})\n",
      "({35}, {31}, {22})\n",
      "({37}, {32}, {20})\n",
      "({43}, {97}, {49})\n",
      "({33}, {32}, {19})\n",
      "({41}, {32}, {22})\n",
      "({35}, {33}, {19})\n",
      "({37}, {37}, {22})\n",
      "({34}, {32}, {19})\n",
      "({35}, {31}, {19})\n",
      "({35}, {33}, {16})\n",
      "({33}, {33}, {24})\n",
      "({35}, {32}, {17})\n",
      "({37}, {33}, {22})\n",
      "({31}, {29}, {17})\n"
     ]
    }
   ],
   "source": [
    "print(*pred_szs, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36fb7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predictions[0]\n",
    "pred_mk   = torch.argmax(pred, dim=0)\n",
    "nii = test_items[0][0]\n",
    "\n",
    "print(pred_mk.shape, nii, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da580ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "RTfm = ReverseTfm(iso_sp = 2, const_sz = [130, 134, 134])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89683427",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_pred = RTfm((pred_mk, nii))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3709e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.load(f\"{save_preds_loc}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1727cb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/data/oermannlab/private_data/DeepPit/saved_dset_metadata/preds_iso_2mm_pad_130_134_134_bs_4_test_sz_67_epochs_30_time_Mon Jun 28 18:00:05 2021\n"
     ]
    }
   ],
   "source": [
    "save_loc = \"/gpfs/data/oermannlab/private_data/DeepPit/saved_dset_metadata\"\n",
    "save_preds_loc = f\"{save_loc}/preds_{model_fn[:-4]}\"\n",
    "print(save_preds_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6efffd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # all predictions, 67 items, 4 workers, 15sec\n",
    "# start = time.time()\n",
    "# predictions, targets = learn.get_preds(ds_idx=0, save_preds=Path(save_preds_loc))\n",
    "# elapsed = time.time() - start\n",
    "\n",
    "# print(f\"Elapsed: {elapsed:0.2f} s for {len(test_items)} items.\")\n",
    "\n",
    "# print(predictions.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ac98d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/data/oermannlab/private_data/DeepPit/PitMRdata/samir_labels/50155-50212/50201/MP-RAGE/2000-01-01_00_00_00.0/S164577/ABIDE_50201_MRI_MP-RAGE_br_raw_20120830171150028_S164577_I328580_corrected_n4.nii\n"
     ]
    }
   ],
   "source": [
    "mr_names = [item[0] for item in items]\n",
    "print(mr_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2992f09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast inference (https://forums.fast.ai/t/speeding-up-fastai2-inference-and-a-few-things-learned/66179)\n",
    "\n",
    "# for inference, no segm mask\n",
    "class InferenceIso(Transform):\n",
    "    \n",
    "    def __init__(self, new_sp = 3):\n",
    "        self.new_sp = new_sp\n",
    "        \n",
    "    def encodes(self, x):\n",
    "        # get sitk objs\n",
    "        im_path = x\n",
    "        mr = sitk.ReadImage(im_path, sitk.sitkFloat32)\n",
    "        im = torch.transpose(torch.tensor(sitk.GetArrayFromImage(mr)), 0, 2)\n",
    "        \n",
    "        # resize so isotropic spacing\n",
    "        orig_sp = mr.GetSpacing()\n",
    "        orig_sz = mr.GetSize()\n",
    "        new_sz = [int(round(osz*ospc/self.new_sp)) for osz,ospc in zip(orig_sz, orig_sp)]\n",
    "\n",
    "        while im.ndim < 5: \n",
    "            im = im.unsqueeze(0)\n",
    "\n",
    "        return F.interpolate(im, size = new_sz, mode = 'trilinear', align_corners=False).squeeze()\n",
    "    \n",
    "class InferencePiecewiseHistScaling(Transform):\n",
    "\n",
    "    def __init__(self, landmark_percs=None, standard_scale=None, final_scale=None):\n",
    "        self.landmark_percs = landmark_percs\n",
    "        self.standard_scale = standard_scale\n",
    "        self.final_scale = final_scale\n",
    "\n",
    "    def encodes(self, x):\n",
    "        x = x.piecewise_hist(self.landmark_percs, self.standard_scale)\n",
    "        x = x.clamp(min=0)\n",
    "        x = x.sqrt().max_scale() if self.final_scale is None else self.final_scale(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f518efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # all predictions, 67 items, 4 workers, 15sec\n",
    "# start = time.time()\n",
    "# predictions, targets = learn.get_preds(ds_idx=0, save_preds=)\n",
    "# elapsed = time.time() - start\n",
    "\n",
    "# print(f\"Elapsed: {elapsed:0.2f} s for {len(test_items)} items.\")\n",
    "\n",
    "# print(predictions.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad55b4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9ac65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path, segm_path = test_items[0]\n",
    "orig_mk = torch.load(f\"{str(Path(segm_path).parent)}/seg.pt\").float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb5be23",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85041f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mask2bbox(np.asarray(orig_mk)))\n",
    "print(mask2bbox(np.asarray(rev_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a60891",
   "metadata": {},
   "source": [
    "# Predict unlabelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adc881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = \"ABIDE\"\n",
    "print(\"Folders in ABIDE src (data wo labels) \", end=\"\"); print(*os.listdir(ABIDE_src), sep=\", \")\n",
    "\n",
    "# load ABIDE files\n",
    "with open(f\"{deepPit_src}/saved_metadata/{ds}.txt\", \"rb\") as input_file:\n",
    "    ABIDE_fns = pickle.load(input_file)\n",
    "    \n",
    "# change prefix path\n",
    "def change_src(overlap, s, new_src):\n",
    "    return new_src + s[s.index(overlap) + len(overlap):]\n",
    "\n",
    "ABIDE_fns = [change_src(\"PitMRdata\", s, data_src) for s in ABIDE_fns]\n",
    "\n",
    "# ABIDE ABIDE\n",
    "ABIDE_ABIDE_fns = [fn for fn in ABIDE_fns if fn.startswith(f\"{data_src}/ABIDE/ABIDE\")]\n",
    "print(f\"ABIDE: {len(ABIDE_fns)} vs {len(ABIDE_ABIDE_fns)} files for ABIDE/ABIDE.\")\n",
    "\n",
    "# Get unlabelled files\n",
    "def get_folder_name(s): \n",
    "    return re.search('\\/([0-9]{5})\\/', s).group(1)\n",
    "\n",
    "ABIDE_folders = [get_folder_name(s) for s in ABIDE_ABIDE_fns]\n",
    "labelled_folders = [child for folder in os.listdir(label_src) for child in os.listdir(f\"{label_src}/{folder}\")]\n",
    "unlabelled_fns = [fn for fn in ABIDE_ABIDE_fns if get_folder_name(fn) not in labelled_folders]\n",
    "\n",
    "# filter to exclude Matched_bandwidth_hires?\n",
    "print(*unlabelled_fns[0:10], sep=\"\\n\")\n",
    "print(os.listdir(unlabelled_fns[0])), print(os.listdir(unlabelled_fns[1]))\n",
    "\n",
    "# unlabelled .nii files\n",
    "unlabelled_items = [f\"{fn}/{os.listdir(fn)[0]}\" for fn in unlabelled_fns if \"MP-RAGE\" in fn]\n",
    "print(len(unlabelled_items))\n",
    "\n",
    "#unlabelled_folders = [folder for folder in ABIDE_folders if folder not in labelled_folders]\n",
    "#print(f\"Unlabelled_folders: {len(unlabelled_folders)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf384144",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsoTestSet(Transform):\n",
    "    \n",
    "    def __init__(self, new_sp = 3):\n",
    "        self.new_sp = new_sp\n",
    "        \n",
    "    def encodes(self, x):\n",
    "        # get sitk objs\n",
    "        im_path = x\n",
    "        mr = sitk.ReadImage(im_path, sitk.sitkFloat32)\n",
    "        im = torch.transpose(torch.tensor(sitk.GetArrayFromImage(mr)), 0, 2)\n",
    "       \n",
    "        # resize so isotropic spacing\n",
    "        orig_sp = mr.GetSpacing()\n",
    "        orig_sz = mr.GetSize()\n",
    "        new_sz = [int(round(osz*ospc/self.new_sp)) for osz,ospc in zip(orig_sz, orig_sp)]\n",
    "\n",
    "        while im.ndim < 5: \n",
    "            im = im.unsqueeze(0)\n",
    "\n",
    "        return F.interpolate(im, size = new_sz, mode = 'trilinear', align_corners=False).squeeze()\n",
    "    \n",
    "class Unsqueeze(Transform):\n",
    "    def encodes(self, x):\n",
    "        return x.unsqueeze(1) #.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f60ee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_items[0]) \n",
    "print(unlabelled_items[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0941e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test DLs (no labelled segm obj)\n",
    "\n",
    "unlabelled_items_subset = unlabelled_items[0:30]\n",
    "unlabelled_items_subset = [(a,a) for a in unlabelled_items_subset]\n",
    "\n",
    "unlbl_tfms = [IsoTestSet(3), PadSz(maxs)]\n",
    "unlbl_tls = TfmdLists(unlabelled_items_subset, unlbl_tfms)\n",
    "unlbl_dls = unlbl_tls.dataloaders(bs=bs, after_batch=AddChannel(), num_workers=num_workers)\n",
    "\n",
    "# e\n",
    "\n",
    "# unlbl_tfms = [IsoTestSet(3), PadSz(maxs)]\n",
    "# unlbl_dl = TfmdDL(Datasets(unlabelled_items_subset), \\\n",
    "#                   after_item=unlbl_tfms, \\\n",
    "#                   after_batch=AddChannel(), \\\n",
    "#                   bs=bs, num_workers=num_workers)\n",
    "\n",
    "# #dl = TfmdDL(Datasets(torch.arange(50), tfms = [L(), [_Add1()]]))\n",
    "# unlbl_dls = DataLoaders(unlbl_dl, unlbl_dl)\n",
    "\n",
    "# tls       = TfmdLists(unlabelled_items, test_tfms)\n",
    "# test_dls = tls.dataloaders(bs=bs, after_batch=AddChannel(), num_workers=num_workers)\n",
    "\n",
    "# test get one batch\n",
    "b = unlbl_dls.one_batch()\n",
    "print(type(b), len(b), b[0].shape, b[1].shape)\n",
    "print(len(unlbl_dls.train_ds), len(unlbl_dls.valid_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0263c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all predictions, 36\n",
    "\n",
    "full_res = maxs\n",
    "\n",
    "unlbl_learn = Learner(dls=unlbl_dls, \\\n",
    "                model=obeliskhybrid_visceral(num_labels=2, full_res=full_res), \\\n",
    "                loss_func= loss, \\\n",
    "                metrics = dice_score)\n",
    "\n",
    "# load model fname w/o .pth extension\n",
    "unlbl_learn.load(f\"{model_src}/{model_fn[:-4]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5618324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.predict??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7074f26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cat,_,probs = unlbl_learn.predict(unlabelled_items_subset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48b409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64724f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlbl_learn.get_preds??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242e2122",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlbl_predictions = unlbl_learn.get_preds(dl=unlbl_dl)[0]\n",
    "print(unlbl_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf802a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viz\n",
    "\n",
    "def viz_bbox_unlbl(idx):\n",
    "    mr = unlbl_learn.dls.train_ds[idx][0] \n",
    "    pred = unlbl_predictions[idx]\n",
    "    \n",
    "    # convert pred to mask\n",
    "    pred_mk   = torch.argmax(pred, dim=0)\n",
    "    pred_bbox = mask2bbox(np.array(pred_mk))\n",
    "\n",
    "    mr, pred_mk = np.array(mr), np.array(pred_mk)\n",
    "    \n",
    "    # print bbox\n",
    "    print(\"Pred: \"); print_bbox(*pred_bbox)\n",
    " \n",
    "    # viz\n",
    "    viz_axis(np_arr = mr, \\\n",
    "            bin_mask_arr   = pred_mk,     color1 = \"yellow\",  alpha1=0.3, \\\n",
    "            slices=lrange(*pred_bbox[0:2]), fixed_axis=0, \\\n",
    "            axis_fn = np.rot90, \\\n",
    "            title   = \"Axis 0\", \\\n",
    "\n",
    "            np_arr_b = mr, \\\n",
    "            bin_mask_arr_b   = pred_mk,     color1_b = \"yellow\",  alpha1_b=0.3, \\\n",
    "            slices_b = lrange(*pred_bbox[2:4]), fixed_axis_b=1, \\\n",
    "            title_b  = \"Axis 1\", \\\n",
    "\n",
    "            np_arr_c = mr, \\\n",
    "            bin_mask_arr_c   = pred_mk,     color1_c = \"yellow\",  alpha1_c=0.3, \\\n",
    "            slices_c = lrange(*pred_bbox[4:6]), fixed_axis_c=2, \\\n",
    "            title_c = \"Axis 2\", \\\n",
    "  \n",
    "        ncols = 5, hspace=0.3, fig_mult=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738e4a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_bbox_unlbl(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f9b645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
