{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unable-instruction",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "This notebook checks model generalization performance on other dsets.\n",
    "\n",
    "**With gratitude to**:\n",
    "- https://github.com/mattiaspaul/OBELISK\n",
    "-  https://github.com/kbressem/faimed3d/blob/main/examples/3d_segmentation.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b65c78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    taskid = int(os.getenv('SLURM_ARRAY_TASK_ID'))\n",
    "    do_task = True\n",
    "except:\n",
    "    taskid = 0\n",
    "    do_task = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "832446de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96548c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full lbl items: 335\n",
      "Removed 2 weird, new total lbl items: 333\n",
      "train, valid, test 201 66 66 total 333\n",
      "Cross label items:  418\n",
      "All label items:  751 (abide (333) + cross_lbl (418))\n",
      "Test label items:  484 (test (66) + cross_lbl (418))\n",
      "418\n",
      "418\n",
      "484\n",
      "484\n"
     ]
    }
   ],
   "source": [
    "if not do_task:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "\n",
    "# INFERENCE DATALOADER PARAMS\n",
    "num_workers = 1\n",
    "\n",
    "# ITEMS\n",
    "\n",
    "from pathlib import Path\n",
    "from helpers.items_constants import *\n",
    "from helpers.general import rm_prefix, get_param_default, modelfn2dict\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import pandas as pd\n",
    "\n",
    "dsets_src    = f\"{data_src}/PitMRdata\"\n",
    "\n",
    "# key,val = dset_name, path to top level dir\n",
    "dset_dict = {\n",
    "    \"ABIDE\"                  : f\"{dsets_src}/ABIDE\",\n",
    "    \"ABVIB\"                  : f\"{dsets_src}/ABVIB/ABVIB\",\n",
    "    \"ADNI1_Complete_1Yr_1.5T\": f\"{dsets_src}/ADNI/ADNI1_Complete_1Yr_1.5T/ADNI\",\n",
    "    \"AIBL\"                   : f\"{dsets_src}/AIBL/AIBL\",\n",
    "    \"ICMB\"                   : f\"{dsets_src}/ICMB/ICBM\",\n",
    "    \"PPMI\"                   : f\"{dsets_src}/PPMI/PPMI\",\n",
    "}\n",
    "\n",
    "ppmi  = [i for i in cross_lbl_items if dset_dict[\"PPMI\"] in i[0]]\n",
    "icmb = [i for i in cross_lbl_items if \"ICMB\" in i[1]]\n",
    "adni = [i for i in cross_lbl_items if \"ADNI1_full\" in i[1]]\n",
    "aibl = [i for i in cross_lbl_items if \"AIBL\" in i[1]]\n",
    "abvib = [i for i in cross_lbl_items if \"ABVIB\" in i[1]]\n",
    "\n",
    "print(len(cross_lbl_items))\n",
    "print(len(ppmi)+len(icmb)+len(adni)+len(aibl)+len(abvib))\n",
    "print(len(all_test_lbl_items))\n",
    "print(len(cross_lbl_items)+len(test_items))\n",
    "\n",
    "# Items as dict \n",
    "from pathlib import Path\n",
    "from helpers.items_constants import *\n",
    "\n",
    "# print(f\"n = {len(itemsd)}, test items = {len(test_items)}, other dsets = {len(cross_lbl_items)}\")\n",
    "# print(f\"first item\", itemsd[0])\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "# print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39345ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_recent(model_fn):\n",
    "    dates = [f\"Aug_0{x}\"  for x in range(3,10)]\n",
    "    dates += [f\"Aug_1{x}\" for x in range(0,10)]\n",
    "    return any([date in str(model_fn) for date in dates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e66cc419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO:  84\n",
      "model_CONDSEG_loss_BCE_loss_full_res_96_pixdim_1.5_do_simple_False_do_flip_True_bs_2_epochs_60_time_1628199282_Thu_Aug_05_2021_hr_17_min_34\n",
      "model_CONDSEG_loss_BCE_loss_full_res_96_pixdim_1.5_do_simple_False_do_flip_True_bs_2_epochs_60_time_1628562710_Mon_Aug_09_2021_hr_22_min_31\n",
      "model_CONDSEG_loss_BCE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_False_bs_2_epochs_60_time_1628093521_Wed_Aug_04_2021_hr_12_min_12\n",
      "model_CONDSEG_loss_BCE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1628562656_Mon_Aug_09_2021_hr_22_min_30\n",
      "model_CONDSEG_loss_DICE_loss_full_res_96_pixdim_1.5_do_simple_False_do_flip_True_bs_2_epochs_60_time_1628562361_Mon_Aug_09_2021_hr_22_min_26\n",
      "model_CONDSEG_loss_DICE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1628560951_Mon_Aug_09_2021_hr_22_min_02\n",
      "model_OBELISKHYBRID_loss_BCE_loss_bs_1_epochs_60_time_1627823287_Sun_Aug_01_2021_hr_09_min_08\n",
      "model_OBELISKHYBRID_loss_BCE_loss_bs_1_epochs_60_time_1627823459_Sun_Aug_01_2021_hr_09_min_10\n",
      "model_OBELISKHYBRID_loss_BCE_loss_bs_1_epochs_60_time_1627865816_Sun_Aug_01_2021_hr_20_min_56\n",
      "model_OBELISKHYBRID_loss_BCE_loss_full_res_144_pixdim_1.0_do_simple_False_do_flip_True_bs_2_epochs_60_time_1628520424_Mon_Aug_09_2021_hr_10_min_47\n",
      "model_OBELISKHYBRID_loss_BCE_loss_full_res_144_pixdim_1.0_do_simple_False_do_flip_True_bs_2_epochs_60_time_1628588199_Tue_Aug_10_2021_hr_05_min_36\n",
      "model_OBELISKHYBRID_loss_BCE_loss_full_res_144_pixdim_1.0_do_simple_True_do_flip_True_bs_2_epochs_60_time_1627955068_Mon_Aug_02_2021_hr_21_min_44\n",
      "model_OBELISKHYBRID_loss_BCE_loss_full_res_144_pixdim_1.0_do_simple_True_do_flip_True_bs_2_epochs_60_time_1627955447_Mon_Aug_02_2021_hr_21_min_50\n",
      "model_OBELISKHYBRID_loss_BCE_loss_full_res_144_pixdim_1.0_do_simple_True_do_flip_True_bs_2_epochs_60_time_1628516549_Mon_Aug_09_2021_hr_09_min_42\n",
      "model_OBELISKHYBRID_loss_BCE_loss_full_res_144_pixdim_1.0_do_simple_True_do_flip_True_bs_2_epochs_60_time_1628587053_Tue_Aug_10_2021_hr_05_min_17\n",
      "model_OBELISKHYBRID_loss_BCE_loss_full_res_96_pixdim_1.5_do_simple_False_do_flip_True_bs_2_epochs_60_time_1628572458_Tue_Aug_10_2021_hr_01_min_14\n",
      "model_OBELISKHYBRID_loss_BCE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1628571935_Tue_Aug_10_2021_hr_01_min_05\n",
      "model_OBELISKHYBRID_loss_DICE_loss_bs_1_epochs_60_time_1627865811_Sun_Aug_01_2021_hr_20_min_56\n",
      "model_OBELISKHYBRID_loss_DICE_loss_full_res_144_pixdim_1.0_do_simple_False_do_flip_True_bs_2_epochs_60_time_1628516458_Mon_Aug_09_2021_hr_09_min_40\n",
      "model_OBELISKHYBRID_loss_DICE_loss_full_res_144_pixdim_1.0_do_simple_False_do_flip_True_bs_2_epochs_60_time_1628586305_Tue_Aug_10_2021_hr_05_min_05\n",
      "model_OBELISKHYBRID_loss_DICE_loss_full_res_144_pixdim_1.0_do_simple_True_do_flip_True_bs_1_epochs_60_time_1627951852_Mon_Aug_02_2021_hr_20_min_50\n",
      "model_OBELISKHYBRID_loss_DICE_loss_full_res_144_pixdim_1.0_do_simple_True_do_flip_True_bs_2_epochs_60_time_1627952442_Mon_Aug_02_2021_hr_21_min_00\n",
      "model_OBELISKHYBRID_loss_DICE_loss_full_res_144_pixdim_1.0_do_simple_True_do_flip_True_bs_2_epochs_60_time_1627952846_Mon_Aug_02_2021_hr_21_min_07\n",
      "model_OBELISKHYBRID_loss_DICE_loss_full_res_144_pixdim_1.0_do_simple_True_do_flip_True_bs_2_epochs_60_time_1627954920_Mon_Aug_02_2021_hr_21_min_42\n",
      "model_OBELISKHYBRID_loss_DICE_loss_full_res_144_pixdim_1.0_do_simple_True_do_flip_True_bs_2_epochs_60_time_1627955472_Mon_Aug_02_2021_hr_21_min_51\n",
      "model_OBELISKHYBRID_loss_DICE_loss_full_res_144_pixdim_1.0_do_simple_True_do_flip_True_bs_2_epochs_60_time_1628512328_Mon_Aug_09_2021_hr_08_min_32\n",
      "model_OBELISKHYBRID_loss_DICE_loss_full_res_144_pixdim_1.0_do_simple_True_do_flip_True_bs_2_epochs_60_time_1628584593_Tue_Aug_10_2021_hr_04_min_36\n",
      "model_OBELISKHYBRID_loss_DICE_loss_full_res_96_pixdim_1.5_do_flip_True_bs_1_epochs_60_time_1627945286_Mon_Aug_02_2021_hr_19_min_01\n",
      "model_OBELISKHYBRID_loss_DICE_loss_full_res_96_pixdim_1.5_do_simple_False_do_flip_True_bs_2_epochs_60_time_1628571918_Tue_Aug_10_2021_hr_01_min_05\n",
      "model_OBELISKHYBRID_loss_DICE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1628570351_Tue_Aug_10_2021_hr_00_min_39\n",
      "model_OBELISKHYBRID_loss_log_cosh_dice_loss_bs_1_epochs_60_time_1627865880_Sun_Aug_01_2021_hr_20_min_58\n",
      "model_Regressor_loss_mse_loss_iso_2mm_pad_144_144_144_bs_2_epochs_300_time_1626979958_Thu_Jul_07_2021_hr_14_min_52\n",
      "model_Regressor_loss_mse_loss_iso_2mm_pad_144_144_144_bs_2_epochs_300_time_1627071800_Fri_Jul_07_2021_hr_16_min_23\n",
      "model_Regressor_loss_mse_loss_iso_2mm_pad_144_144_144_bs_2_epochs_300_time_1627072951_Fri_Jul_07_2021_hr_16_min_42\n",
      "model_Regressor_loss_mse_loss_iso_2mm_pad_144_144_144_bs_5_epochs_60_time_1626972581_Thu_Jul_07_2021_hr_12_min_49\n",
      "model_Regressor_loss_mse_loss_iso_2mm_pad_144_144_144_bs_5_epochs_60_time_1626973365_Thu_Jul_07_2021_hr_13_min_02\n",
      "model_Regressor_loss_mse_loss_iso_3mm_pad_96_96_96_bs_2_epochs_60_time_1626975779_Thu_Jul_07_2021_hr_13_min_42\n",
      "model_Regressor_loss_mse_loss_iso_3mm_pad_96_96_96_bs_2_epochs_60_time_1626975971_Thu_Jul_07_2021_hr_13_min_46\n",
      "model_Regressor_loss_mse_loss_iso_3mm_pad_96_96_96_bs_5_epochs_300_time_1626979440_Thu_Jul_07_2021_hr_14_min_44\n",
      "model_Regressor_loss_mse_loss_iso_3mm_pad_96_96_96_bs_5_epochs_60_time_1626975499_Thu_Jul_07_2021_hr_13_min_38\n",
      "model_UNET3D_loss_BCE_loss_bs_1_epochs_60_time_1627587882_Thu_Jul_29_2021_hr_15_min_44\n",
      "model_UNET3D_loss_BCE_loss_bs_1_epochs_60_time_1627589781_Thu_Jul_29_2021_hr_16_min_16\n",
      "model_UNET3D_loss_BCE_loss_bs_1_epochs_60_time_1627644025_Fri_Jul_30_2021_hr_07_min_20\n",
      "model_UNET3D_loss_BCE_loss_bs_1_epochs_60_time_1627647477_Fri_Jul_30_2021_hr_08_min_17\n",
      "model_UNET3D_loss_BCE_loss_bs_1_epochs_60_time_1627648499_Fri_Jul_30_2021_hr_08_min_34\n",
      "model_UNET3D_loss_BCE_loss_bs_1_epochs_60_time_1627857949_Sun_Aug_01_2021_hr_18_min_45\n",
      "model_UNET3D_loss_BCE_loss_full_res_96_pixdim_1.5_do_flip_True_bs_1_epochs_60_time_1627944352_Mon_Aug_02_2021_hr_18_min_45\n",
      "model_UNET3D_loss_BCE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1627953292_Mon_Aug_02_2021_hr_21_min_14\n",
      "model_UNET3D_loss_log_cosh_dice_loss_bs_1_epochs_60_time_1627345795_Mon_Jul_07_2021_hr_20_min_29\n",
      "model_UNET3D_loss_log_cosh_dice_loss_bs_1_epochs_60_time_1627352068_Mon_Jul_07_2021_hr_22_min_14\n",
      "model_UNET3D_loss_log_cosh_dice_loss_bs_1_epochs_60_time_1627512333_Wed_Jul_07_2021_hr_18_min_45\n",
      "model_UNET3D_loss_log_cosh_dice_loss_bs_1_epochs_60_time_1627519002_Wed_Jul_07_2021_hr_20_min_36\n",
      "model_UNET3D_loss_log_cosh_dice_loss_bs_1_epochs_60_time_1627526627_Wed_Jul_07_2021_hr_22_min_43\n",
      "model_UNET3D_loss_log_cosh_dice_loss_bs_1_epochs_60_time_1627645540_Fri_Jul_30_2021_hr_07_min_45\n",
      "model_UNET3D_loss_log_cosh_dice_loss_bs_1_epochs_60_time_1627647678_Fri_Jul_30_2021_hr_08_min_21\n",
      "model_UNET3D_loss_perim_loss_iso_2mm_pad_144_144_144_bs_2_epochs_60_time_1626638418_Sun_Jul_07_2021_hr_16_min_00\n",
      "model_UNETR_loss_BCE_loss_bs_1_epochs_60_time_1627823617_Sun_Aug_01_2021_hr_09_min_13\n",
      "model_UNETR_loss_BCE_loss_bs_1_epochs_60_time_1627830603_Sun_Aug_01_2021_hr_11_min_10\n",
      "model_UNETR_loss_BCE_loss_bs_1_epochs_60_time_1627830873_Sun_Aug_01_2021_hr_11_min_14\n",
      "model_UNETR_loss_BCE_loss_full_res_96_pixdim_1.5_do_flip_True_bs_1_epochs_2_time_1627915331_Mon_Aug_02_2021_hr_10_min_42\n",
      "model_UNETR_loss_BCE_loss_full_res_96_pixdim_1.5_do_flip_True_bs_1_epochs_60_time_1627918222_Mon_Aug_02_2021_hr_11_min_30\n",
      "model_UNETR_loss_BCE_loss_full_res_96_pixdim_1.5_do_simple_False_do_flip_True_bs_2_epochs_60_time_1628117907_Wed_Aug_04_2021_hr_18_min_58\n",
      "model_UNETR_loss_BCE_loss_full_res_96_pixdim_1.5_do_simple_False_do_flip_True_bs_2_epochs_60_time_1628124077_Wed_Aug_04_2021_hr_20_min_41\n",
      "model_UNETR_loss_BCE_loss_full_res_96_pixdim_1.5_do_simple_False_do_flip_True_bs_2_epochs_60_time_1628555571_Mon_Aug_09_2021_hr_20_min_32\n",
      "model_UNETR_loss_BCE_loss_full_res_96_pixdim_1.5_do_simple_False_do_flip_True_bs_2_epochs_60_time_1628614644_Tue_Aug_10_2021_hr_12_min_57\n",
      "model_UNETR_loss_BCE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1628555041_Mon_Aug_09_2021_hr_20_min_24\n",
      "model_UNETR_loss_DICE_loss_full_res_96_pixdim_1.5_do_simple_False_do_flip_True_bs_2_epochs_60_time_1628427274_Sun_Aug_08_2021_hr_08_min_54\n",
      "model_UNETR_loss_DICE_loss_full_res_96_pixdim_1.5_do_simple_False_do_flip_True_bs_2_epochs_60_time_1628531252_Mon_Aug_09_2021_hr_13_min_47\n",
      "model_UNETR_loss_DICE_loss_full_res_96_pixdim_1.5_do_simple_False_do_flip_True_bs_2_epochs_60_time_1628554750_Mon_Aug_09_2021_hr_20_min_19\n",
      "model_UNETR_loss_DICE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1628554005_Mon_Aug_09_2021_hr_20_min_06\n",
      "model_VNET_loss_BCE_loss_bs_1_epochs_60_time_1627818261_Sun_Aug_01_2021_hr_07_min_44\n",
      "model_VNET_loss_BCE_loss_bs_1_epochs_60_time_1627819388_Sun_Aug_01_2021_hr_08_min_03\n",
      "model_VNET_loss_BCE_loss_bs_1_epochs_60_time_1627823149_Sun_Aug_01_2021_hr_09_min_05\n",
      "model_VNET_loss_BCE_loss_full_res_96_pixdim_1.5_do_flip_True_bs_1_epochs_60_time_1627917248_Mon_Aug_02_2021_hr_11_min_14\n",
      "model_VNET_loss_BCE_loss_full_res_96_pixdim_1.5_do_simple_False_do_flip_True_bs_2_epochs_60_time_1628512127_Mon_Aug_09_2021_hr_08_min_28\n",
      "model_VNET_loss_BCE_loss_full_res_96_pixdim_1.5_do_simple_False_do_flip_True_bs_2_epochs_60_time_1628579841_Tue_Aug_10_2021_hr_03_min_17\n",
      "model_VNET_loss_BCE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1628578641_Tue_Aug_10_2021_hr_02_min_57\n",
      "model_VNET_loss_DICE_loss_full_res_96_pixdim_1.5_do_flip_True_bs_1_epochs_60_time_1627917338_Mon_Aug_02_2021_hr_11_min_15\n",
      "model_VNET_loss_DICE_loss_full_res_96_pixdim_1.5_do_flip_True_bs_1_epochs_60_time_1627944650_Mon_Aug_02_2021_hr_18_min_50\n",
      "model_VNET_loss_DICE_loss_full_res_96_pixdim_1.5_do_simple_False_do_flip_True_bs_2_epochs_60_time_1628578584_Tue_Aug_10_2021_hr_02_min_56\n",
      "model_VNET_loss_DICE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1628577004_Tue_Aug_10_2021_hr_02_min_30\n",
      "model_ensemble\n",
      "model_ensemble_bce\n",
      "model_ensemble_dice\n",
      "CONDSEG BCE_loss simple augs:  False flip True pixdim (1.5, 1.5, 1.5) full_res (96, 96, 96)\n",
      "UNETR DICE_loss simple augs:  False flip True pixdim (1.5, 1.5, 1.5) full_res (96, 96, 96)\n",
      "CONDSEG BCE_loss simple augs:  True flip True pixdim (1.5, 1.5, 1.5) full_res (96, 96, 96)\n",
      "CONDSEG DICE_loss simple augs:  True flip True pixdim (1.5, 1.5, 1.5) full_res (96, 96, 96)\n",
      "OBELISKHYBRID BCE_loss simple augs:  True flip True pixdim (1.5, 1.5, 1.5) full_res (96, 96, 96)\n",
      "CONDSEG DICE_loss simple augs:  False flip True pixdim (1.5, 1.5, 1.5) full_res (96, 96, 96)\n",
      "OBELISKHYBRID DICE_loss simple augs:  True flip True pixdim (1.5, 1.5, 1.5) full_res (96, 96, 96)\n",
      "OBELISKHYBRID DICE_loss simple augs:  False flip True pixdim (1.5, 1.5, 1.5) full_res (96, 96, 96)\n",
      "OBELISKHYBRID BCE_loss simple augs:  False flip True pixdim (1.5, 1.5, 1.5) full_res (96, 96, 96)\n",
      "UNETR DICE_loss simple augs:  False flip True pixdim (1.5, 1.5, 1.5) full_res (96, 96, 96)\n",
      "OBELISKHYBRID BCE_loss simple augs:  False flip True pixdim (1.0, 1.0, 1.0) full_res (144, 144, 144)\n",
      "UNETR DICE_loss simple augs:  True flip True pixdim (1.5, 1.5, 1.5) full_res (96, 96, 96)\n",
      "UNETR BCE_loss simple augs:  True flip True pixdim (1.5, 1.5, 1.5) full_res (96, 96, 96)\n",
      "UNETR BCE_loss simple augs:  False flip True pixdim (1.5, 1.5, 1.5) full_res (96, 96, 96)\n",
      "VNET BCE_loss simple augs:  False flip True pixdim (1.5, 1.5, 1.5) full_res (96, 96, 96)\n",
      "VNET DICE_loss simple augs:  False flip True pixdim (1.5, 1.5, 1.5) full_res (96, 96, 96)\n",
      "VNET BCE_loss simple augs:  True flip True pixdim (1.5, 1.5, 1.5) full_res (96, 96, 96)\n",
      "VNET DICE_loss simple augs:  True flip True pixdim (1.5, 1.5, 1.5) full_res (96, 96, 96)\n",
      "OBELISKHYBRID DICE_loss simple augs:  True flip True pixdim (1.0, 1.0, 1.0) full_res (144, 144, 144)\n",
      "OBELISKHYBRID BCE_loss simple augs:  True flip True pixdim (1.0, 1.0, 1.0) full_res (144, 144, 144)\n",
      "OBELISKHYBRID BCE_loss simple augs:  False flip True pixdim (1.0, 1.0, 1.0) full_res (144, 144, 144)\n",
      "OBELISKHYBRID DICE_loss simple augs:  False flip True pixdim (1.0, 1.0, 1.0) full_res (144, 144, 144)\n",
      "UNETR BCE_loss simple augs:  False flip True pixdim (1.5, 1.5, 1.5) full_res (96, 96, 96)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "substring not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d2b1318e148e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtodo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmodel_dict2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelfn2dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mmodel_type2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_type2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_res2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixdim2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_flip2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_simple2\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mmodel_dict2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"loss_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"full_res\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pixdim\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"do_flip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"do_simple\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DeepPit/helpers/general.py\u001b[0m in \u001b[0;36mmodelfn2dict\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;31m# get params from model name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model_\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"loss_bs\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DeepPit/helpers/general.py\u001b[0m in \u001b[0;36mget_param\u001b[0;34m(fn, prefix, suffix)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0mend\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0mres\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: substring not found"
     ]
    }
   ],
   "source": [
    "from helpers.model_loss_choices import get_model, get_loss\n",
    "\n",
    "model_fns = sorted(Path(run_src).iterdir(), key=os.path.getmtime, reverse=True)\n",
    "todo = [str(model_fn) \n",
    "        for model_fn in model_fns \n",
    "        if not (os.path.isfile(f\"{str(model_fn)}/post_lcc_df.pkl\") and \\\n",
    "                (os.path.isfile(f\"{str(model_fn)}/figs/metrics.png\")) and \\\n",
    "                is_recent(model_fn)\n",
    "            )\n",
    "       ]\n",
    "\n",
    "print(\"TODO: \", len(todo))\n",
    "print(*rm_prefix(todo, prefix=run_src, do_sort=True), sep=\"\\n\")\n",
    "\n",
    "for fn in todo:\n",
    "    model_dict2 = modelfn2dict(fn)\n",
    "    model_type2, loss_type2, full_res2, pixdim2, do_flip2, do_simple2 = \\\n",
    "        [model_dict2[k] for k in (\"model_type\", \"loss_type\", \"full_res\", \"pixdim\", \"do_flip\", \"do_simple\")]\n",
    "\n",
    "    print(model_type2, loss_type2, \"simple augs: \", do_simple2, \"flip\", do_flip2, \"pixdim\", pixdim2, \"full_res\", full_res2)\n",
    "    \n",
    "# doing    \n",
    "model_idx  = taskid\n",
    "model_fn   = todo[model_idx]\n",
    "model_name = Path(model_fn).name\n",
    "\n",
    "# get params\n",
    "model_dict = modelfn2dict(model_fn)\n",
    "model_type, loss_type, full_res, pixdim, do_flip, do_simple = \\\n",
    "        [model_dict[k] for k in (\"model_type\", \"loss_type\", \"full_res\", \"pixdim\", \"do_flip\", \"do_simple\")]\n",
    "\n",
    "print(f\"Chosen: {model_name} (idx {model_idx})\")\n",
    "\n",
    "\n",
    "print(f\"Model: {model_type}\")\n",
    "print(f\"Loss : {loss_type}\")\n",
    "print(f\"Pixd : {pixdim}\")\n",
    "print(f\"Fullres : {full_res}\")\n",
    "print(f\"Do flip: {do_flip}\")\n",
    "print(f\"Do simple: {do_simple}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d42b2d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#GPU = 1, #CPU = 40\n",
      "GPU Tesla V100-SXM2-16GB RAM Free: 9321MB | Used: 6839MB | Util  42% | Total 16160MB\n"
     ]
    }
   ],
   "source": [
    "# clear cache\n",
    "import gc\n",
    "from helpers.general import print_hardware_stats\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "if not str(device)==\"cpu\":\n",
    "    torch.cuda.empty_cache()\n",
    "    print_hardware_stats()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60c2c92f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_type' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8902d1dc23c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms_simplified\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_itemsd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_items\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# for condseg atlas choice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{model_type}, {loss_type}, res {full_res} simple augs {do_simple} flip {do_flip} weird {not do_simple and not do_flip}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m _, val_tfms = get_train_valid_transforms(items=train_itemsd, pixdim=pixdim, full_res=full_res, \n\u001b[1;32m      7\u001b[0m                                               do_flip=do_flip, do_simple=do_simple, do_condseg=(model_type==\"CONDSEG\"))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_type' is not defined"
     ]
    }
   ],
   "source": [
    "# Transforms\n",
    "\n",
    "from helpers.transforms_simplified import *\n",
    "train_itemsd = getd(train_items) # for condseg atlas choice\n",
    "_, val_tfms = get_train_valid_transforms(items=train_itemsd, pixdim=pixdim, full_res=full_res, \n",
    "                                              do_flip=do_flip, do_simple=do_simple, do_condseg=(model_type==\"CONDSEG\"))\n",
    "print(f\"val tfms: \", *val_tfms.transforms, sep=\"\\n\")\n",
    "\n",
    "\n",
    "from helpers.general            import get_param\n",
    "from helpers.model_loss_choices import get_model, get_loss\n",
    "\n",
    "model   = get_model(model_type, full_res)\n",
    "loss_fn = get_loss(loss_type) \n",
    "\n",
    "# print\n",
    "print(\"Model name: \", model_name)\n",
    "print(f\"Model type: {model_type}. Loss type: {loss_type}.\")\n",
    "# Dataloaders\n",
    "\n",
    "# Fastai + distributed training\n",
    "from fastai              import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.basics       import *\n",
    "from fastai.distributed  import *\n",
    "\n",
    "# time it - 18s for 484 items\n",
    "start = time.time()\n",
    "\n",
    "#items  = all_test_lbl_items\n",
    "items = all_test_lbl_items #ppmi, icmb, adni, aibl, abvib, test_items\n",
    "itemsd = getd(items)\n",
    "\n",
    "# tls, dls, cuda\n",
    "bs  = 30\n",
    "tls = TfmdLists(itemsd, val_tfms)\n",
    "dls = tls.dataloaders(bs=bs, after_batch=[], num_workers=num_workers, drop_last=False, shuffle=False, shuffle_train=False)\n",
    "\n",
    "if not str(device)==\"cpu\":\n",
    "    dls = dls.cuda()\n",
    "\n",
    "# end timer\n",
    "elapsed = time.time() - start\n",
    "print(f\"Elapsed time: {elapsed:.2f} s for {len(itemsd)} items\")\n",
    "\n",
    "# Learner\n",
    "import gc\n",
    "gc.collect()\n",
    "from helpers.losses import dice_score\n",
    "learn = Learner(dls       = dls, \n",
    "                model     = model, \n",
    "                loss_func = loss_fn,\n",
    "                metrics   = dice_score)\n",
    "\n",
    "# load model fname w/o .pth extension\n",
    "learn.load(f\"{run_src}/{model_name}/model\")\n",
    "if not str(device)==\"cpu\":\n",
    "    learn.model = learn.model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a93b162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.losses import dice, dice_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08650283",
   "metadata": {},
   "source": [
    "# Post-processing\n",
    "\n",
    "1. Largest Connect Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88f7c751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.postprocess import get_largest_connected_component, eval_measure, eval_lcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1c8571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create batches\n",
    "bs        = 5\n",
    "batches = [itemsd[i:min(i+bs, len(itemsd))] for i in range(0,len(itemsd),bs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d26da9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen: model_UNET3D_loss_DICE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1627971508_Tue_Aug_03_2021_hr_02_min_18 (idx 0)\n",
      "Model: UNET3D\n",
      "Loss : DICE_loss\n",
      "Pixd : (1.5, 1.5, 1.5)\n",
      "Fullres : (96, 96, 96)\n",
      "Do flip: True\n",
      "Do simple: True\n",
      "UNET3D, DICE_loss, res (96, 96, 96) simple augs True flip True weird False\n",
      "val tfms: \n",
      "<monai.transforms.io.dictionary.LoadImaged object at 0x7faae0dfa320>\n",
      "<monai.transforms.spatial.dictionary.Spacingd object at 0x7faae0e00fd0>\n",
      "<monai.transforms.intensity.dictionary.NormalizeIntensityd object at 0x7faae0e00d68>\n",
      "<monai.transforms.utility.dictionary.AddChanneld object at 0x7faae0e00c18>\n",
      "<monai.transforms.croppad.dictionary.SpatialPadd object at 0x7f8525020550>\n",
      "<monai.transforms.croppad.dictionary.CenterSpatialCropd object at 0x7faae0e007b8>\n",
      "<monai.transforms.utility.dictionary.ToTensord object at 0x7faae0e00550>\n",
      "UndoDict(['image', 'label'])\n",
      "Model name:  model_UNET3D_loss_DICE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1627971508_Tue_Aug_03_2021_hr_02_min_18\n",
      "Model type: UNET3D. Loss type: DICE_loss.\n",
      "Elapsed time: 1.33 s for 484 items\n"
     ]
    }
   ],
   "source": [
    "overwritten = 'model_UNET3D_loss_DICE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1627971508_Tue_Aug_03_2021_hr_02_min_18'\n",
    "\n",
    "# doing    \n",
    "model_fn   = overwritten\n",
    "model_name = Path(model_fn).name\n",
    "\n",
    "# get params\n",
    "model_dict = modelfn2dict(model_fn)\n",
    "model_type, loss_type, full_res, pixdim, do_flip, do_simple = \\\n",
    "        [model_dict[k] for k in (\"model_type\", \"loss_type\", \"full_res\", \"pixdim\", \"do_flip\", \"do_simple\")]\n",
    "\n",
    "print(f\"Chosen: {model_name} (idx {model_idx})\")\n",
    "\n",
    "\n",
    "print(f\"Model: {model_type}\")\n",
    "print(f\"Loss : {loss_type}\")\n",
    "print(f\"Pixd : {pixdim}\")\n",
    "print(f\"Fullres : {full_res}\")\n",
    "print(f\"Do flip: {do_flip}\")\n",
    "print(f\"Do simple: {do_simple}\")\n",
    "\n",
    "\n",
    "# Transforms\n",
    "\n",
    "from helpers.transforms_simplified import *\n",
    "train_itemsd = getd(train_items) # for condseg atlas choice\n",
    "print(f\"{model_type}, {loss_type}, res {full_res} simple augs {do_simple} flip {do_flip} weird {not do_simple and not do_flip}\")\n",
    "_, val_tfms = get_train_valid_transforms(items=train_itemsd, pixdim=pixdim, full_res=full_res, \n",
    "                                              do_flip=do_flip, do_simple=do_simple, do_condseg=(model_type==\"CONDSEG\"))\n",
    "print(f\"val tfms: \", *val_tfms.transforms, sep=\"\\n\")\n",
    "\n",
    "\n",
    "from helpers.general            import get_param\n",
    "from helpers.model_loss_choices import get_model, get_loss\n",
    "\n",
    "model   = get_model(model_type, full_res)\n",
    "loss_fn = get_loss(loss_type) \n",
    "\n",
    "# print\n",
    "print(\"Model name: \", model_name)\n",
    "print(f\"Model type: {model_type}. Loss type: {loss_type}.\")\n",
    "# Dataloaders\n",
    "\n",
    "# Fastai + distributed training\n",
    "from fastai              import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.basics       import *\n",
    "from fastai.distributed  import *\n",
    "\n",
    "# time it - 18s for 484 items\n",
    "start = time.time()\n",
    "\n",
    "#items  = all_test_lbl_items\n",
    "items = all_test_lbl_items #ppmi, icmb, adni, aibl, abvib, test_items\n",
    "itemsd = getd(items)\n",
    "\n",
    "# tls, dls, cuda\n",
    "bs  = 30\n",
    "tls = TfmdLists(itemsd, val_tfms)\n",
    "dls = tls.dataloaders(bs=bs, after_batch=[], num_workers=num_workers, drop_last=False, shuffle=False, shuffle_train=False)\n",
    "\n",
    "if not str(device)==\"cpu\":\n",
    "    dls = dls.cuda()\n",
    "\n",
    "# end timer\n",
    "elapsed = time.time() - start\n",
    "print(f\"Elapsed time: {elapsed:.2f} s for {len(itemsd)} items\")\n",
    "\n",
    "# Learner\n",
    "import gc\n",
    "gc.collect()\n",
    "from helpers.losses import dice_score\n",
    "learn = Learner(dls       = dls, \n",
    "                model     = model, \n",
    "                loss_func = loss_fn,\n",
    "                metrics   = dice_score)\n",
    "\n",
    "# load model fname w/o .pth extension\n",
    "learn.load(f\"{run_src}/{model_name}/model\")\n",
    "if not str(device)==\"cpu\":\n",
    "    learn.model = learn.model.cuda()\n",
    "    \n",
    "# set model to evaluate model\n",
    "learn.model.eval()\n",
    "\n",
    "i = 0\n",
    "bs = 5\n",
    "batch = batches[0]\n",
    "    \n",
    "data = Pipeline(val_tfms)(batch)\n",
    "inputs, labels = zip(*data) # [(img,lbl), (img,lbl)] => imgs, labels\n",
    "inputs = torch.stack(inputs, dim=0)\n",
    "labels = torch.stack(labels, dim=0)\n",
    "inputs = inputs.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs).cpu()\n",
    "\n",
    "with open(f\"{run_src}/{model_name}/preds_batch_{i}_bs_{bs}.pkl\", 'wb') as handle:\n",
    "    pickle.dump(outputs, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94c229a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " '/gpfs/data/oermannlab/private_data/DeepPit/runs/model_UNET3D_loss_DICE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1627971508_Tue_Aug_03_2021_hr_02_min_18/preds_batch_0_bs_5.pkl')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs), f\"{run_src}/{model_name}/preds_batch_{i}_bs_{bs}.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "694ec2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 5.85 s\n",
      "Elapsed: 6.73 s\n",
      "Elapsed: 4.83 s\n",
      "Elapsed: 4.64 s\n",
      "Elapsed: 4.14 s\n",
      "Elapsed: 5.30 s\n",
      "Elapsed: 4.53 s\n",
      "Elapsed: 4.45 s\n",
      "Elapsed: 4.54 s\n",
      "Elapsed: 4.64 s\n",
      "Elapsed: 4.55 s\n",
      "Elapsed: 4.80 s\n",
      "Elapsed: 6.11 s\n",
      "Elapsed: 5.51 s\n",
      "Elapsed: 5.20 s\n",
      "Elapsed: 4.60 s\n",
      "Elapsed: 5.11 s\n",
      "Elapsed: 5.38 s\n",
      "Elapsed: 5.26 s\n",
      "Elapsed: 5.30 s\n",
      "Elapsed: 5.25 s\n",
      "Elapsed: 5.51 s\n",
      "Elapsed: 5.30 s\n",
      "Elapsed: 5.73 s\n",
      "Elapsed: 5.30 s\n",
      "Elapsed: 5.49 s\n",
      "Elapsed: 5.57 s\n",
      "Elapsed: 5.24 s\n",
      "Elapsed: 4.77 s\n",
      "Elapsed: 4.74 s\n",
      "Elapsed: 5.13 s\n",
      "Elapsed: 5.27 s\n",
      "Elapsed: 5.05 s\n",
      "Elapsed: 5.40 s\n",
      "Elapsed: 5.13 s\n",
      "Elapsed: 5.31 s\n",
      "Elapsed: 5.30 s\n",
      "Elapsed: 5.15 s\n",
      "Elapsed: 5.06 s\n",
      "Elapsed: 5.00 s\n",
      "Elapsed: 5.05 s\n",
      "Elapsed: 5.12 s\n",
      "Elapsed: 5.24 s\n",
      "Elapsed: 5.47 s\n",
      "Elapsed: 4.32 s\n",
      "Elapsed: 5.20 s\n",
      "Elapsed: 4.74 s\n",
      "Elapsed: 5.16 s\n",
      "Elapsed: 4.50 s\n",
      "Elapsed: 5.20 s\n",
      "Elapsed: 4.75 s\n",
      "Elapsed: 5.12 s\n",
      "Elapsed: 5.59 s\n",
      "Elapsed: 5.07 s\n",
      "Elapsed: 4.40 s\n",
      "Elapsed: 4.86 s\n",
      "Elapsed: 4.85 s\n",
      "Elapsed: 4.79 s\n",
      "Elapsed: 4.82 s\n",
      "Elapsed: 4.85 s\n",
      "Elapsed: 4.96 s\n",
      "Elapsed: 5.24 s\n",
      "Elapsed: 5.31 s\n",
      "Elapsed: 5.30 s\n",
      "Elapsed: 5.18 s\n",
      "Elapsed: 5.25 s\n",
      "Elapsed: 5.17 s\n",
      "Elapsed: 5.24 s\n",
      "Elapsed: 5.21 s\n",
      "Elapsed: 5.65 s\n",
      "Elapsed: 5.63 s\n",
      "Elapsed: 5.44 s\n",
      "Elapsed: 5.39 s\n",
      "Elapsed: 5.50 s\n",
      "Elapsed: 5.38 s\n",
      "Elapsed: 5.23 s\n",
      "Elapsed: 5.22 s\n",
      "Elapsed: 5.23 s\n",
      "Elapsed: 5.27 s\n",
      "Elapsed: 5.39 s\n",
      "Elapsed: 5.45 s\n",
      "Elapsed: 5.26 s\n",
      "Elapsed: 5.38 s\n",
      "Elapsed: 5.23 s\n",
      "Elapsed: 5.41 s\n",
      "Elapsed: 5.46 s\n",
      "Elapsed: 5.51 s\n",
      "Elapsed: 5.42 s\n",
      "Elapsed: 5.34 s\n",
      "Elapsed: 5.28 s\n",
      "Elapsed: 5.14 s\n",
      "Elapsed: 5.22 s\n",
      "Elapsed: 5.36 s\n",
      "Elapsed: 5.13 s\n",
      "Elapsed: 5.38 s\n",
      "Elapsed: 5.55 s\n",
      "Elapsed: 5.68 s\n",
      "Elapsed: 502.69 s for 484 items.\n"
     ]
    }
   ],
   "source": [
    "# set model to evaluate model\n",
    "learn.model.eval()\n",
    "\n",
    "# device = torch.device(\"cuda:0\")\n",
    "\n",
    "# pre & post LCC\n",
    "pre_df  = []\n",
    "post_df = []\n",
    "\n",
    "start = time.time()\n",
    "              \n",
    "                        \n",
    "# deactivate autograd engine and reduce memory usage and speed up computations\n",
    "for i,batch in enumerate(batches):\n",
    "#     start_small = time.time()\n",
    "    \n",
    "    data = Pipeline(val_tfms)(batch)\n",
    "    inputs, labels = zip(*data) # [(img,lbl), (img,lbl)] => imgs, labels\n",
    "    inputs = torch.stack(inputs, dim=0)\n",
    "    labels = torch.stack(labels, dim=0)\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs).cpu()\n",
    "\n",
    "    with open(f\"{run_src}/{model_name}/preds_batch_{i}_bs_{bs}.pkl\", 'wb') as handle:\n",
    "        pickle.dump(outputs, handle)\n",
    "        \n",
    "    # clean up memory\n",
    "    del inputs\n",
    "    del labels\n",
    "    del outputs\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    if str(device) != \"cpu\":\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    # print_hardware_stats()\n",
    "\n",
    "#     elapsed_small = time.time() - start_small\n",
    "#     print(f\"Elapsed: {elapsed_small:0.2f} s\")\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"Elapsed: {elapsed:0.2f} s for {len(itemsd)} items.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2817610f",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e684dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af56359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# for i,fn in enumerate(model_fns):\n",
    "#     if os.path.isfile(f\"{fn}/post_lcc_df.pkl\"):\n",
    "#         print(i,fn)\n",
    "#         os.remove(f\"{fn}/post_lcc_df.pkl\")\n",
    "#         try:\n",
    "#             os.remove(f\"{fn}/pre_lcc_df.pkl\")\n",
    "#             os.remove(f\"{fn}/stats_df.pkl\")\n",
    "#         except:\n",
    "#             \"issue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ce1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import shutil\n",
    "#print(os.path.isfile(f\"{model_fns[0]}/model.pth\"))\n",
    "#shutil.rmtree(model_fns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4ac469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# for i,fn in enumerate(model_fns):\n",
    "#     if not os.path.isfile(f\"{fn}/model.pth\"):\n",
    "#         print(i,fn)\n",
    "#         shutil.rmtree(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff5225c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for model_fn in model_fns:\n",
    "#     if os.path.isfile(f\"{model_fn}/post_lcc_df.pkl\"):\n",
    "#         print(model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ade0868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1daca0fd",
   "metadata": {},
   "source": [
    "# Choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0361050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helpers.general            import get_param\n",
    "# from helpers.model_loss_choices import get_model, get_loss\n",
    "\n",
    "# model_fns = sorted(Path(run_src).iterdir(), key=os.path.getmtime, reverse=True)\n",
    "# todo = [str(model_fn) \n",
    "#         for model_fn in model_fns \n",
    "#         if not os.path.isfile(f\"{str(model_fn)}/post_lcc_df.pkl\") and \"Mon_Aug_02\" in str(model_fn)\n",
    "#        ]\n",
    "\n",
    "# print(\"TODO: \", len(todo))\n",
    "\n",
    "# # params\n",
    "# def get_param_default(name, prefix, suffix, default):\n",
    "#     try:\n",
    "#         return get_param(name, prefix, suffix)\n",
    "#     except:\n",
    "#         return default\n",
    "\n",
    "# for model_fn in todo:\n",
    "#     model_name = Path(model_fn).name\n",
    "\n",
    "#     model_type = get_param(model_name, \"model_\", \"_loss\")\n",
    "\n",
    "#     if \"loss_bs\" in model_name:\n",
    "#         loss_type  = get_param(model_name, \"loss_\", \"_bs\")\n",
    "#     else:\n",
    "#         loss_type  = get_param(model_name, \"loss_\", \"_full_res\")\n",
    "\n",
    "#     full_res   = get_param_default(model_name, \"full_res_\", \"_pixdim\", 96)\n",
    "#     pixdim     = get_param_default(model_name, \"pixdim_\", \"_do_simple\", 1.5)\n",
    "#     do_simple  = get_param_default(model_name, \"do_simple_\", \"_do_flip\", False)\n",
    "#     do_flip    = get_param_default(model_name, \"do_flip_\", \"_bs\", True)\n",
    "\n",
    "#     # tuple\n",
    "#     pixdim    = tuple(float(pixdim) for _ in range(3))\n",
    "#     full_res  = tuple(int(full_res) for _ in range(3))\n",
    "\n",
    "#     # bool\n",
    "#     do_flip   = do_flip == \"True\"\n",
    "#     do_simple = do_simple == \"True\"\n",
    "\n",
    "#     print(f\"Model Name: {model_name}\")\n",
    "#     print(f\"Model: {model_type}\")\n",
    "#     print(f\"Loss : {loss_type}\")\n",
    "#     print(f\"Pixd : {pixdim}\")\n",
    "#     print(f\"Fullres : {full_res}\")\n",
    "#     print(f\"Do flip: {do_flip}\")\n",
    "#     print(f\"Do simple: {do_simple}\")\n",
    "    \n",
    "#     print(\"*\"*50 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
