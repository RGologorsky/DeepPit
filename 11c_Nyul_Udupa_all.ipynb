{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "705a6225",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "Nyul-Udupa histogram rescaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec891cc",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef0a2b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders in data src: ICMB, ABVIB (1).zip, central.xnat.org, ADNI, PPMI, Oasis_long, samir_labels, ACRIN-FMISO-Brain, LGG-1p19qDeletion, REMBRANDT, AIBL, CPTAC-GBM, TCGA-GBM, TCGA-LGG, ABVIB, ABIDE, AIBL.zip\n",
      "Folders in label src (data w labels): 50155-50212, 50313-50372, 50213-50312, 50373-50453, 50002-50153\n",
      "Folders in ABIDE src (data wo labels) PAD, ABIDE_1, ABIDE\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Paths to (1) code (2) data (3) saved models (4) where to save Nyul-Udupa landmarks\n",
    "code_src    = \"/gpfs/home/gologr01\"\n",
    "data_src    = \"/gpfs/data/oermannlab/private_data/DeepPit/PitMRdata\"\n",
    "model_src   = \"/gpfs/data/oermannlab/private_data/DeepPit/saved_models\"\n",
    "save_src    = \"/gpfs/data/oermannlab/private_data/DeepPit/saved_landmarks/ABIDE\"\n",
    "\n",
    "# UMich \n",
    "# code src: \"/home/labcomputer/Desktop/Rachel\"\n",
    "# data src: \"../../../../..//media/labcomputer/e33f6fe0-5ede-4be4-b1f2-5168b7903c7a/home/rachel/\"\n",
    "\n",
    "deepPit_src = f\"{code_src}/DeepPit\"\n",
    "obelisk_src = f\"{code_src}/OBELISK\"\n",
    "label_src   = f\"{data_src}/samir_labels\"\n",
    "ABIDE_src   = f\"{data_src}/ABIDE\"\n",
    "\n",
    "# print\n",
    "print(\"Folders in data src: \", end=\"\"); print(*os.listdir(data_src), sep=\", \")\n",
    "print(\"Folders in label src (data w labels): \", end=\"\"); print(*os.listdir(label_src), sep=\", \")\n",
    "print(\"Folders in ABIDE src (data wo labels) \", end=\"\"); print(*os.listdir(ABIDE_src), sep=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "122d6624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cc19f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from transforms import AddChannel, Iso, PadSz\n",
    "\n",
    "# Utilities\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# regex\n",
    "from re import search\n",
    "\n",
    "# Input IO\n",
    "import SimpleITK as sitk\n",
    "import meshio\n",
    "\n",
    "# Numpy and Pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as DF\n",
    "\n",
    "# Fastai + distributed training\n",
    "from fastai import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.basics import *\n",
    "from fastai.distributed import *\n",
    "\n",
    "# PyTorch\n",
    "from torchvision.models.video import r3d_18\n",
    "from fastai.callback.all import SaveModelCallback\n",
    "from torch import nn\n",
    "\n",
    "# Obelisk\n",
    "sys.path.append(deepPit_src)\n",
    "sys.path.append(obelisk_src)\n",
    "\n",
    "# OBELISK\n",
    "from utils import *\n",
    "from models import obelisk_visceral, obeliskhybrid_visceral\n",
    "\n",
    "# 3D extension to FastAI\n",
    "# from faimed3d.all import *\n",
    "\n",
    "# Helper functions\n",
    "from helpers.preprocess import get_data_dict, paths2objs, folder2objs, seg2mask, mask2bbox, print_bbox, get_bbox_size, print_bbox_size\n",
    "from helpers.general import sitk2np, np2sitk, print_sitk_info, round_tuple, lrange, lmap, get_roi_range, numbers2groups\n",
    "from helpers.viz import viz_axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6690c455",
   "metadata": {},
   "source": [
    "# MR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "161fe182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1160 ../../../mnt/d/PitMRdata/ABIDE/PAD/PAD_0001/T1-FFE/1995-03-11_00_00_00.0/S7478\n",
      "1160 /gpfs/data/oermannlab/private_data/DeepPit/PitMRdata/ABIDE/PAD/PAD_0001/T1-FFE/1995-03-11_00_00_00.0/S7478\n",
      "1157 /gpfs/data/oermannlab/private_data/DeepPit/PitMRdata/ABIDE/ABIDE_1/50383/MP-RAGE/2000-01-01_00_00_00.0/S164289\n"
     ]
    }
   ],
   "source": [
    "# Load fnames from .txt\n",
    "with open(f\"{deepPit_src}/saved_metadata/ABIDE.txt\", 'rb') as f:\n",
    "    fnames = pickle.load(f)\n",
    "print(len(fnames), fnames[0])\n",
    "\n",
    "def change_src(s, old_src=\"../../../mnt/d/PitMRdata\", new_src=data_src): return new_src + s[len(old_src):] \n",
    "fnames = [change_src(f) for f in fnames]\n",
    "print(len(fnames), fnames[0])\n",
    "\n",
    "# exclude PAD (not .nii files)\n",
    "fnames_no_pad = [f for f in fnames if not \"PAD\" in f]\n",
    "print(len(fnames_no_pad), fnames_no_pad[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9cc3448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1157\n"
     ]
    }
   ],
   "source": [
    "# get corrected N4\n",
    "fnames_no_pad = [glob.glob(f\"{f}/*corrected_n4.nii\") for f in fnames_no_pad]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73b5227",
   "metadata": {},
   "source": [
    "# Get chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2f8d5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_chunks = 58\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "taskid = int(os.getenv('SLURM_ARRAY_TASK_ID') or 0)\n",
    "   \n",
    "n_total = len(fnames_no_pad)\n",
    "\n",
    "chunk_len = 20    \n",
    "chunks    = [range(i,min(i+chunk_len, n_total)) for i in range(0, n_total, chunk_len)]\n",
    "\n",
    "print(f\"N_chunks = {len(chunks)}\")\n",
    "# print(f\"Array Task ID: {taskid}\")\n",
    "# print(f\"Array ID: {os.getenv('SLURM_ARRAY_TASK_ID')}\")\n",
    "# print(f\"Job ID: {os.getenv('SLURM_JOB_ID')}\")\n",
    "#print(*chunks, sep=\"\\n\")\n",
    "\n",
    "task_chunk = chunks[taskid]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215209e3",
   "metadata": {},
   "source": [
    "# Transform\n",
    "\n",
    "## from FAIMED3D 02_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8140f638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from FAIMED3D 02_preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78740421",
   "metadata": {},
   "source": [
    "Piecewise linear histogram matching\n",
    "[1] N. Laszlo G and J. K. Udupa, “On Standardizing the MR Image Intensity Scale,” Magn. Reson. Med., vol. 42, pp. 1072–1081, 1999.\n",
    "\n",
    "[2] M. Shah, Y. Xiao, N. Subbanna, S. Francis, D. L. Arnold, D. L. Collins, and T. Arbel, “Evaluating intensity normalization on MRIs of human brain with multiple sclerosis,” Med. Image Anal., vol. 15, no. 2, pp. 267–282, 2011.\n",
    "\n",
    "Implementation adapted from: https://github.com/jcreinhold/intensity-normalization, ported to pytorch (no use of numpy works in cuda).\n",
    "\n",
    "In contrast to hist_scaled, the piecewise linear histogram matching need pre-specified values for new scale and landmarks. It should be used to normalize a whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aa99569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a31a7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percentile(t, q):\n",
    "    \"\"\"\n",
    "    Return the ``q``-th percentile of the flattened input tensor's data.\n",
    "\n",
    "    CAUTION:\n",
    "     * Needs PyTorch >= 1.1.0, as ``torch.kthvalue()`` is used.\n",
    "     * Values are not interpolated, which corresponds to\n",
    "       ``numpy.percentile(..., interpolation=\"nearest\")``.\n",
    "\n",
    "    :param t: Input tensor.\n",
    "    :param q: Percentile to compute, which must be between 0 and 100 inclusive.\n",
    "    :return: Resulting value (float).\n",
    "\n",
    "    This function is twice as fast as torch.quantile and has no size limitations\n",
    "    \"\"\"\n",
    "    # Note that ``kthvalue()`` works one-based, i.e. the first sorted value\n",
    "    # indeed corresponds to k=1, not k=0! Use float(q) instead of q directly,\n",
    "    # so that ``round()`` returns an integer, even if q is a np.float32.\n",
    "\n",
    "    k = 1 + round(.01 * float(q) * (t.numel() - 1))\n",
    "    result = t.view(-1).kthvalue(k)[0].item()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b62ecc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmarks(t: torch.Tensor, percentiles: torch.Tensor)->torch.Tensor:\n",
    "    \"\"\"\n",
    "    Returns the input's landmarks.\n",
    "\n",
    "    :param t (torch.Tensor): Input tensor.\n",
    "    :param percentiles (torch.Tensor): Peraentiles to calculate landmarks for.\n",
    "    :return: Resulting landmarks (torch.tensor).\n",
    "    \"\"\"\n",
    "    return tensor([get_percentile(t, perc.item()) for perc in percentiles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ef298b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_standard_scale(inputs, i_min=1, i_max=99, i_s_min=1, i_s_max=100, l_percentile=10, u_percentile=90, step=10):\n",
    "    \"\"\"\n",
    "    determine the standard scale for the set of images\n",
    "    Args:\n",
    "        inputs (list or L): set of TensorDicom3D objects which are to be normalized\n",
    "        i_min (float): minimum percentile to consider in the images\n",
    "        i_max (float): maximum percentile to consider in the images\n",
    "        i_s_min (float): minimum percentile on the standard scale\n",
    "        i_s_max (float): maximum percentile on the standard scale\n",
    "        l_percentile (int): middle percentile lower bound (e.g., for deciles 10)\n",
    "        u_percentile (int): middle percentile upper bound (e.g., for deciles 90)\n",
    "        step (int): step for middle percentiles (e.g., for deciles 10)\n",
    "    Returns:\n",
    "        standard_scale (np.ndarray): average landmark intensity for images\n",
    "        percs (np.ndarray): array of all percentiles used\n",
    "    \"\"\"\n",
    "    percs = torch.cat([torch.tensor([i_min]),\n",
    "                       torch.arange(l_percentile, u_percentile+1, step),\n",
    "                       torch.tensor([i_max])], dim=0)\n",
    "    standard_scale = torch.zeros(len(percs))\n",
    "\n",
    "    for input_image in inputs:\n",
    "        mask_data = input_image > input_image.mean()\n",
    "        masked = input_image[mask_data]\n",
    "        landmarks = get_landmarks(masked, percs)\n",
    "        min_p = get_percentile(masked, i_min)\n",
    "        max_p = get_percentile(masked, i_max)\n",
    "        new_landmarks = landmarks.interp_1d(torch.FloatTensor([i_s_min, i_s_max]),\n",
    "                                            torch.FloatTensor([min_p, max_p]))\n",
    "        standard_scale += new_landmarks\n",
    "    #standard_scale = standard_scale / len(inputs)\n",
    "    return standard_scale, percs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c00a284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path2tensor(mr_path):\n",
    "    mr = sitk.ReadImage(mr_path, sitk.sitkFloat32)\n",
    "    return torch.transpose(torch.tensor(sitk.GetArrayFromImage(mr)), 0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4795f1",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13b85827",
   "metadata": {},
   "outputs": [],
   "source": [
    "files     = [fnames_no_pad[i] for i in task_chunk]\n",
    "nii_files = [glob.glob(f\"{f}/*corrected_n4.nii\")[0] for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48464f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_sum, percs = find_standard_scale([path2tensor(f) for f in nii_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99fe4d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write standard scale\n",
    "save_loc = \"/gpfs/data/oermannlab/private_data/DeepPit/saved_landmarks/ABIDE\"\n",
    "torch.save(landmarks_sum, f\"{save_loc}/{taskid}_landmarks_sum.pt\")\n",
    "\n",
    "d = {\"nii_files\": nii_files, \"percs\": percs}\n",
    "with open(f'{save_loc}/{taskid}_info.pickle', 'wb') as handle:\n",
    "    pickle.dump(d, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b39b82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
