{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "Run on Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader params\n",
    "\n",
    "subset_size = 330\n",
    "\n",
    "test_pct  = 1 - float(subset_size)/335\n",
    "bs        = 2\n",
    "nepochs   = 50\n",
    "num_workers = 1\n",
    "\n",
    "iso       = 3\n",
    "maxs      = [87, 90, 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS\n",
    "\n",
    "# CODE (DeepPit, OBELISK, etc)\n",
    "code_src     = \"/workspace\"\n",
    "deepPit_src  = f\"{code_src}/DeepPit\"\n",
    "obelisk_src  = f\"{code_src}/OBELISK\"\n",
    "\n",
    "# DATA (training, ABIDE, etc)\n",
    "todd_data_src = \"../../../../..//media/labcomputer/e33f6fe0-5ede-4be4-b1f2-5168b7903c7a/home/rachel/\"\n",
    "olab_data_src = \"/gpfs/data/oermannlab/private_data/DeepPit/\"\n",
    "docker_data_src = \"../PitMRdata/Labels/ABIDE\"\n",
    "\n",
    "curr_data_src = docker_data_src\n",
    "\n",
    "def change_src(fn, old_prefix=docker_data_src, new_prefix=olab_data_src):\n",
    "    return new_prefix + fn[len(old_prefix):]\n",
    "\n",
    "# path to training data\n",
    "train_src = curr_data_src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from transforms import AddChannel, Iso, PadSz\n",
    "\n",
    "# Utilities\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Fastai\n",
    "from fastai import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.basics import *\n",
    "\n",
    "# PyTorch\n",
    "from torchvision.models.video import r3d_18\n",
    "from fastai.callback.all import SaveModelCallback\n",
    "from torch import nn\n",
    "\n",
    "# 3D extension to FastAI\n",
    "# from faimed3d.all import *\n",
    "\n",
    "# Input IO\n",
    "import SimpleITK as sitk\n",
    "import meshio\n",
    "\n",
    "# Numpy and Pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as DF\n",
    "\n",
    "# Helper functions\n",
    "from helpers.preprocess import get_data_dict, paths2objs, folder2objs, seg2mask, mask2bbox, print_bbox, get_bbox_size, print_bbox_size\n",
    "from helpers.general import sitk2np, np2sitk, print_sitk_info, round_tuple, lrange, lmap, get_roi_range, numbers2groups\n",
    "from helpers.viz import viz_axis\n",
    "\n",
    "import sys\n",
    "sys.path.append(deepPit_src)\n",
    "sys.path.append(obelisk_src)\n",
    "\n",
    "# OBELISK\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fastai.distributed import *\n",
    "# import argparse\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--local_rank\", type=int)\n",
    "# args = parser.parse_args()\n",
    "# torch.cuda.set_device(args.local_rank)\n",
    "# torch.distributed.init_process_group(backend='nccl', init_method='env://')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Source = path to labels (segmentation)\n",
    "2. data dict[foldername] = (path to MR, path to Segm tensor)\n",
    "    \n",
    "Special subsets:\n",
    "1. *training*: small subset of all labelled items (quick epoch w/ 100 instead of 335 items).\n",
    "2. *unique*: subset of items with unique size, spacing, and orientation (quickly evaluate resize vs. istropic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: Fri Jun 18 16:35:29 2021\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "model_time = time.ctime() # 'Mon Oct 18 13:35:29 2010'\n",
    "print(f\"Time: {model_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders in train path: 50213-50312.zip, 50373-50453, 50313-50372, 50155-50212.zip, 50213-50312, 50155-50212, 50313-50372.zip, 50373-50453.zip, 50002-50153, 50002-50153.zip\n",
      "Folders  ['50373-50453', '50313-50372', '50213-50312', '50155-50212', '50002-50153']\n",
      "Total 335 items in dataset.\n",
      "Training subset of 330 items.\n",
      "Test subset of 5 items.\n",
      "Model name: iso_3mm_pad_87_90_90_bs_2_subset_330_epochs_50_time_Fri Jun 18 16:35:29 2021\n",
      "Total 335 items in dataset.\n",
      "Training subset of 330 items.\n",
      "Unique subset of 28 items.\n"
     ]
    }
   ],
   "source": [
    "# labelled train data\n",
    "train_src = docker_data_src\n",
    "\n",
    "# print\n",
    "print(\"Folders in train path: \", end=\"\"); print(*os.listdir(train_src), sep=\", \")\n",
    "\n",
    "# get data\n",
    "data = {}\n",
    "folders = os.listdir(train_src)\n",
    "\n",
    "# filter .zip\n",
    "folders = [folder for folder in folders if not folder.endswith(\".zip\")]\n",
    "print(\"Folders \", folders)\n",
    "\n",
    "for folder in folders: data.update(get_data_dict(f\"{train_src}/{folder}/{folder}\"))\n",
    "\n",
    "# all items\n",
    "items = list(data.values())\n",
    "\n",
    "# MR files: unique sz, sp, dir\n",
    "with open(f'{deepPit_src}/saved_metadata/unique_sz_sp_dir.pkl', 'rb') as f:\n",
    "    unique = pickle.load(f)\n",
    "\n",
    "# Create (MR path, Segm path) item from MR path\n",
    "def get_folder_name(s):\n",
    "    start = s.index(\"samir_labels/\")\n",
    "    s = s[start + len(\"samir_labels/50373-50453/\"):]\n",
    "    return s[0:s.index(\"/\")]\n",
    "\n",
    "# get unique\n",
    "unique = [(change_src(mr), data[get_folder_name(mr)][1]) for mr in unique]\n",
    "\n",
    "# subset\n",
    "subset_idxs, test_idxs = RandomSplitter(valid_pct=test_pct)(items)\n",
    "subset = [items[i] for i in subset_idxs]\n",
    "test   = [items[i] for i in test_idxs]\n",
    "\n",
    "# print\n",
    "print(f\"Total {len(items)} items in dataset.\")\n",
    "print(f\"Training subset of {len(subset)} items.\")\n",
    "print(f\"Test subset of {len(test)} items.\")\n",
    "\n",
    "# model name\n",
    "model_name = f\"iso_{iso}mm_pad_{maxs[0]}_{maxs[1]}_{maxs[2]}_bs_{bs}_subset_{len(subset)}_epochs_{nepochs}_time_{model_time}\"\n",
    "print(f\"Model name: {model_name}\")\n",
    "\n",
    "# save test set indices\n",
    "with open(f'{deepPit_src}/model_test_sets/{model_name}_test_items.pkl', 'wb') as f:\n",
    "    pickle.dump(list(test), f)\n",
    "    \n",
    "# print\n",
    "print(f\"Total {len(items)} items in dataset.\")\n",
    "print(f\"Training subset of {len(subset)} items.\")\n",
    "print(f\"Unique subset of {len(unique)} items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: iso_3mm_pad_87_90_90_bs_2_subset_330_epochs_50_time_Fri Jun 18 16:35:29 2021\n"
     ]
    }
   ],
   "source": [
    "# model name\n",
    "model_name = f\"iso_3mm_pad_87_90_90_bs_{bs}_subset_{len(subset)}_epochs_{nepochs}_time_{model_time}\"\n",
    "print(f\"Model name: {model_name}\"),\n",
    "\n",
    "# save test set indices\\n\",\n",
    "with open(f'{deepPit_src}/model_test_sets/{model_name}_test_items.pkl', 'wb') as f:\n",
    "    pickle.dump(list(test), f)\n",
    "      \n",
    "# with open(f\"model_test_sets/{model_name}_test_items.pkl\", 'rb') as f:\n",
    "#     test = pickle.load(f)\n",
    "# print(test[0]), print(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms\n",
    "\n",
    "1. Isotropic 3mm or Resize to 50x50x50 dimensions\n",
    "2. Crop/Pad to common dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test\n",
    "\n",
    "# tfms = [Iso(3)]\n",
    "# tls = TfmdLists(unique, tfms)\n",
    "\n",
    "# start = time.time()\n",
    "# iso_szs = [mr.shape for mr,mk in tls]\n",
    "# elapsed = time.time() - start\n",
    "\n",
    "# print(f\"Elapsed: {elapsed} s for {len(unique)} items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# iso_szs = [mr.shape for mr,mk in tls]\n",
    "# elapsed = time.time() - start\n",
    "\n",
    "# print(f\"Elapsed: {elapsed} s for {len(unique)} items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(*[f\"{get_folder_name(mr)}: {tuple(sz)}\" for (mr,mk),sz in zip(unique, iso_szs)], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxs = [int(x) for x in torch.max(torch.tensor(iso_szs), dim=0).values]\n",
    "# print(\"Maxs: \", maxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test\n",
    "# iso_items = list(tls[0:2])\n",
    "\n",
    "# # tfms\n",
    "# pad_tfms = [PadSz(maxs)]\n",
    "\n",
    "# # tls\n",
    "# pad_tls = TfmdLists(iso_items, pad_tfms)\n",
    "\n",
    "# pad_tls[0][0].shape, pad_tls[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloaders\n",
    "\n",
    "TODO augmentations.\n",
    "\n",
    "- dset = tfms applied to items\n",
    "- splits into training/valid\n",
    "- bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 264, Valid: 66\n",
      "Elapsed time: 2.158508539199829 s for 330 items\n",
      "<class 'tuple'> torch.Size([2, 1, 87, 90, 90]) torch.Size([2, 1, 87, 90, 90])\n",
      "132 33\n"
     ]
    }
   ],
   "source": [
    "# time it\n",
    "start = time.time()\n",
    "\n",
    "# splits\n",
    "splits = RandomSplitter(seed=42)(subset)\n",
    "print(f\"Training: {len(splits[0])}, Valid: {len(splits[1])}\")\n",
    "\n",
    "# tfms\n",
    "tfms = [Iso(3), PadSz(maxs)]\n",
    "\n",
    "# tls\n",
    "tls = TfmdLists(items, tfms, splits=splits)\n",
    "\n",
    "# dls\n",
    "dls = tls.dataloaders(bs=bs, after_batch=AddChannel(), num_workers=num_workers)\n",
    "\n",
    "# GPU\n",
    "dls = dls.cuda()\n",
    "\n",
    "# end timer\n",
    "elapsed = time.time() - start\n",
    "print(f\"Elapsed time: {elapsed} s for {len(subset)} items\")\n",
    "\n",
    "# test get one batch\n",
    "b = dls.one_batch()\n",
    "print(type(b), b[0].shape, b[1].shape)\n",
    "print(len(dls.train), len(dls.valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric\n",
    "\n",
    "Linear combination of Dice and Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(input, target):\n",
    "    iflat = input.contiguous().view(-1)\n",
    "    tflat = target.contiguous().view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    return ((2. * intersection) /\n",
    "           (iflat.sum() + tflat.sum()))\n",
    "\n",
    "def dice_score(input, target):\n",
    "    return dice(input.argmax(1), target)\n",
    "\n",
    "def dice_loss(input, target): \n",
    "    return 1 - dice(input.softmax(1)[:, 1], target)\n",
    "\n",
    "def loss(input, target):\n",
    "    return dice_loss(input, target) + nn.CrossEntropyLoss()(input, target[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OBELISK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "\n",
    "# segs = torch.cat([tl[1] for tl in dls.train],0)\n",
    "# print(segs.shape)\n",
    "\n",
    "# elapsed = time.time() - start\n",
    "\n",
    "# print(f\"Elapsed time: {elapsed} s for {len(segs)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weight = torch.sqrt(1.0/(torch.bincount(segs.view(-1)).float()))\n",
    "# class_weight = class_weight/class_weight.mean()\n",
    "# class_weight[0] = 0.5\n",
    "# np.set_printoptions(formatter={'float': '{: 0.2f}'.format})\n",
    "# print('inv sqrt class_weight',class_weight.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import my_ohem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_weight = torch.load(\"saved_metadata/class_weights.pt\")\n",
    "# class_weights = [0, pos_weight]\n",
    "\n",
    "# # inv\n",
    "# class_weights [1.0/x for x in class_wei]\n",
    "# my_criterion = my_ohem(.25,[0, pos_weight]) #.cuda())#0.25 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obelisk_loss_fn(predict, target): return my_criterion(F.log_softmax(predict,dim=1),target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipython nbconvert --to python  '6 - Dataloaders- NB - Simple-Copy1.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBELISK-NET from github\n",
    "from models import obelisk_visceral, obeliskhybrid_visceral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_res = maxs\n",
    "\n",
    "learn = Learner(dls=dls, \\\n",
    "                model=obeliskhybrid_visceral(num_labels=2, full_res=full_res), \\\n",
    "                loss_func= loss, #DiceLoss(), #nn.CrossEntropyLoss(), \\\n",
    "                metrics = dice_score, \\\n",
    "                model_dir = code_src + \"models\", \\\n",
    "                cbs = [SaveModelCallback(monitor='dice_score', fname=model_name, with_opt=True)])\n",
    "\n",
    "# SaveModelCallback: model_dir = \"./models\", cbs = [SaveModelCallback(monitor='dice_score')]\n",
    "\n",
    "# GPU\n",
    "learn.model = learn.model.cuda()\n",
    "\n",
    "#learn = learn.to_distributed(args.local_rank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test:\n",
    "\n",
    "# #dls.device = \"cpu\"\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# x,y = dls.one_batch()\n",
    "# #x,y = to_cpu(x), to_cpu(y)\n",
    "\n",
    "# pred = learn.model(x)\n",
    "# loss = learn.loss_func(pred, y)\n",
    "\n",
    "# elapsed = time.time() - start\n",
    "\n",
    "# print(f\"Elapsed: {elapsed} s\")\n",
    "# print(\"Batch: x,y\")\n",
    "# print(type(x), x.shape, x.dtype, \"\\n\", type(y), y.shape, y.dtype)\n",
    "\n",
    "# print(\"Pred shape\")\n",
    "# print(type(pred), pred.shape, pred.dtype)\n",
    "\n",
    "# print(\"Loss\")\n",
    "# print(loss)\n",
    "# print(learn.loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE learn.fit one cycle\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>dice_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.017327</td>\n",
       "      <td>0.955622</td>\n",
       "      <td>0.560371</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with dice_score value: 0.5603711605072021.\n"
     ]
    }
   ],
   "source": [
    "print(\"PRE learn.fit one cycle\")\n",
    "with learn.distrib_ctx():\n",
    "    learn.fit_one_cycle(1, 3e-3, wd = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unfreeze, learn 50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='28' class='' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      56.00% [28/50 11:12<08:48]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>dice_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.508293</td>\n",
       "      <td>1.419596</td>\n",
       "      <td>0.023283</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.305650</td>\n",
       "      <td>1.198959</td>\n",
       "      <td>0.119322</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.122148</td>\n",
       "      <td>1.058931</td>\n",
       "      <td>0.327266</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.969378</td>\n",
       "      <td>0.928443</td>\n",
       "      <td>0.681038</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.468230</td>\n",
       "      <td>0.376098</td>\n",
       "      <td>0.673380</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.285837</td>\n",
       "      <td>0.227961</td>\n",
       "      <td>0.793906</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.245115</td>\n",
       "      <td>0.343518</td>\n",
       "      <td>0.678921</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.232375</td>\n",
       "      <td>0.271501</td>\n",
       "      <td>0.736131</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.237001</td>\n",
       "      <td>0.241869</td>\n",
       "      <td>0.780092</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.210405</td>\n",
       "      <td>0.333116</td>\n",
       "      <td>0.671908</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.200649</td>\n",
       "      <td>0.201405</td>\n",
       "      <td>0.806243</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.199527</td>\n",
       "      <td>0.210904</td>\n",
       "      <td>0.794734</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.199308</td>\n",
       "      <td>0.188849</td>\n",
       "      <td>0.817424</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.182388</td>\n",
       "      <td>0.261999</td>\n",
       "      <td>0.742773</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.176740</td>\n",
       "      <td>0.187510</td>\n",
       "      <td>0.819855</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.168740</td>\n",
       "      <td>0.232074</td>\n",
       "      <td>0.773714</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.171502</td>\n",
       "      <td>0.204060</td>\n",
       "      <td>0.803450</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.158257</td>\n",
       "      <td>0.189648</td>\n",
       "      <td>0.817780</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.157555</td>\n",
       "      <td>0.188346</td>\n",
       "      <td>0.817335</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.143044</td>\n",
       "      <td>0.202320</td>\n",
       "      <td>0.804133</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.137940</td>\n",
       "      <td>0.185364</td>\n",
       "      <td>0.820577</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.126283</td>\n",
       "      <td>0.182460</td>\n",
       "      <td>0.823142</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.121762</td>\n",
       "      <td>0.183423</td>\n",
       "      <td>0.821466</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.116330</td>\n",
       "      <td>0.186962</td>\n",
       "      <td>0.818772</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.113001</td>\n",
       "      <td>0.187590</td>\n",
       "      <td>0.818746</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.115861</td>\n",
       "      <td>0.185412</td>\n",
       "      <td>0.820651</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.104124</td>\n",
       "      <td>0.192180</td>\n",
       "      <td>0.814151</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.094624</td>\n",
       "      <td>0.193162</td>\n",
       "      <td>0.813586</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='46' class='' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      34.85% [46/132 00:06<00:11 0.0861]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with dice_score value: 0.02328326366841793.\n",
      "Better model found at epoch 1 with dice_score value: 0.11932217329740524.\n",
      "Better model found at epoch 2 with dice_score value: 0.32726627588272095.\n",
      "Better model found at epoch 3 with dice_score value: 0.6810376048088074.\n",
      "Better model found at epoch 5 with dice_score value: 0.7939056754112244.\n",
      "Better model found at epoch 10 with dice_score value: 0.8062425255775452.\n",
      "Better model found at epoch 12 with dice_score value: 0.817424476146698.\n",
      "Better model found at epoch 14 with dice_score value: 0.8198553919792175.\n",
      "Better model found at epoch 20 with dice_score value: 0.8205769062042236.\n",
      "Better model found at epoch 21 with dice_score value: 0.8231424689292908.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-0e73634790d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistrib_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/fastai/callback/schedule.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    111\u001b[0m     scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\n\u001b[1;32m    112\u001b[0m               'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mParamScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_end_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/fastai/data/load.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'it'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"unfreeze, learn 50\")\n",
    "learn.unfreeze()\n",
    "with learn.distrib_ctx():\n",
    "    learn.fit_one_cycle(nepochs, 3e-3, wd = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('models/iso_3mm_pad_87_90_90_subset_50_epochs_50.pth')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn.save('iso_3mm_pad_87_90_90_subset_50_epochs_50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=6.309573450380412e-08, lr_steep=6.309573450380412e-07)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"unfreeze, learn 50\")\n",
    "# learn.unfreeze()\n",
    "# learn.fit_one_cycle(50, 1e-3, wd = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testmask = torch.tensor([[[False, False, False], [False, False, False], [True, True, True]],\n",
    "#                        [[False, False, False], [False, False, True], [True, True, True]],\n",
    "#                        [[False, False, False], [False, False, False], [False, False, False]]])\n",
    "# testmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testmaskN = np.array(testmask)\n",
    "# testmaskN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maskT = testmask.type(torch.BoolTensor)\n",
    "\n",
    "# iT = torch.any(maskT, dim=(1,2))\n",
    "# jT = torch.any(maskT, dim=(0,2))\n",
    "# kT = torch.any(maskT, dim=(0,1))\n",
    "\n",
    "# iminT, imaxT = torch.where(iT)[0][[0, -1]]\n",
    "# jminT, jmaxT = torch.where(jT)[0][[0, -1]]\n",
    "# kminT, kmaxT = torch.where(kT)[0][[0, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maskN = np.array(testmask).astype(bool)\n",
    "    \n",
    "# iN = np.any(maskN, axis=(1, 2))\n",
    "# jN = np.any(maskN, axis=(0, 2))\n",
    "# kN = np.any(maskN, axis=(0, 1))\n",
    "\n",
    "# iminN, imaxN = np.where(iN)[0][[0, -1]]\n",
    "# jminN, jmaxN = np.where(jN)[0][[0, -1]]\n",
    "# kminN, kmaxN = np.where(kN)[0][[0, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maskT.shape, maskN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(iT)\n",
    "# print(jT)\n",
    "# print(kT)\n",
    "# print([x for x in (iminT, imaxT, jminT, jmaxT, kminT, kmaxT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(iN)\n",
    "# print(jN)\n",
    "# print(kN)\n",
    "# print([int(x) for x in (iminN, imaxN, jminN, jmaxN, kminN, kmaxN)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def torch_mask2bbox(mask):\n",
    "#         mask = mask.type(torch.BoolTensor)\n",
    "\n",
    "#         i = torch.any(mask, dim=0)\n",
    "#         j = torch.any(mask, dim=1)\n",
    "#         k = torch.any(mask, dim=2)\n",
    "\n",
    "#         imin, imax = torch.where(i)[0][[0, -1]]\n",
    "#         jmin, jmax = torch.where(j)[0][[0, -1]]\n",
    "#         kmin, kmax = torch.where(k)[0][[0, -1]]\n",
    "\n",
    "#         # inclusive idxs\n",
    "#         return imin, imax+1, jmin, jmax+1, kmin, kmax+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
