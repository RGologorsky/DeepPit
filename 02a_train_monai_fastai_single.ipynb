{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3321cd55",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "Train model\n",
    "\n",
    "Thanks to: OBELISK, FAIMED3D, MONAI\n",
    "- https://github.com/mattiaspaul/OBELISK\n",
    "-  https://github.com/kbressem/faimed3d/blob/main/examples/3d_segmentation.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493866e5",
   "metadata": {},
   "source": [
    "# Setup parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e07c233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "\n",
    "# DATALOADER PARAMS\n",
    "bs          = 2\n",
    "nepochs     = 60\n",
    "num_workers = 2\n",
    "\n",
    "kwargs = dict(arg.split(\"=\") for arg in sys.argv if \"=\" in arg)\n",
    "print(kwargs)\n",
    "\n",
    "do_reload = \"model_type\" not in kwargs # True #True #True #False\n",
    "if do_reload:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    \n",
    "    model_type = \"UNETR\" # VNET, UNET3D, UNETR, SegResNetVAE, OBELISKHYBRID\n",
    "    loss_type  = \"DICE_loss\" # DICE_loss\n",
    "    pixdim     = tuple(1.5 for _ in range(3))\n",
    "    full_res   = tuple(96 for _ in range(3))\n",
    "    do_flip    = True\n",
    "    do_simple  = False\n",
    "    do_test    = False # False\n",
    "\n",
    "else:\n",
    "    model_type = kwargs[\"model_type\"]\n",
    "    loss_type  = kwargs[\"loss_type\"]\n",
    "    pixdim     = kwargs[\"pixdim\"]\n",
    "    full_res   = kwargs[\"full_res\"]\n",
    "    do_flip    = kwargs[\"do_flip\"]\n",
    "    do_simple  = kwargs[\"do_simple\"]\n",
    "    do_test    = False\n",
    "\n",
    "    # tuple\n",
    "    pixdim    = tuple(float(pixdim) for _ in range(3))\n",
    "    full_res  = tuple(int(full_res) for _ in range(3))\n",
    "    \n",
    "    # bool\n",
    "    do_flip   = do_flip == \"True\"\n",
    "    do_simple = do_simple == \"True\"\n",
    "\n",
    "    print(f\"Model: {model_type}\")\n",
    "    print(f\"Loss : {loss_type}\")\n",
    "    print(f\"Pixd : {pixdim}\")\n",
    "    print(f\"Fullres : {full_res}\")\n",
    "    print(f\"Do flip: {do_flip}\")\n",
    "    print(f\"Do simple: {do_simple}\")\n",
    "    \n",
    "if model_type == \"UNETR\":\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89fdc796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full lbl items: 335\n",
      "Removed 2 weird, new total lbl items: 333\n",
      "train, valid, test 201 66 66 total 333\n",
      "Cross label items:  418\n",
      "All label items:  751 (abide (333) + cross_lbl (418))\n",
      "Test label items:  484 (test (66) + cross_lbl (418))\n",
      "MONAI version: 0.7.dev2131\n",
      "Numpy version: 1.19.5\n",
      "Pytorch version: 1.7.1+cu101\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: 57467c75bff90e6c9da74461f7da3a828a39626b\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.5\n",
      "Nibabel version: 3.2.1\n",
      "scikit-image version: 0.17.2\n",
      "Pillow version: 8.3.1\n",
      "Tensorboard version: 2.5.0\n",
      "gdown version: 3.13.0\n",
      "TorchVision version: 0.8.2+cu101\n",
      "tqdm version: 4.62.0\n",
      "lmdb version: 1.2.1\n",
      "psutil version: 5.8.0\n",
      "pandas version: 1.1.5\n",
      "einops version: 0.3.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n",
      "#GPU = 1, #CPU = 40\n",
      "GPU Tesla V100-SXM2-16GB RAM Free: 16157MB | Used: 3MB | Util   0% | Total 16160MB\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "# Utilities\n",
    "import os, shutil, sys, gc, time, pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Monai\n",
    "from monai.config    import print_config\n",
    "\n",
    "# Fastai + distributed training\n",
    "from fastai              import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.basics       import *\n",
    "from fastai.distributed  import *\n",
    "from fastai.callback.all import SaveModelCallback, CSVLogger, ProgressCallback\n",
    "\n",
    "# Helpers\n",
    "from helpers.general import print_hardware_stats\n",
    "from helpers.losses  import dice_score\n",
    "from helpers.items_constants    import *\n",
    "from helpers.transforms_simplified         import *\n",
    "\n",
    "# Save test idxs + model + runs\n",
    "from helpers.time       import time_one_batch, get_time_id\n",
    "from helpers.model_loss_choices import get_model, get_loss\n",
    "\n",
    "print_config()\n",
    "\n",
    "# clear cache\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print_hardware_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2eb7395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 201, val: 66\n",
      "UNETR, res (96, 96, 96) simple augs False flip True weird False\n",
      "Model name: model_UNETR_loss_DICE_loss_full_res_96_pixdim_1.5_do_simple_False_do_flip_True_bs_2_epochs_60_time_1628683844_Wed_Aug_11_2021_hr_08_min_10\n"
     ]
    }
   ],
   "source": [
    "# Items as dict\n",
    "train_itemsd = getd(train_items)\n",
    "val_itemsd   = getd(valid_items)\n",
    "print(f\"train: {len(train_itemsd)}, val: {len(val_itemsd)}\")\n",
    "\n",
    "# Transforms\n",
    "print(f\"{model_type}, res {full_res} simple augs {do_simple} flip {do_flip} weird {not do_simple and not do_flip}\")\n",
    "train_tfms, val_tfms = get_train_valid_transforms(items=train_itemsd, pixdim=pixdim, full_res=full_res, \n",
    "                                                  do_flip=do_flip, do_simple=do_simple, do_condseg=(model_type==\"CONDSEG\"))\n",
    "\n",
    "# tls, dls, cuda\n",
    "train_dl = TfmdDL(train_itemsd, after_item=train_tfms, after_batch=[], bs=bs)\n",
    "val_dl   = TfmdDL(val_itemsd,   after_item=val_tfms,   after_batch=[], bs=bs)\n",
    "\n",
    "# tls, dls, cuda\n",
    "if do_test:\n",
    "    train_dl = TfmdDL(train_itemsd[:10], after_item=train_tfms, after_batch=[], bs=bs)\n",
    "    val_dl   = TfmdDL(val_itemsd[:10],   after_item=val_tfms,   after_batch=[], bs=bs)\n",
    "    nepochs = 2\n",
    "    \n",
    "dls = DataLoaders(train_dl, val_dl)\n",
    "dls = dls.cuda()\n",
    "\n",
    "# get model\n",
    "model   = get_model(model_type, full_res)\n",
    "loss_fn = get_loss(loss_type) \n",
    "\n",
    "# save model in runs/model dir + figs; mkdir\n",
    "\n",
    "# file name\n",
    "model_time = get_time_id() # 'Mon Oct 18 13:35:29 2010'\n",
    "model_name = f\"model_{model_type}_loss_{loss_type}_full_res_{full_res[0]}_pixdim_{pixdim[0]}_do_simple_{do_simple}_do_flip_{do_flip}_bs_{bs}_epochs_{nepochs}_time_{model_time}\"\n",
    "print(f\"Model name: {model_name}\")\n",
    "\n",
    "model_src = f\"{run_src}/{model_name}\"\n",
    "fig_src   = f\"{model_src}/figs\"\n",
    "Path(fig_src).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# cbs\n",
    "cbs = [\n",
    "    Recorder(train_metrics=True), # False\n",
    "    SaveModelCallback(monitor='valid_dice_score', with_opt=True), \n",
    "    CSVLogger(fname=f\"{fig_src}/history.csv\")\n",
    "]\n",
    "\n",
    "# learner\n",
    "learn = Learner(dls   = dls, \\\n",
    "                model     = model, \\\n",
    "                loss_func = loss_fn, \\\n",
    "                metrics   = dice_score, \\\n",
    "                model_dir = model_src, \\\n",
    "                cbs       = [])\n",
    "\n",
    "# remove post-recorder, add new cbs, to GPU\n",
    "learn.remove_cbs(learn.cbs[1:])\n",
    "learn.add_cb(ProgressCallback())\n",
    "learn.add_cbs(cbs)\n",
    "learn.model = learn.model.cuda()\n",
    "\n",
    "# save data augs\n",
    "with open(f\"{model_src}/data_augs.txt\", 'w') as f:\n",
    "    def print_data_augs():\n",
    "        print(\"Train Tfms: \", file=f); print(monai_tfms2str(train_tfms), file=f)\n",
    "        print(\"Val   Tfms: \", file=f); print(monai_tfms2str(val_tfms), file=f)\n",
    "        \n",
    "    print_data_augs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce240e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check\n",
    "# print(\"Check\")\n",
    "# b = dls.one_batch()\n",
    "# xb,yb = b #b[\"image\"], b[\"label\"]\n",
    "# print(f\"Batch: {len(b)}. xb: {xb.shape}, yb: {yb.shape}\")\n",
    "# predb = learn.model(xb)\n",
    "# print(f\"Pred batch: {predb.shape}\")\n",
    "# loss = loss_fn(predb, yb)\n",
    "# print(f\"Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd54581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(predb[0].shape, predb[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceedd82",
   "metadata": {},
   "source": [
    "# LR Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ff83a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"PRE learn.fit one cycle\")\n",
    "# with learn.distrib_ctx():\n",
    "#     learn.fit_one_cycle(2, 3e-3, wd = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7b2d803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SuggestedLRs(valley=tensor(0.0229))\n",
    "# learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2aa4f647",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE learn.fit one cycle\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_dice_score</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_dice_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.966480</td>\n",
       "      <td>0.043844</td>\n",
       "      <td>0.963515</td>\n",
       "      <td>0.065915</td>\n",
       "      <td>02:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.961498</td>\n",
       "      <td>0.081873</td>\n",
       "      <td>0.958554</td>\n",
       "      <td>0.089645</td>\n",
       "      <td>02:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.956461</td>\n",
       "      <td>0.107432</td>\n",
       "      <td>0.951601</td>\n",
       "      <td>0.127683</td>\n",
       "      <td>02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.941521</td>\n",
       "      <td>0.129221</td>\n",
       "      <td>0.921993</td>\n",
       "      <td>0.204297</td>\n",
       "      <td>01:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.885263</td>\n",
       "      <td>0.219537</td>\n",
       "      <td>0.821267</td>\n",
       "      <td>0.266886</td>\n",
       "      <td>02:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.737189</td>\n",
       "      <td>0.361769</td>\n",
       "      <td>0.587281</td>\n",
       "      <td>0.496157</td>\n",
       "      <td>02:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.601704</td>\n",
       "      <td>0.457351</td>\n",
       "      <td>0.504346</td>\n",
       "      <td>0.544778</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.550583</td>\n",
       "      <td>0.478826</td>\n",
       "      <td>0.501655</td>\n",
       "      <td>0.529097</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.531044</td>\n",
       "      <td>0.496422</td>\n",
       "      <td>0.507107</td>\n",
       "      <td>0.511964</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.506480</td>\n",
       "      <td>0.501930</td>\n",
       "      <td>0.460101</td>\n",
       "      <td>0.558431</td>\n",
       "      <td>02:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.516685</td>\n",
       "      <td>0.500763</td>\n",
       "      <td>0.443753</td>\n",
       "      <td>0.573476</td>\n",
       "      <td>01:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.502321</td>\n",
       "      <td>0.519113</td>\n",
       "      <td>0.707797</td>\n",
       "      <td>0.300856</td>\n",
       "      <td>01:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.494433</td>\n",
       "      <td>0.505271</td>\n",
       "      <td>0.450803</td>\n",
       "      <td>0.561061</td>\n",
       "      <td>01:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.476695</td>\n",
       "      <td>0.545197</td>\n",
       "      <td>0.415037</td>\n",
       "      <td>0.599756</td>\n",
       "      <td>01:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.477733</td>\n",
       "      <td>0.528314</td>\n",
       "      <td>0.403770</td>\n",
       "      <td>0.606909</td>\n",
       "      <td>01:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.495051</td>\n",
       "      <td>0.517804</td>\n",
       "      <td>0.500026</td>\n",
       "      <td>0.506737</td>\n",
       "      <td>01:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.464151</td>\n",
       "      <td>0.541742</td>\n",
       "      <td>0.391635</td>\n",
       "      <td>0.620285</td>\n",
       "      <td>01:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.452682</td>\n",
       "      <td>0.553918</td>\n",
       "      <td>0.400135</td>\n",
       "      <td>0.610847</td>\n",
       "      <td>01:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.432900</td>\n",
       "      <td>0.573226</td>\n",
       "      <td>0.453599</td>\n",
       "      <td>0.553454</td>\n",
       "      <td>01:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.442106</td>\n",
       "      <td>0.559827</td>\n",
       "      <td>0.380949</td>\n",
       "      <td>0.628901</td>\n",
       "      <td>01:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.409847</td>\n",
       "      <td>0.597552</td>\n",
       "      <td>0.381444</td>\n",
       "      <td>0.634059</td>\n",
       "      <td>02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.415818</td>\n",
       "      <td>0.577993</td>\n",
       "      <td>0.386976</td>\n",
       "      <td>0.621699</td>\n",
       "      <td>01:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.416977</td>\n",
       "      <td>0.586212</td>\n",
       "      <td>0.349060</td>\n",
       "      <td>0.657429</td>\n",
       "      <td>01:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.392868</td>\n",
       "      <td>0.612933</td>\n",
       "      <td>0.406867</td>\n",
       "      <td>0.601936</td>\n",
       "      <td>01:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.400092</td>\n",
       "      <td>0.600799</td>\n",
       "      <td>0.367890</td>\n",
       "      <td>0.640359</td>\n",
       "      <td>01:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.409722</td>\n",
       "      <td>0.595294</td>\n",
       "      <td>0.378091</td>\n",
       "      <td>0.628111</td>\n",
       "      <td>01:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.376256</td>\n",
       "      <td>0.626427</td>\n",
       "      <td>0.361788</td>\n",
       "      <td>0.642836</td>\n",
       "      <td>02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.377773</td>\n",
       "      <td>0.619859</td>\n",
       "      <td>0.335773</td>\n",
       "      <td>0.671065</td>\n",
       "      <td>01:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.378184</td>\n",
       "      <td>0.632101</td>\n",
       "      <td>0.344414</td>\n",
       "      <td>0.660616</td>\n",
       "      <td>01:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.377717</td>\n",
       "      <td>0.623702</td>\n",
       "      <td>0.325320</td>\n",
       "      <td>0.679698</td>\n",
       "      <td>01:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.368284</td>\n",
       "      <td>0.639999</td>\n",
       "      <td>0.352122</td>\n",
       "      <td>0.653399</td>\n",
       "      <td>01:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.359419</td>\n",
       "      <td>0.645364</td>\n",
       "      <td>0.328394</td>\n",
       "      <td>0.676198</td>\n",
       "      <td>01:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.349367</td>\n",
       "      <td>0.656973</td>\n",
       "      <td>0.325207</td>\n",
       "      <td>0.679654</td>\n",
       "      <td>01:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.354263</td>\n",
       "      <td>0.647391</td>\n",
       "      <td>0.319111</td>\n",
       "      <td>0.685231</td>\n",
       "      <td>01:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.361400</td>\n",
       "      <td>0.643392</td>\n",
       "      <td>0.320124</td>\n",
       "      <td>0.685048</td>\n",
       "      <td>01:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.345082</td>\n",
       "      <td>0.659210</td>\n",
       "      <td>0.310725</td>\n",
       "      <td>0.693959</td>\n",
       "      <td>01:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.331903</td>\n",
       "      <td>0.669487</td>\n",
       "      <td>0.299553</td>\n",
       "      <td>0.706263</td>\n",
       "      <td>02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.339302</td>\n",
       "      <td>0.662319</td>\n",
       "      <td>0.315293</td>\n",
       "      <td>0.688723</td>\n",
       "      <td>01:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.334491</td>\n",
       "      <td>0.664805</td>\n",
       "      <td>0.314464</td>\n",
       "      <td>0.689296</td>\n",
       "      <td>01:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.344330</td>\n",
       "      <td>0.661062</td>\n",
       "      <td>0.308599</td>\n",
       "      <td>0.696320</td>\n",
       "      <td>01:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.336311</td>\n",
       "      <td>0.671067</td>\n",
       "      <td>0.300520</td>\n",
       "      <td>0.704290</td>\n",
       "      <td>01:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.313368</td>\n",
       "      <td>0.689318</td>\n",
       "      <td>0.287521</td>\n",
       "      <td>0.716183</td>\n",
       "      <td>01:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.314455</td>\n",
       "      <td>0.686778</td>\n",
       "      <td>0.309590</td>\n",
       "      <td>0.694796</td>\n",
       "      <td>01:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.327389</td>\n",
       "      <td>0.681139</td>\n",
       "      <td>0.295005</td>\n",
       "      <td>0.708897</td>\n",
       "      <td>01:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.312619</td>\n",
       "      <td>0.688272</td>\n",
       "      <td>0.288541</td>\n",
       "      <td>0.715252</td>\n",
       "      <td>02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.311811</td>\n",
       "      <td>0.693247</td>\n",
       "      <td>0.285123</td>\n",
       "      <td>0.718999</td>\n",
       "      <td>01:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.315462</td>\n",
       "      <td>0.693313</td>\n",
       "      <td>0.291981</td>\n",
       "      <td>0.711981</td>\n",
       "      <td>01:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.309631</td>\n",
       "      <td>0.695098</td>\n",
       "      <td>0.291293</td>\n",
       "      <td>0.712975</td>\n",
       "      <td>01:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.307992</td>\n",
       "      <td>0.696861</td>\n",
       "      <td>0.289799</td>\n",
       "      <td>0.714427</td>\n",
       "      <td>01:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.308711</td>\n",
       "      <td>0.695104</td>\n",
       "      <td>0.286699</td>\n",
       "      <td>0.717620</td>\n",
       "      <td>01:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.314454</td>\n",
       "      <td>0.692892</td>\n",
       "      <td>0.291867</td>\n",
       "      <td>0.712215</td>\n",
       "      <td>01:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.298577</td>\n",
       "      <td>0.706647</td>\n",
       "      <td>0.293397</td>\n",
       "      <td>0.711080</td>\n",
       "      <td>01:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.300769</td>\n",
       "      <td>0.700929</td>\n",
       "      <td>0.289429</td>\n",
       "      <td>0.714602</td>\n",
       "      <td>01:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.304785</td>\n",
       "      <td>0.701444</td>\n",
       "      <td>0.282959</td>\n",
       "      <td>0.721170</td>\n",
       "      <td>01:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.301686</td>\n",
       "      <td>0.706173</td>\n",
       "      <td>0.283115</td>\n",
       "      <td>0.720817</td>\n",
       "      <td>01:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.305535</td>\n",
       "      <td>0.699782</td>\n",
       "      <td>0.283415</td>\n",
       "      <td>0.720630</td>\n",
       "      <td>01:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.300290</td>\n",
       "      <td>0.708109</td>\n",
       "      <td>0.282834</td>\n",
       "      <td>0.721295</td>\n",
       "      <td>01:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.302831</td>\n",
       "      <td>0.702812</td>\n",
       "      <td>0.282753</td>\n",
       "      <td>0.721364</td>\n",
       "      <td>01:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.294040</td>\n",
       "      <td>0.710400</td>\n",
       "      <td>0.282817</td>\n",
       "      <td>0.721288</td>\n",
       "      <td>01:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.299739</td>\n",
       "      <td>0.706522</td>\n",
       "      <td>0.282867</td>\n",
       "      <td>0.721244</td>\n",
       "      <td>01:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_dice_score value: 0.0659150779247284.\n",
      "Better model found at epoch 1 with valid_dice_score value: 0.08964536339044571.\n",
      "Better model found at epoch 2 with valid_dice_score value: 0.12768332660198212.\n",
      "Better model found at epoch 3 with valid_dice_score value: 0.2042970210313797.\n",
      "Better model found at epoch 4 with valid_dice_score value: 0.2668862044811249.\n",
      "Better model found at epoch 5 with valid_dice_score value: 0.49615663290023804.\n",
      "Better model found at epoch 6 with valid_dice_score value: 0.5447778105735779.\n",
      "Better model found at epoch 9 with valid_dice_score value: 0.5584313273429871.\n",
      "Better model found at epoch 10 with valid_dice_score value: 0.5734764933586121.\n",
      "Better model found at epoch 13 with valid_dice_score value: 0.5997562408447266.\n",
      "Better model found at epoch 14 with valid_dice_score value: 0.6069093942642212.\n",
      "Better model found at epoch 16 with valid_dice_score value: 0.6202845573425293.\n",
      "Better model found at epoch 19 with valid_dice_score value: 0.628901481628418.\n",
      "Better model found at epoch 20 with valid_dice_score value: 0.6340592503547668.\n",
      "Better model found at epoch 22 with valid_dice_score value: 0.657429039478302.\n",
      "Better model found at epoch 27 with valid_dice_score value: 0.6710653305053711.\n",
      "Better model found at epoch 29 with valid_dice_score value: 0.6796982288360596.\n",
      "Better model found at epoch 33 with valid_dice_score value: 0.6852308511734009.\n",
      "Better model found at epoch 35 with valid_dice_score value: 0.6939594149589539.\n",
      "Better model found at epoch 36 with valid_dice_score value: 0.7062625288963318.\n",
      "Better model found at epoch 41 with valid_dice_score value: 0.7161829471588135.\n",
      "Better model found at epoch 45 with valid_dice_score value: 0.7189989686012268.\n",
      "Better model found at epoch 53 with valid_dice_score value: 0.7211704850196838.\n",
      "Better model found at epoch 56 with valid_dice_score value: 0.7212952971458435.\n",
      "Better model found at epoch 57 with valid_dice_score value: 0.721364438533783.\n"
     ]
    }
   ],
   "source": [
    "print(\"PRE learn.fit one cycle\")\n",
    "learn.fit_one_cycle(nepochs, 3e-3, wd = 1e-4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37f41385",
   "metadata": {},
   "outputs": [],
   "source": [
    "@delegates(subplots)\n",
    "def save_plot_metrics(self: Recorder, nrows=None, ncols=None, figsize=None, **kwargs):\n",
    "    metrics = np.stack(self.values)\n",
    "    # 'train_loss', 'train_dice_score', 'valid_loss', 'valid_dice_score'\n",
    "    names = self.metric_names[1:-1]\n",
    "    print(\"Metric names: \", names)\n",
    "    \n",
    "    names_train = [n for n in names if n.startswith(\"train\")]\n",
    "    n = len(names_train)\n",
    "    if nrows is None and ncols is None:\n",
    "        nrows = int(math.sqrt(n))\n",
    "        ncols = int(np.ceil(n / nrows))\n",
    "    elif nrows is None: nrows = int(np.ceil(n / ncols))\n",
    "    elif ncols is None: ncols = int(np.ceil(n / nrows))\n",
    "    figsize = (ncols * 6, nrows * 4)\n",
    "    fig, axs = subplots(nrows, ncols, figsize=figsize)\n",
    "    for i, ax in enumerate(axs):\n",
    "        name = names_train[i]\n",
    "        n = name[name.index(\"_\")+1:]\n",
    "        valid_name = f\"valid_{n}\"\n",
    "        valid_idx = names.index(valid_name)\n",
    "        print(i, valid_idx, name, valid_name)\n",
    "        ax.plot(metrics[:, i], color='#1f77b4',  label='train')\n",
    "        ax.plot(metrics[:, valid_idx], color = '#ff7f0e', label='valid')\n",
    "        ax.set_title(n)\n",
    "        ax.legend(loc='best')\n",
    "    #plt.show()\n",
    "    plt.savefig(f'{fig_src}/metrics.png', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec814eaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric names:  ['train_loss', 'train_dice_score', 'valid_loss', 'valid_dice_score']\n",
      "0 2 train_loss valid_loss\n",
      "1 3 train_dice_score valid_dice_score\n"
     ]
    }
   ],
   "source": [
    "save_plot_metrics(learn.recorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c0836bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_UNETR_loss_DICE_loss_full_res_96_pixdim_1.5_do_simple_False_do_flip_True_bs_2_epochs_60_time_1628683844_Wed_Aug_11_2021_hr_08_min_10\n"
     ]
    }
   ],
   "source": [
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b27d2017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not do_test:\n",
    "#     sys.stdout = old_stdout\n",
    "#     log_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4c295b",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683aaf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_tfms = [\n",
    "#     # normalize mean/std of foreground pixels\n",
    "#     ZScale(),\n",
    "#     # affine + flips\n",
    "#     RandomAffine(p=0.5, degrees=35, translate=0.1, scale=0.1),\n",
    "#     RandDihedral(p=0.5),\n",
    "#     # lighting\n",
    "#     RandBright(p=0.5),\n",
    "#     RandContrast(p=0.5),\n",
    "#     # noise for generalizability\n",
    "#     GNoise(p=0.5),\n",
    "#     GBlur(p=0.5),\n",
    "#     # add channel dim\n",
    "#     AddChannel()\n",
    "\n",
    "# UMich \n",
    "# code src: \"/home/labcomputer/Desktop/Rachel\"\n",
    "# data src: \"../../../../..//media/labcomputer/e33f6fe0-5ede-4be4-b1f2-5168b7903c7a/home/rachel/\"\n",
    "\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d1c877",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87db8dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Test\")\n",
    "# xb, yb = dls.one_batch()\n",
    "# xb, yb = xb.cpu(), yb.cpu()\n",
    "\n",
    "# pb = model.cpu()(xb)\n",
    "# print(xb.shape, pb.shape)\n",
    "# print(f\"logcosh dice loss {log_cosh_dice_loss(pb,yb)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cb367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test:\n",
    "\n",
    "# #dls.device = \"cpu\"\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# x,y = dls.one_batch()\n",
    "# #x,y = to_cpu(x), to_cpu(y)\n",
    "\n",
    "# pred = learn.model(x)\n",
    "# loss = learn.loss_func(pred, y)\n",
    "\n",
    "# elapsed = time.time() - start\n",
    "\n",
    "# print(f\"Elapsed: {elapsed} s\")\n",
    "# print(\"Batch: x,y\")\n",
    "# print(type(x), x.shape, x.dtype, \"\\n\", type(y), y.shape, y.dtype)\n",
    "\n",
    "# print(\"Pred shape\")\n",
    "# print(type(pred), pred.shape, pred.dtype)\n",
    "\n",
    "# print(\"Loss\")\n",
    "# print(loss)\n",
    "# print(learn.loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d6d220",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7930b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Viz\n",
    "\n",
    "# from helpers.viz        import viz_axis, viz_compare_inputs, viz_compare_outputs\n",
    "# from helpers.preprocess import mask2bbox\n",
    "# from helpers.general    import lrange\n",
    "\n",
    "# train_dl = TfmdDL(train_itemsd, after_item=train_tfms, after_batch=[], bs=3)\n",
    "\n",
    "# b = train_dl.one_batch()\n",
    "\n",
    "# xb,yb = b\n",
    "\n",
    "# print(\"shape xb yb\", xb.shape, yb.shape)\n",
    "\n",
    "# i = 2\n",
    "# mr = np.array(xb[i].squeeze().cpu())\n",
    "# mk = np.array(yb[i].squeeze().cpu())\n",
    "\n",
    "# bbox = mask2bbox(mk)\n",
    "\n",
    "# viz_axis(np_arr = mr, \\\n",
    "#     bin_mask_arr   = mk,     color1 = \"yellow\",  alpha1=0.3, \\\n",
    "#     slices=lrange(*bbox[0:2]), fixed_axis=0, \\\n",
    "#     axis_fn = np.rot90, \\\n",
    "#     title   = \"Axis 0\", \\\n",
    "\n",
    "#     np_arr_b = mr, \\\n",
    "#     bin_mask_arr_b   = mk,     color1_b = \"yellow\",  alpha1_b=0.3, \\\n",
    "#     slices_b = lrange(*bbox[2:4]), fixed_axis_b=1, \\\n",
    "#     title_b  = \"Axis 1\", \\\n",
    "\n",
    "#     np_arr_c = mr, \\\n",
    "#     bin_mask_arr_c   = mk,     color1_c = \"yellow\",  alpha1_c=0.3, \\\n",
    "#     slices_c = lrange(*bbox[4:6]), fixed_axis_c=2, \\\n",
    "#     title_c = \"Axis 2\", \\\n",
    "  \n",
    "# ncols = 5, hspace=0.3, fig_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bbc228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length  = len(items)\n",
    "# indices = np.arange(length)\n",
    "# np.random.shuffle(indices)\n",
    "# #rank0_first(lambda: np.random.shuffle(indices))\n",
    "\n",
    "# test_split   = int(test_frac  * length)\n",
    "# valid_split  = int(valid_frac * length) + test_split\n",
    "\n",
    "# test_idxs    = indices[:test_split] \n",
    "# valid_idxs   = indices[test_split:valid_split]\n",
    "# train_idxs   = indices[valid_split:]\n",
    "\n",
    "# train_items = [items[i] for i in train_idxs]\n",
    "# valid_items = [items[i] for i in valid_idxs]\n",
    "# test_items  = [items[i] for i in test_idxs]\n",
    "\n",
    "# # print\n",
    "# print(f\"Total  {len(items)} items in dataset.\")\n",
    "# print(f\"Train: {len(train_items)} items.\")\n",
    "# print(f\"Valid: {len(valid_items)} items.\")\n",
    "# print(f\"Test:  {len(test_items)} items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7501063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save test set indices\n",
    "# with open(f\"{data_src}/saved_dset_metadata/split_train_valid_test.pkl\", 'wb') as f:\n",
    "#     pickle.dump([train_idxs, valid_idxs, test_idxs, train_items, valid_items, test_items], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702c1a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test get one batch\n",
    "# time_one_batch(dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846e03de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Viz\n",
    "\n",
    "# from helpers.viz        import viz_axis, viz_compare_inputs, viz_compare_outputs\n",
    "# from helpers.preprocess import mask2bbox\n",
    "# from helpers.general    import lrange\n",
    "\n",
    "# train_dl = TfmdDL(train_itemsd, after_item=train_tfms, after_batch=[], bs=3)\n",
    "\n",
    "# b = train_dl.one_batch()\n",
    "\n",
    "# xb,yb = b\n",
    "\n",
    "# print(\"shape xb yb\", xb.shape, yb.shape)\n",
    "\n",
    "# i = 2\n",
    "# mr = np.array(xb[i].squeeze().cpu())\n",
    "# mk = np.array(yb[i].squeeze().cpu())\n",
    "\n",
    "# bbox = mask2bbox(mk)\n",
    "\n",
    "# viz_axis(np_arr = mr, \\\n",
    "#     bin_mask_arr   = mk,     color1 = \"yellow\",  alpha1=0.3, \\\n",
    "#     slices=lrange(*bbox[0:2]), fixed_axis=0, \\\n",
    "#     axis_fn = np.rot90, \\\n",
    "#     title   = \"Axis 0\", \\\n",
    "\n",
    "#     np_arr_b = mr, \\\n",
    "#     bin_mask_arr_b   = mk,     color1_b = \"yellow\",  alpha1_b=0.3, \\\n",
    "#     slices_b = lrange(*bbox[2:4]), fixed_axis_b=1, \\\n",
    "#     title_b  = \"Axis 1\", \\\n",
    "\n",
    "#     np_arr_c = mr, \\\n",
    "#     bin_mask_arr_c   = mk,     color1_c = \"yellow\",  alpha1_c=0.3, \\\n",
    "#     slices_c = lrange(*bbox[4:6]), fixed_axis_c=2, \\\n",
    "#     title_c = \"Axis 2\", \\\n",
    "  \n",
    "# ncols = 5, hspace=0.3, fig_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c852fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length  = len(items)\n",
    "# indices = np.arange(length)\n",
    "# np.random.shuffle(indices)\n",
    "# #rank0_first(lambda: np.random.shuffle(indices))\n",
    "\n",
    "# test_split   = int(test_frac  * length)\n",
    "# valid_split  = int(valid_frac * length) + test_split\n",
    "\n",
    "# test_idxs    = indices[:test_split] \n",
    "# valid_idxs   = indices[test_split:valid_split]\n",
    "# train_idxs   = indices[valid_split:]\n",
    "\n",
    "# train_items = [items[i] for i in train_idxs]\n",
    "# valid_items = [items[i] for i in valid_idxs]\n",
    "# test_items  = [items[i] for i in test_idxs]\n",
    "\n",
    "# # print\n",
    "# print(f\"Total  {len(items)} items in dataset.\")\n",
    "# print(f\"Train: {len(train_items)} items.\")\n",
    "# print(f\"Valid: {len(valid_items)} items.\")\n",
    "# print(f\"Test:  {len(test_items)} items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46429e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe42690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
