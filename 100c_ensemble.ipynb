{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unable-instruction",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "This notebook checks model generalization performance on other dsets.\n",
    "\n",
    "**With gratitude to**:\n",
    "- https://github.com/mattiaspaul/OBELISK\n",
    "-  https://github.com/kbressem/faimed3d/blob/main/examples/3d_segmentation.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "832446de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Full lbl items: 335\n",
      "Removed 2 weird, new total lbl items: 333\n",
      "train, valid, test 201 66 66 total 333\n",
      "Cross label items:  418\n",
      "All label items:  751 (abide (333) + cross_lbl (418))\n",
      "Test label items:  484 (test (66) + cross_lbl (418))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from fastai              import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.basics       import *\n",
    "from fastai.distributed  import *\n",
    "\n",
    "from helpers.general            import get_param, rm_prefix, modelfn2dict\n",
    "from helpers.model_loss_choices import get_model, get_loss\n",
    "from helpers.items_constants import *\n",
    "from helpers.transforms_simplified import get_train_valid_transforms, monai_tfms2str\n",
    "\n",
    "# Learner\n",
    "import gc\n",
    "gc.collect()\n",
    "from helpers.losses import dice_score\n",
    "from helpers.general            import get_param\n",
    "from helpers.transforms_simplified import *\n",
    "from helpers.model_loss_choices import get_model, get_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f435cfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_ensemble = [\n",
    "    # UNET DICE, VNET DICE, UNET BCE, VNET BCE, OBELISK DICE, OBELISK BCE, CONDSEG DICE, CONDSEG BCE\n",
    "    \"model_UNET3D_loss_DICE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1627971508_Tue_Aug_03_2021_hr_02_min_18\",\n",
    "    \"model_VNET_loss_DICE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1627978137_Tue_Aug_03_2021_hr_04_min_08\",\n",
    "    \"model_UNET3D_loss_BCE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1627971506_Tue_Aug_03_2021_hr_02_min_18\",\n",
    "    \"model_VNET_loss_BCE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1627978233_Tue_Aug_03_2021_hr_04_min_10\",\n",
    "    \"model_OBELISKHYBRID_loss_DICE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1627963440_Tue_Aug_03_2021_hr_00_min_04\",\n",
    "    \"model_OBELISKHYBRID_loss_BCE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1627963631_Tue_Aug_03_2021_hr_00_min_07\",\n",
    "#     \"model_CONDSEG_loss_DICE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1628097973_Wed_Aug_04_2021_hr_13_min_26\",\n",
    "#     \"model_CONDSEG_loss_BCE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1628097978_Wed_Aug_04_2021_hr_13_min_26\"\n",
    "]\n",
    "\n",
    "# items\n",
    "items = all_test_lbl_items #ppmi, icmb, adni, aibl, abvib, test_items\n",
    "itemsd = getd(items)\n",
    "\n",
    "# get dices, worst indexes\n",
    "post_df_dict     = {}\n",
    "worst_index_dict = {}\n",
    "\n",
    "for done_fn in models_to_ensemble:\n",
    "    model_name = Path(done_fn).name\n",
    "    model_src = f\"{run_src}/{model_name}\"\n",
    "    check_post_df  = pd.read_pickle(f\"{model_src}/post_lcc_df.pkl\")\n",
    "    check_pre_df   = pd.read_pickle(f\"{model_src}/pre_lcc_df.pkl\")\n",
    "    \n",
    "    post_df_dict[model_name] = check_post_df\n",
    "    \n",
    "    # sort 5 worst idxs + DICE\n",
    "    n_worst = 5\n",
    "    dices = check_post_df[\"dice\"].values\n",
    "    worst_idxs = sorted(range(len(dices)), key=lambda x: dices[x])[:n_worst]\n",
    "    worst_dices = [dices[x] for x in worst_idxs]\n",
    "    worst_index_dict[model_name] = {\"idxs\": worst_idxs, \"dices\": worst_dices}\n",
    "    \n",
    "    if len(check_post_df) != len(itemsd):\n",
    "        print(done_fn)\n",
    "        print(\"Len\", len(check_post_df))\n",
    "        print(\"*\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baaee747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/237079/how-to-get-file-creation-modification-date-times-in-python\n",
    "import os, time\n",
    "def creation_date(file):\n",
    "    \"\"\"\n",
    "    Try to get the date that a file was created, falling back to when it was\n",
    "    last modified if that isn't possible.\n",
    "    See http://stackoverflow.com/a/39501288/1709587 for explanation.\n",
    "    \"\"\"\n",
    "    print(\"last modified: %s\" % time.ctime(os.path.getmtime(file)))\n",
    "    print(\"created: %s\" % time.ctime(os.path.getctime(file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58af370b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last modified: Fri Aug  6 13:00:35 2021\n",
      "created: Fri Aug  6 13:00:35 2021\n"
     ]
    }
   ],
   "source": [
    "creation_date(f\"{run_src}/{models_to_ensemble[0]}/post_lcc_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cb115e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_UNET3D_loss_DICE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1627971508_Tue_Aug_03_2021_hr_02_min_18': {'idxs': [229,\n",
       "   79,\n",
       "   276,\n",
       "   227,\n",
       "   283],\n",
       "  'dices': [0.4157860469775129,\n",
       "   0.5679616129925256,\n",
       "   0.5870066458700665,\n",
       "   0.6121827004050207,\n",
       "   0.6181390061708346]},\n",
       " 'model_VNET_loss_DICE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1627978137_Tue_Aug_03_2021_hr_04_min_08': {'idxs': [229,\n",
       "   79,\n",
       "   397,\n",
       "   114,\n",
       "   99],\n",
       "  'dices': [0.4520469510449471,\n",
       "   0.5520037278657969,\n",
       "   0.5597326649958229,\n",
       "   0.5767521750494754,\n",
       "   0.5960908946448434]},\n",
       " 'model_UNET3D_loss_BCE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1627971506_Tue_Aug_03_2021_hr_02_min_18': {'idxs': [229,\n",
       "   79,\n",
       "   266,\n",
       "   99,\n",
       "   197],\n",
       "  'dices': [0.40389004664086525,\n",
       "   0.5387131952017448,\n",
       "   0.5927826426459926,\n",
       "   0.5998751950078003,\n",
       "   0.6112254945841912]},\n",
       " 'model_VNET_loss_BCE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1627978233_Tue_Aug_03_2021_hr_04_min_10': {'idxs': [229,\n",
       "   79,\n",
       "   283,\n",
       "   99,\n",
       "   94],\n",
       "  'dices': [0.4088873725958463,\n",
       "   0.56047197640118,\n",
       "   0.5900948366701791,\n",
       "   0.6003208253389111,\n",
       "   0.6027627035027134]},\n",
       " 'model_OBELISKHYBRID_loss_DICE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1627963440_Tue_Aug_03_2021_hr_00_min_04': {'idxs': [251,\n",
       "   235,\n",
       "   229,\n",
       "   227,\n",
       "   397],\n",
       "  'dices': [0.23743652600245144,\n",
       "   0.4502643350955673,\n",
       "   0.4575065947929809,\n",
       "   0.48443193874256196,\n",
       "   0.49251457687660877]},\n",
       " 'model_OBELISKHYBRID_loss_BCE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1627963631_Tue_Aug_03_2021_hr_00_min_07': {'idxs': [221,\n",
       "   235,\n",
       "   251,\n",
       "   260,\n",
       "   233],\n",
       "  'dices': [0.0, 0.0, 0.0, 0.20576252883718646, 0.21237571194130705]}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst_index_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb09a7f",
   "metadata": {},
   "source": [
    "# Worst dice for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bef3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indexes = [a for model in models_to_ensemble for a in worst_index_dict[model][\"idxs\"]]\n",
    "print(len(all_indexes), len(set(all_indexes)), all_indexes)\n",
    "\n",
    "set_all_indexes = set(all_indexes)\n",
    "\n",
    "repeated_indexes = [a for a in set_all_indexes if all_indexes.count(a) > 1]\n",
    "s = [f\"#repeats = {all_indexes.count(a)-1} idx {a}\" for a in repeated_indexes]\n",
    "print(\"repeated: n, which is: \", len(repeated_indexes), *s, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c5db8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in set_all_indexes:\n",
    "    print(f\"idx {i}\", [round(post_df_dict[model].dice[i],2) for model in models_to_ensemble]); print(\"*\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f7cddb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ensemble vote: 6 models on 30 items => 180 model/item\n",
    "\n",
    "num_workers = 2\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# items\n",
    "items_todo   = [itemsd[i] for i in set_all_indexes]\n",
    "train_itemsd = getd(train_items) # for condseg atlas choice\n",
    "\n",
    "# preds\n",
    "model_preds_dict = {}\n",
    "\n",
    "for model_fn in models_to_ensemble:\n",
    "    start_small = time.time()\n",
    "    \n",
    "    # get params\n",
    "    model_name = Path(model_fn).name\n",
    "    model_dict = modelfn2dict(model_fn)\n",
    "    print(model_fn, model_dict)\n",
    "    \n",
    "    model_type, loss_type, full_res, pixdim, do_flip, do_simple = \\\n",
    "        [model_dict[k] for k in (\"model_type\", \"loss_type\", \"full_res\", \"pixdim\", \"do_flip\", \"do_simple\")]\n",
    "    \n",
    "    # get model\n",
    "    model   = get_model(model_type, full_res)\n",
    "    loss_fn = get_loss(loss_type) \n",
    "    \n",
    "    # get transforms\n",
    "    print(f\"{model_type}, {loss_type}, res {full_res} simple augs {do_simple} flip {do_flip} weird {not do_simple and not do_flip}\")\n",
    "    _, val_tfms = get_train_valid_transforms(items=train_itemsd, pixdim=pixdim, full_res=full_res, \n",
    "                                                  do_flip=do_flip, do_simple=do_simple, do_condseg=(model_type==\"CONDSEG\"))\n",
    "\n",
    "    # deactivate autograd engine and reduce memory usage and speed up computations\n",
    "    data = Pipeline(val_tfms)(items_todo)\n",
    "    inputs, labels = zip(*data) # [(img,lbl), (img,lbl)] => imgs, labels\n",
    "    inputs = torch.stack(inputs, dim=0)\n",
    "    labels = torch.stack(labels, dim=0)\n",
    "    inputs = inputs.to(device)\n",
    "    print(\"inputs\", inputs.shape, \"labels\", labels.shape)\n",
    "    \n",
    "    # tls, dls, cuda\n",
    "    bs  = 1\n",
    "    tls = TfmdLists(items_todo, val_tfms)\n",
    "    dls = tls.dataloaders(bs=bs, after_batch=[], num_workers=num_workers, drop_last=False)\n",
    "\n",
    "    if not str(device)==\"cpu\":\n",
    "        dls = dls.cuda()\n",
    "    \n",
    "    learn = Learner(dls       = dls, \n",
    "                    model     = model, \n",
    "                    loss_func = loss_fn,\n",
    "                    metrics   = dice_score)\n",
    "\n",
    "    # load model fname w/o .pth extension\n",
    "    learn.load(f\"{run_src}/{model_name}/model\")\n",
    "    learn.model = learn.model.to(device)\n",
    "        \n",
    "    # set model to evaluate model\n",
    "    learn.model.eval()\n",
    "\n",
    "    # print(\"before no grad\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs).cpu()\n",
    "\n",
    "    model_preds_dict[model_fn] = (labels, outputs)\n",
    "\n",
    "    # clean up memory\n",
    "    del inputs\n",
    "    del labels\n",
    "    del outputs\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    if str(device) != \"cpu\":\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        # print_hardware_stats()\n",
    "\n",
    "    elapsed_small = time.time() - start_small\n",
    "    print(f\"Elapsed: {elapsed_small:0.2f} s\")\n",
    "\n",
    "        # break\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"Elapsed: {elapsed:0.2f} s for {len(itemsd)} items.\")\n",
    "# y_true = y_true.cpu().numpy()  \n",
    "# _, y_pred = torch.max(all_outputs, 1)\n",
    "# y_pred = y_pred.cpu().numpy()\n",
    "# y_pred_prob = F.softmax(all_outputs, dim=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f8f523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import VoteEnsemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e33b538",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_preds_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(model_preds_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a382c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model_preds_dict.pickle\", \"rb\") as f:\n",
    "    model_preds_dict  = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337d46d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lbls, all_preds = zip(*[model_preds_dict[model_fn] for model_fn in models_to_ensemble])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a9c751",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6913748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble_preds[0] = 0th item, all 6 model preds for item 0\n",
    "ensemble_preds = [[pred[i] for pred in all_preds] for i in range(len(set_all_indexes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb540ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds[0].shape, len(ensemble_preds[0]), ensemble_preds[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914981cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get majority vote\n",
    "from helpers.postprocess import get_largest_connected_component, torch2sitk, sitk2torch, eval_measure\n",
    "\n",
    "# 6 preds for given label ==> max dice pre, ensemble dice\n",
    "def get_majority_vote(label, all_preds):\n",
    "    label      = torch2sitk(label.squeeze(0).byte())\n",
    "    preds_lcc  = [get_largest_connected_component(torch2sitk(pred.argmax(0).byte())) for pred in all_preds]\n",
    "        \n",
    "    labelForUndecidedPixels = 0\n",
    "    majority_vote = sitk.LabelVoting(preds_lcc, labelForUndecidedPixels)\n",
    "        \n",
    "    # get metrics\n",
    "    majority_metrics = eval_measure(label, majority_vote)\n",
    "    indiv_metrics = [eval_measure(label, pred_lcc) for pred_lcc in preds_lcc]\n",
    "    \n",
    "    return majority_metrics, indiv_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881b7bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ensemble_preds)):\n",
    "    majority_metric, indiv_metrics = get_majority_vote(all_lbls[0][i], ensemble_preds[i])\n",
    "    indiv_metric_dices = [d[\"dice\"] for d in indiv_metrics]\n",
    "    best_indiv_metric   = indiv_metrics[np.argmax(indiv_metric_dices)]\n",
    "    worst_indiv_metric  = indiv_metrics[np.argmin(indiv_metric_dices)]\n",
    "\n",
    "    print(i, f\"idx {list(set_all_indexes)[i]}\")\n",
    "    print(majority_metric)\n",
    "    print(best_indiv_metric)\n",
    "    print(worst_indiv_metric)\n",
    "    print(\"*\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bf01ae",
   "metadata": {},
   "source": [
    "# Save all preds ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def55d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4483f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb65a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14edc671",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56e0fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "indiv_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5661bfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_indiv_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef34334a",
   "metadata": {},
   "outputs": [],
   "source": [
    "indiv_metric_dices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d321368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 200 secs for, 20 secs per\n",
    "\n",
    "model_preds_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0535bef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array([1,2,78,10,3,4,-2,5,20,15,6])\n",
    "# idxs = sorted(range(len(a)), key=lambda x: a[x])\n",
    "# print(idxs)\n",
    "# print(np.argpartition(a, 5))\n",
    "# print([a[x] for x in idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9f582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stats\n",
    "\n",
    "from helpers.general            import get_param, rm_prefix\n",
    "from helpers.model_loss_choices import get_model, get_loss\n",
    "\n",
    "post_df_dict = {}\n",
    "\n",
    "for done_fn in models_to_ensemble:\n",
    "    model_name = Path(done_fn).name\n",
    "    #print(model_name)\n",
    "    model_src = f\"{run_src}/{model_name}\"\n",
    "    check_post_df  = pd.read_pickle(f\"{model_src}/post_lcc_df.pkl\")\n",
    "    check_pre_df   = pd.read_pickle(f\"{model_src}/pre_lcc_df.pkl\")\n",
    "    #check_stats_df = pd.read_pickle(f\"{model_src}/stats_df.pkl\")\n",
    "    \n",
    "    #check_stats_df = check_stats_df.style.set_caption(f\"{model_name}\")\n",
    "\n",
    "    post_df_dict[model_name] = check_post_df\n",
    "    \n",
    "    if len(check_post_df) != len(itemsd):\n",
    "        print(done_fn)\n",
    "        print(\"Len\", len(check_post_df))\n",
    "        print(\"*\" * 50)\n",
    "    #display(check_post_df)\n",
    "    #display(check_pre_df)\n",
    "    #display(check_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96548c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_task:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "\n",
    "# INFERENCE DATALOADER PARAMS\n",
    "num_workers = 1\n",
    "\n",
    "# ITEMS\n",
    "\n",
    "from pathlib import Path\n",
    "from helpers.items_constants import *\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import pandas as pd\n",
    "\n",
    "dsets_src    = f\"{data_src}/PitMRdata\"\n",
    "\n",
    "# key,val = dset_name, path to top level dir\n",
    "dset_dict = {\n",
    "    \"ABIDE\"                  : f\"{dsets_src}/ABIDE\",\n",
    "    \"ABVIB\"                  : f\"{dsets_src}/ABVIB/ABVIB\",\n",
    "    \"ADNI1_Complete_1Yr_1.5T\": f\"{dsets_src}/ADNI/ADNI1_Complete_1Yr_1.5T/ADNI\",\n",
    "    \"AIBL\"                   : f\"{dsets_src}/AIBL/AIBL\",\n",
    "    \"ICMB\"                   : f\"{dsets_src}/ICMB/ICBM\",\n",
    "    \"PPMI\"                   : f\"{dsets_src}/PPMI/PPMI\",\n",
    "}\n",
    "\n",
    "ppmi  = [i for i in cross_lbl_items if dset_dict[\"PPMI\"] in i[0]]\n",
    "icmb = [i for i in cross_lbl_items if \"ICMB\" in i[1]]\n",
    "adni = [i for i in cross_lbl_items if \"ADNI1_full\" in i[1]]\n",
    "aibl = [i for i in cross_lbl_items if \"AIBL\" in i[1]]\n",
    "abvib = [i for i in cross_lbl_items if \"ABVIB\" in i[1]]\n",
    "\n",
    "# print(len(ppmi))\n",
    "# print(len(icmb))\n",
    "# print(len(adni))\n",
    "# print(len(aibl))\n",
    "# print(len(abvib))\n",
    "# print(len(test_items), len(valid_items), len(train_items))\n",
    "print(len(cross_lbl_items))\n",
    "print(len(ppmi)+len(icmb)+len(adni)+len(aibl)+len(abvib))\n",
    "print(len(all_test_lbl_items))\n",
    "print(len(cross_lbl_items)+len(test_items))\n",
    "\n",
    "# Items as dict \n",
    "from pathlib import Path\n",
    "from helpers.items_constants import *\n",
    "\n",
    "#items  = all_test_lbl_items\n",
    "items = all_test_lbl_items #ppmi, icmb, adni, aibl, abvib, test_items\n",
    "itemsd = getd(items)\n",
    "\n",
    "# print(f\"n = {len(itemsd)}, test items = {len(test_items)}, other dsets = {len(cross_lbl_items)}\")\n",
    "# print(f\"first item\", itemsd[0])\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "# print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff5225c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for model_fn in model_fns:\n",
    "#     if os.path.isfile(f\"{model_fn}/post_lcc_df.pkl\"):\n",
    "#         print(model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ade0868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1daca0fd",
   "metadata": {},
   "source": [
    "# Choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0361050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helpers.general            import get_param\n",
    "# from helpers.model_loss_choices import get_model, get_loss\n",
    "\n",
    "# model_fns = sorted(Path(run_src).iterdir(), key=os.path.getmtime, reverse=True)\n",
    "# todo = [str(model_fn) \n",
    "#         for model_fn in model_fns \n",
    "#         if not os.path.isfile(f\"{str(model_fn)}/post_lcc_df.pkl\") and \"Mon_Aug_02\" in str(model_fn)\n",
    "#        ]\n",
    "\n",
    "# print(\"TODO: \", len(todo))\n",
    "\n",
    "# # params\n",
    "# def get_param_default(name, prefix, suffix, default):\n",
    "#     try:\n",
    "#         return get_param(name, prefix, suffix)\n",
    "#     except:\n",
    "#         return default\n",
    "\n",
    "# for model_fn in todo:\n",
    "#     model_name = Path(model_fn).name\n",
    "\n",
    "#     model_type = get_param(model_name, \"model_\", \"_loss\")\n",
    "\n",
    "#     if \"loss_bs\" in model_name:\n",
    "#         loss_type  = get_param(model_name, \"loss_\", \"_bs\")\n",
    "#     else:\n",
    "#         loss_type  = get_param(model_name, \"loss_\", \"_full_res\")\n",
    "\n",
    "#     full_res   = get_param_default(model_name, \"full_res_\", \"_pixdim\", 96)\n",
    "#     pixdim     = get_param_default(model_name, \"pixdim_\", \"_do_simple\", 1.5)\n",
    "#     do_simple  = get_param_default(model_name, \"do_simple_\", \"_do_flip\", False)\n",
    "#     do_flip    = get_param_default(model_name, \"do_flip_\", \"_bs\", True)\n",
    "\n",
    "#     # tuple\n",
    "#     pixdim    = tuple(float(pixdim) for _ in range(3))\n",
    "#     full_res  = tuple(int(full_res) for _ in range(3))\n",
    "\n",
    "#     # bool\n",
    "#     do_flip   = do_flip == \"True\"\n",
    "#     do_simple = do_simple == \"True\"\n",
    "\n",
    "#     print(f\"Model Name: {model_name}\")\n",
    "#     print(f\"Model: {model_type}\")\n",
    "#     print(f\"Loss : {loss_type}\")\n",
    "#     print(f\"Pixd : {pixdim}\")\n",
    "#     print(f\"Fullres : {full_res}\")\n",
    "#     print(f\"Do flip: {do_flip}\")\n",
    "#     print(f\"Do simple: {do_simple}\")\n",
    "    \n",
    "#     print(\"*\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66cc419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.general            import get_param, get_param_default\n",
    "from helpers.model_loss_choices import get_model, get_loss\n",
    "\n",
    "model_fns = sorted(Path(run_src).iterdir(), key=os.path.getmtime, reverse=True)\n",
    "todo = [str(model_fn) \n",
    "        for model_fn in model_fns \n",
    "        if (not os.path.isfile(f\"{str(model_fn)}/post_lcc_df.pkl\") and \\\n",
    "                (os.path.isfile(f\"{str(model_fn)}/figs/metrics.png\")) and \\\n",
    "                (\"Mon_Aug_02\" in str(model_fn) or \"Aug_03\" in str(model_fn) or \"Aug_04\" in str(model_fn))\n",
    "            )\n",
    "       ]\n",
    "\n",
    "print(\"TODO: \", len(todo))\n",
    "\n",
    "model_idx  = taskid\n",
    "model_name = Path(todo[model_idx]).name\n",
    "print(f\"Chosen: {model_name} (idx {model_idx})\")\n",
    "\n",
    "\n",
    "\n",
    "model_type = get_param(model_name, \"model_\", \"_loss\")\n",
    "\n",
    "if \"loss_bs\" in model_name:\n",
    "    loss_type  = get_param(model_name, \"loss_\", \"_bs\")\n",
    "else:\n",
    "    loss_type  = get_param(model_name, \"loss_\", \"_full_res\")\n",
    "    \n",
    "full_res   = get_param_default(model_name, \"full_res_\", \"_pixdim\", 96)\n",
    "pixdim     = get_param_default(model_name, \"pixdim_\", \"_do_simple\", 1.5)\n",
    "do_simple  = get_param_default(model_name, \"do_simple_\", \"_do_flip\", False)\n",
    "do_flip    = get_param_default(model_name, \"do_flip_\", \"_bs\", True)\n",
    "\n",
    "# tuple\n",
    "pixdim    = tuple(float(pixdim) for _ in range(3))\n",
    "full_res  = tuple(int(full_res) for _ in range(3))\n",
    "\n",
    "# bool\n",
    "do_flip   = do_flip == \"True\"\n",
    "do_simple = do_simple == \"True\"\n",
    "\n",
    "print(f\"Model: {model_type}\")\n",
    "print(f\"Loss : {loss_type}\")\n",
    "print(f\"Pixd : {pixdim}\")\n",
    "print(f\"Fullres : {full_res}\")\n",
    "print(f\"Do flip: {do_flip}\")\n",
    "print(f\"Do simple: {do_simple}\")\n",
    "\n",
    "#model_fn = \"OBELISKHYBRID_log_cosh_dice_loss_iso_2mm_pad_144_144_144_bs_2_test_sz_67_epochs_30_time_1626043621_Sun_Jul_07_2021_hr_18_min_47.pth\"\n",
    "# model_idx = 3\n",
    "# model_name   = Path(model_fns[model_idx]).name\n",
    "# print(f\"Chosen: {model_name}\")\n",
    "# print(f\"Prior: \", *[f\"{idx}: {model_fn[len(run_src):]}\" for idx,model_fn in enumerate(model_fns[:5])], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504cd95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in todo:\n",
    "    model_name2 = Path(fn).name\n",
    "    model_type2 = get_param(model_name2, \"model_\", \"_loss\")\n",
    "\n",
    "    if \"loss_bs\" in model_name:\n",
    "        loss_type2  = get_param(model_name2, \"loss_\", \"_bs\")\n",
    "    else:\n",
    "        loss_type2  = get_param(model_name2, \"loss_\", \"_full_res\")\n",
    "\n",
    "    full_res2   = get_param_default(model_name2, \"full_res_\", \"_pixdim\", 96)\n",
    "    pixdim2     = get_param_default(model_name2, \"pixdim_\", \"_do_simple\", 1.5)\n",
    "    do_simple2  = get_param_default(model_name2, \"do_simple_\", \"_do_flip\", False)\n",
    "    do_flip2    = get_param_default(model_name2, \"do_flip_\", \"_bs\", True)\n",
    "\n",
    "    print(model_type2, loss_type2, \"simple augs: \", do_simple2, \"flip\", do_flip2, \"pixdim\", pixdim2, \"full_res\", full_res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d470e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helpers.general import rm_prefix\n",
    "\n",
    "# # check\n",
    "# done = [str(model_fn) \n",
    "#         for model_fn in model_fns \n",
    "#         if os.path.isfile(f\"{str(model_fn)}/post_lcc_df.pkl\") and \"Aug_03\" in str(model_fn)\n",
    "#        ]\n",
    "# #print(*rm_prefix(done, prefix=run_src, do_sort=True), sep=\"\\n\")\n",
    "# print(f\"DONE: {len(done)}\")\n",
    "\n",
    "# for done_fn in done:\n",
    "#     model_name = Path(done_fn).name\n",
    "#     #print(model_name)\n",
    "#     model_src = f\"{run_src}/{model_name}\"\n",
    "#     check_post_df  = pd.read_pickle(f\"{model_src}/post_lcc_df.pkl\")\n",
    "#     check_pre_df   = pd.read_pickle(f\"{model_src}/pre_lcc_df.pkl\")\n",
    "#     check_stats_df = pd.read_pickle(f\"{model_src}/stats_df.pkl\")\n",
    "    \n",
    "#     if len(check_post_df) != len(itemsd):\n",
    "#         print(done_fn)\n",
    "#         print(\"Len\", len(check_post_df))\n",
    "#         print(\"*\" * 50)\n",
    "#     #display(check_post_df)\n",
    "#     #display(check_pre_df)\n",
    "#     #display(check_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45c907d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.general import rm_prefix\n",
    "# print(*rm_prefix(todo, prefix=run_src), sep=\"\\n\")\n",
    "print(*rm_prefix(todo, prefix=run_src, do_sort=True), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ce1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import shutil\n",
    "#print(os.path.isfile(f\"{model_fns[0]}/model.pth\"))\n",
    "#shutil.rmtree(model_fns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4ac469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# for i,fn in enumerate(model_fns):\n",
    "#     if not os.path.isfile(f\"{fn}/model.pth\"):\n",
    "#         print(i,fn)\n",
    "#         shutil.rmtree(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c6382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Choices\n",
    "\n",
    "# if not do_task:\n",
    "#     model_names = {\n",
    "#         # pixdim 1.5, full_res 96\n",
    "#         \"unet_bce\": \"model_UNET3D_loss_BCE_loss_bs_1_epochs_60_time_1627647477_Fri_Jul_30_2021_hr_08_min_17\",\n",
    "#         \"obelisk_bce\": \"model_OBELISKHYBRID_loss_BCE_loss_bs_1_epochs_60_time_1627823459_Sun_Aug_01_2021_hr_09_min_10\",\n",
    "#         \"vnet_bce\": \"model_VNET_loss_BCE_loss_bs_1_epochs_60_time_1627823149_Sun_Aug_01_2021_hr_09_min_05\",\n",
    "#         \"unetr_bce\": \"model_UNETR_loss_BCE_loss_bs_1_epochs_60_time_1627830873_Sun_Aug_01_2021_hr_11_min_14\",\n",
    "\n",
    "#         \"obelisk_bce_144\": \"model_OBELISKHYBRID_loss_BCE_loss_bs_1_epochs_60_time_1627865816_Sun_Aug_01_2021_hr_20_min_56\",\n",
    "#         \"obelisk_dice_144\": \"model_OBELISKHYBRID_loss_DICE_loss_bs_1_epochs_60_time_1627865811_Sun_Aug_01_2021_hr_20_min_56\",\n",
    "#     }\n",
    "\n",
    "#     model_name = model_names[\"obelisk_dice_144\"]\n",
    "#     full_res = 144\n",
    "#     pixdim   = 1.0\n",
    "#     do_flip = True\n",
    "\n",
    "#     full_res = tuple(full_res for _ in range(3))\n",
    "#     pixdim   = tuple(pixdim   for _ in range(3))\n",
    "\n",
    "#     print(f\"Full res: {full_res}, Pixdim: {pixdim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42b2d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear cache\n",
    "import gc\n",
    "from helpers.general import print_hardware_stats\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "if not str(device)==\"cpu\":\n",
    "    torch.cuda.empty_cache()\n",
    "    print_hardware_stats()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c2c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms\n",
    "\n",
    "from helpers.transforms_simplified import get_train_valid_transforms, monai_tfms2str\n",
    "\n",
    "train_tfms, val_tfms = get_train_valid_transforms_simple(pixdim=pixdim, full_res=full_res, do_flip=do_flip, items=train_itemsd)\n",
    "else:\n",
    "    train_tfms, val_tfms = get_train_valid_transforms(pixdim=pixdim, full_res=full_res, do_flip=do_flip)\n",
    "    \n",
    "print(f\"val tfms: \", *val_tfms.transforms, sep=\"\\n\")\n",
    "\n",
    "\n",
    "from helpers.general            import get_param\n",
    "from helpers.model_loss_choices import get_model, get_loss\n",
    "\n",
    "model   = get_model(model_type, full_res)\n",
    "loss_fn = get_loss(loss_type) \n",
    "\n",
    "# print\n",
    "print(\"Model name: \", model_name)\n",
    "print(f\"Model type: {model_type}. Loss type: {loss_type}.\")\n",
    "# Dataloaders\n",
    "\n",
    "# Fastai + distributed training\n",
    "from fastai              import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.basics       import *\n",
    "from fastai.distributed  import *\n",
    "\n",
    "# time it - 18s for 484 items\n",
    "start = time.time()\n",
    "\n",
    "# tls, dls, cuda\n",
    "bs  = 5\n",
    "tls = TfmdLists(itemsd, val_tfms)\n",
    "dls = tls.dataloaders(bs=bs, after_batch=[], num_workers=num_workers, drop_last=False)\n",
    "\n",
    "if not str(device)==\"cpu\":\n",
    "    dls = dls.cuda()\n",
    "\n",
    "# end timer\n",
    "elapsed = time.time() - start\n",
    "print(f\"Elapsed time: {elapsed:.2f} s for {len(itemsd)} items\")\n",
    "\n",
    "# Learner\n",
    "import gc\n",
    "gc.collect()\n",
    "from helpers.losses import dice_score\n",
    "learn = Learner(dls       = dls, \n",
    "                model     = model, \n",
    "                loss_func = loss_fn,\n",
    "                metrics   = dice_score)\n",
    "\n",
    "# load model fname w/o .pth extension\n",
    "learn.load(f\"{run_src}/{model_name}/model\")\n",
    "\n",
    "if not str(device)==\"cpu\":\n",
    "    learn.model = learn.model.cuda()\n",
    "else:\n",
    "    learn.model = learn.model.to(device)\n",
    "#learn.model.eval()\n",
    "\n",
    "# all predictions, 67 items, 4 workers, 15sec\n",
    "# Elapsed: 326.07 s for 484 items.\n",
    "# start = time.time()\n",
    "\n",
    "# predictions = []\n",
    "# targets     = []\n",
    "# val_batch_iter = iter(dls.train)\n",
    "# for n in range(int(len(itemsd[:20]) / bs)):\n",
    "#     xb,yb = next(val_batch_iter)\n",
    "#     preds = learn.model(xb.cpu())\n",
    "#     predictions.append(preds)\n",
    "#     targets.append(yb.cpu())\n",
    "#     break\n",
    "    \n",
    "# #predictions, targets = learn.get_preds(dl=dls.train)\n",
    "# elapsed = time.time() - start\n",
    "\n",
    "# print(f\"Elapsed: {elapsed:0.2f} s for {len(itemsd)} items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561e8185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 6\n",
    "# data = dls.train_ds[i]\n",
    "# #print(data[0].shape, data[1].shape)\n",
    "# # print(mask2bbox(np.asarray(data[1].squeeze(0))))\n",
    "\n",
    "# # with torch.no_grad():\n",
    "# #     outputs = model(data[0].unsqueeze(1).to(device)).cpu()\n",
    "\n",
    "# # #print(outputs.shape)\n",
    "# # print(mask2bbox(np.asarray(outputs.argmax(1).squeeze(0))))\n",
    "\n",
    "# # input = outputs.argmax(1)\n",
    "# target = data[1].unsqueeze(1)\n",
    "\n",
    "# # iflat = input.contiguous().view(-1)\n",
    "# tflat = target.contiguous().view(-1)\n",
    "# # intersection = (iflat * tflat).sum()\n",
    "# # dice_val = ((2. * intersection) /\n",
    "# #            (iflat.sum() + tflat.sum()))\n",
    "\n",
    "# # print(\"Dice\", dice_score(outputs, data[0].unsqueeze(1)), dice_val)\n",
    "# # print(\"*\"*50)\n",
    "\n",
    "# print(tflat.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef819d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 6\n",
    "# print(dls.train_ds[i][1].shape)\n",
    "# print(val_tfms(itemsd[i])[1].shape)\n",
    "# print(dls.train_ds[i][1].min(), val_tfms(itemsd[i])[1].min())\n",
    "\n",
    "# assert np.array_equal(np.asarray(dls.train_ds[i][1]), np.asarray(val_tfms(itemsd[i])[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f4c5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from monai.transforms import Compose\n",
    "# i = 6\n",
    "# t = val_tfms(itemsd[i])\n",
    "# #t = Compose(val_tfms.transforms[:8])(itemsd[i])[\"label\"]\n",
    "# print(t[1].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6fcd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helpers.losses import dice_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bb923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check\n",
    "# from helpers.preprocess import mask2bbox\n",
    "# for i in range(484):\n",
    "#     data = dls.train_ds[i]\n",
    "#     #print(data[0].shape, data[1].shape)\n",
    "#     #print(mask2bbox(np.asarray(data[1].squeeze(0))))\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(data[0].unsqueeze(1).to(device)).cpu()\n",
    "\n",
    "#     #print(outputs.shape)\n",
    "#     #print(mask2bbox(np.asarray(outputs.argmax(1).squeeze(0))))\n",
    "    \n",
    "#     dice_val = dice_score(outputs, data[1].unsqueeze(1))\n",
    "    \n",
    "#     input_mr   = data[0].squeeze(0).cpu()\n",
    "#     output_seg = outputs.argmax(1).squeeze(0).cpu().byte()\n",
    "#     target_seg = data[1].squeeze(1).squeeze(0).cpu().byte()\n",
    "\n",
    "#     f = sitk.LabelOverlapMeasuresImageFilter()\n",
    "#     f.Execute(torch2sitk(target_seg), torch2sitk(output_seg))\n",
    "\n",
    "#     dice_val2 = f.GetDiceCoefficient()\n",
    "#     false_neg_val = f.GetFalseNegativeError() \n",
    "#     false_pos_val = f.GetFalsePositiveError()\n",
    "    \n",
    "#     if false_neg_val > 1.0 or false_pos_val > 1.0:\n",
    "# #     if dice_val.item() < 0.20:\n",
    "#         print(\"idx \", i)\n",
    "#         print(\"Dice\", dice_val, dice_val2)\n",
    "#         print(\"False pos\", false_pos_val, \"False neg\", false_neg_val)\n",
    "#         print(mask2bbox(np.asarray(data[1].squeeze(0))))\n",
    "#         print(mask2bbox(np.asarray(outputs.argmax(1).squeeze(0))))\n",
    "#         print(\"*\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f44adb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = sitk.LabelOverlapMeasuresImageFilter()\n",
    "# f.Execute(torch2sitk(output_seg), torch2sitk(target_seg))\n",
    "\n",
    "# label all zeros => huge proportion of labelled negative are falsely labelled negative => but no false positives\n",
    "# n. labelled negative/ n. ground truth negative\n",
    "\n",
    "# # False Neg: proportion ground truth positives that are labelled neg = 100% = (# label neg / total # gt pos)\n",
    "# # False Pos: proportion ground truth negs that are labelled pos = 0% (# label pos / total # gt neg)\n",
    "# dice_val_opp = f.GetDiceCoefficient()\n",
    "# false_neg_val_opp = f.GetFalseNegativeError() \n",
    "# false_pos_val_opp = f.GetFalsePositiveError()\n",
    "\n",
    "# # false pos rate = #false pos/(#false pos + #true neg)\n",
    "# print(dice_val_opp, false_neg_val_opp, false_pos_val_opp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4972cbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 127\n",
    "# data = dls.train_ds[i]\n",
    "# with torch.no_grad():\n",
    "#     outputs = model(data[0].unsqueeze(1).to(device)).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048dad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_mr   = data[0].squeeze(0).cpu()\n",
    "# output_seg = outputs.argmax(1).squeeze(0).cpu().byte()\n",
    "# target_seg = data[1].squeeze(1).squeeze(0).cpu().byte()\n",
    "\n",
    "# f = sitk.LabelOverlapMeasuresImageFilter()\n",
    "# f.Execute(torch2sitk(target_seg), torch2sitk(output_seg))\n",
    "\n",
    "# dice_val = f.GetDiceCoefficient()\n",
    "# false_neg_val = f.GetFalseNegativeError() \n",
    "# false_pos_val = f.GetFalsePositiveError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7433f04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dice_val)\n",
    "# print(false_neg_val)\n",
    "# print(false_pos_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b4c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_mr   = data[0].squeeze(0).cpu()\n",
    "# output_seg = outputs.argmax(1).squeeze(0).cpu()\n",
    "# target_seg = data[1].squeeze(1).squeeze(0).cpu()\n",
    "\n",
    "# input_mr = np.asarray(input_mr)\n",
    "# output_seg = np.asarray(output_seg)\n",
    "    \n",
    "# # bbox 112-115\n",
    "\n",
    "# # target (57, 87, 77, 108, 62, 83)\n",
    "# # pred (112, 115, 66, 68, 41, 44)\n",
    "\n",
    "# # for sag_idx in range(112,115):\n",
    "# #     fig, axes = plt.subplots(1,3)\n",
    "\n",
    "# #     axes[0].imshow(np.rot90(input_mr[sag_idx]), cmap=plt.cm.gray)\n",
    "# #     axes[0].imshow(np.rot90(output_seg[sag_idx]), alpha=0.5)\n",
    "\n",
    "# #     axes[1].imshow(np.rot90(output_seg[sag_idx]))\n",
    "# #     plt.show()\n",
    "\n",
    "# for sag_idx in range(60,61):\n",
    "#     fig, axes = plt.subplots(1,3)\n",
    "\n",
    "#     axes[0].imshow(np.rot90(input_mr[sag_idx]), cmap=plt.cm.gray)\n",
    "    \n",
    "#     axes[1].imshow(np.rot90(input_mr[sag_idx]), cmap=plt.cm.gray)\n",
    "#     axes[1].imshow(np.rot90(target_seg[sag_idx]), alpha=0.5)\n",
    "\n",
    "#     axes[2].imshow(np.rot90(target_seg[sag_idx]))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a93b162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.losses import dice, dice_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8454b99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 6\n",
    "# data = dls.train_ds[i]\n",
    "# #print(data[0].shape, data[1].shape)\n",
    "# print(mask2bbox(np.asarray(data[1].squeeze(0))))\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     outputs = model(data[0].unsqueeze(1).to(device)).cpu()\n",
    "\n",
    "# #print(outputs.shape)\n",
    "# print(mask2bbox(np.asarray(outputs.argmax(1).squeeze(0))))\n",
    "\n",
    "# input = outputs.argmax(1)\n",
    "# target = data[1].unsqueeze(1)\n",
    "\n",
    "# iflat = input.contiguous().view(-1)\n",
    "# tflat = target.contiguous().view(-1)\n",
    "# intersection = (iflat * tflat).sum()\n",
    "# dice_val = ((2. * intersection) /\n",
    "#            (iflat.sum() + tflat.sum()))\n",
    "\n",
    "# print(\"Dice\", dice_score(outputs, data[1].unsqueeze(1)), dice_val)\n",
    "# print(\"*\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08650283",
   "metadata": {},
   "source": [
    "# Post-processing\n",
    "\n",
    "1. Largest Connect Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af6c4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source sitk 36_Microscopy_Colocalization_Distance_Analysis.html\n",
    "def get_largest_connected_component(binary_seg):\n",
    "    # tensor to sitk\n",
    "    #binary_seg = sitk.GetImageFromArray(binary_seg)\n",
    "    \n",
    "    # connected components in sitkSeg\n",
    "    labeled_seg = sitk.ConnectedComponent(binary_seg)\n",
    "\n",
    "    # re-order labels according to size (at least 1_000 pixels = 10x10x10)\n",
    "    labeled_seg = sitk.RelabelComponent(labeled_seg, minimumObjectSize=1000, sortByObjectSize=True)\n",
    "\n",
    "    # return segm of largest label\n",
    "    binary_seg = labeled_seg == 1\n",
    "    \n",
    "    return binary_seg\n",
    "    # sitk to tensor\n",
    "    #return torch.tensor(sitk.GetArrayFromImage(binary_seg))\n",
    "    \n",
    "# eval metrics\n",
    "# evaluate\n",
    "filters = [sitk.LabelOverlapMeasuresImageFilter(), sitk.HausdorffDistanceImageFilter()]\n",
    "methods = [\n",
    "    [\n",
    "        sitk.LabelOverlapMeasuresImageFilter.GetDiceCoefficient, \n",
    "        sitk.LabelOverlapMeasuresImageFilter.GetFalseNegativeError, \n",
    "        sitk.LabelOverlapMeasuresImageFilter.GetFalsePositiveError\n",
    "    ],\n",
    "    [sitk.HausdorffDistanceImageFilter.GetHausdorffDistance]\n",
    "]\n",
    "\n",
    "names = [\n",
    "    [\"dice\", \"false_neg\", \"false_pos\"],\n",
    "    [\"hausdorff_dist\"]\n",
    "]\n",
    "\n",
    "# d{\"dice\": x, \"Hausdorff\": y, \"false pos\": z}\n",
    "def eval_measure(ground_truth, after_registration, names_todo=None):\n",
    "    if isinstance(names_todo, str): names_todo = [names_todo]\n",
    "        \n",
    "    d = {}\n",
    "    for f,method_list, name_list in zip(filters, methods, names):\n",
    "        for m,n in zip(method_list, name_list):\n",
    "            if not names_todo or n in names_todo:\n",
    "                try:\n",
    "                    #f.Execute(ground_truth, after_registration)\n",
    "                    f.Execute(after_registration, ground_truth)\n",
    "                    val = m(f)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    val = np.NaN\n",
    "                d[n] = val\n",
    "    return d\n",
    "\n",
    "def torch2sitk(t): return sitk.GetImageFromArray(torch.transpose(t, 0, 2))\n",
    "def sitk2torch(o): return torch.transpose(torch.tensor(sitk.GetArrayFromImage(o)), 0, 2)\n",
    "\n",
    "# both pre and post lcc\n",
    "def eval_measure2(label, pred, names_todo=None):\n",
    "    label = torch2sitk(label.squeeze(0).byte())\n",
    "    pred  = torch2sitk(pred.argmax(0).byte())\n",
    "    pred_lcc = get_largest_connected_component(pred)\n",
    "    return eval_measure(label, pred, names_todo), eval_measure(label, pred_lcc, names_todo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694ec2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model to evaluate model\n",
    "learn.model.eval()\n",
    "\n",
    "# device = torch.device(\"cuda:0\")\n",
    "\n",
    "# pre & post LCC\n",
    "pre_df  = []\n",
    "post_df = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# deactivate autograd engine and reduce memory usage and speed up computations\n",
    "for data in dls.train:\n",
    "#     start_small = time.time()\n",
    "\n",
    "    # print(\"in loop\")\n",
    "    \n",
    "    inputs = [i.to(device) for i in data[:-1]]\n",
    "    labels = data[-1].cpu()\n",
    "\n",
    "    # print(\"before no grad\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(*inputs).cpu()\n",
    "        \n",
    "    # print(\"after no grad\")\n",
    "    # calculate metrics pre-LCC and post-LCC\n",
    "    pre_metrics, post_metrics = zip(*[eval_measure2(labels[i], outputs[i])\n",
    "                                      for i in range(len(labels))\n",
    "                                     ])\n",
    "    pre_df  += pre_metrics\n",
    "    post_df += post_metrics\n",
    "    \n",
    "    # clean up memory\n",
    "    del inputs\n",
    "    del labels\n",
    "    del outputs\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    if str(device) != \"cpu\":\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    # print_hardware_stats()\n",
    "\n",
    "#     elapsed_small = time.time() - start_small\n",
    "#     print(f\"Elapsed: {elapsed_small:0.2f} s\")\n",
    "\n",
    "    # break\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"Elapsed: {elapsed:0.2f} s for {len(itemsd)} items.\")\n",
    "# y_true = y_true.cpu().numpy()  \n",
    "# _, y_pred = torch.max(all_outputs, 1)\n",
    "# y_pred = y_pred.cpu().numpy()\n",
    "# y_pred_prob = F.softmax(all_outputs, dim=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b195b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for df in (pre_df, post_df):\n",
    "#     # non-intersecting\n",
    "#     for col in (\"false_neg\",):\n",
    "#         df.loc[df[col]>1.0, col] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e36079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for df in (pre_df, post_df):\n",
    "#     for col in (\"dice\", \"false_neg\", \"false_pos\", \"hausdorff_dist\"):\n",
    "#         df.loc[df[col]=='-99', col] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee1f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df  = pd.DataFrame(pre_df)\n",
    "post_df = pd.DataFrame(post_df)\n",
    "\n",
    "# save\n",
    "model_src = f\"{run_src}/{model_name}\"\n",
    "pre_df.to_pickle(f\"{model_src}/pre_lcc_df.pkl\")\n",
    "post_df.to_pickle(f\"{model_src}/post_lcc_df.pkl\")\n",
    "\n",
    "for name_lst in names:\n",
    "    for name in name_lst:\n",
    "        pre_mean  = pre_df[name].mean()\n",
    "        post_mean = post_df[name].mean()\n",
    "        delta = post_mean - pre_mean\n",
    "        print(f\"{name}: diff = {delta:0.4f} ({pre_mean: 0.4f} ==> {post_mean:0.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbaa27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff_dff = post_df - pre_df\n",
    "# display(diff_dff[diff_dff[\"hausdorff_dist\"].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff7891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', 230)\n",
    "# display(diff_dff[diff_dff[\"false_pos\"] < 0].sort_values(by=['dice'], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3808313",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# diff_dff[diff_dff[\"dice\"]!=0.0][\"dice\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ab7198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# col = \"false_pos\"\n",
    "# diff_dff[diff_dff[col]!=0.0][col].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e5b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# col = \"false_neg\"\n",
    "# diff_dff[diff_dff[col]!=0.0][col].hist(), diff_dff[diff_dff[col]!=0.0][col].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d9a2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_df[\"dice\"].hist(), post_df[\"dice\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b08d753",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a8bce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_indiv_dices = post_df[\"dice\"].values\n",
    "\n",
    "test_idxs  = [idx for idx,i in enumerate(items) if \"ABIDE\" in i[0]] \n",
    "ppmi_idxs  = [idx for idx,i in enumerate(items) if dset_dict[\"PPMI\"] in i[0]]\n",
    "icmb_idxs  = [idx for idx,i in enumerate(items) if \"ICMB\" in i[1]]\n",
    "adni_idxs  = [idx for idx,i in enumerate(items) if \"ADNI1_full\" in i[1]]\n",
    "aibl_idxs  = [idx for idx,i in enumerate(items) if \"AIBL\" in i[1]]\n",
    "abvib_idxs = [idx for idx,i in enumerate(items) if \"ABVIB\" in i[1]]\n",
    "\n",
    "# print(len(test_idxs))\n",
    "# print(len(ppmi_idxs))\n",
    "# print(len(icmb_idxs))\n",
    "# print(len(adni_idxs))\n",
    "# print(len(aibl_idxs))\n",
    "# print(len(abvib_idxs))\n",
    "# print(len(test_items), len(valid_items), len(train_items))\n",
    "\n",
    "names = [\"ABIDE\", \"PPMI\", \"ICMB\", \"ADNI\", \"AIBL\", \"ABVIB\"]\n",
    "idxs  = [test_idxs, ppmi_idxs, icmb_idxs, adni_idxs, aibl_idxs, abvib_idxs]\n",
    "\n",
    "print_df = []\n",
    "\n",
    "# overall dice\n",
    "print_df.append({\n",
    "    \"dset\":\"Overall\",\n",
    "    \"median_dice\":np.median(np_indiv_dices),\n",
    "    \"mean_dice\":np_indiv_dices.mean(),\n",
    "    \"std_dice\":np_indiv_dices.std()\n",
    "})\n",
    "\n",
    "for name,name_idxs in zip(names, idxs):\n",
    "    subset_idxs = np.array([np_indiv_dices[i] for i in name_idxs])\n",
    "    print_df.append({\"dset\":name,\"median_dice\":np.median(subset_idxs),\"mean_dice\":subset_idxs.mean(),\"std_dice\":subset_idxs.std()})\n",
    "\n",
    "print_df = pd.DataFrame(print_df)\n",
    "\n",
    "# save\n",
    "print_df.to_pickle(f\"{model_src}/stats_df.pkl\")\n",
    "\n",
    "print_df = print_df.style.set_caption(f\"{model_name}\")\n",
    "#display(print_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6459db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4554629",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c164043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check\n",
    "# check_post_df  = pd.read_pickle(f\"{model_src}/post_lcc_df.pkl\")\n",
    "# check_pre_df   = pd.read_pickle(f\"{model_src}/pre_lcc_df.pkl\")\n",
    "# check_stats_df = pd.read_pickle(f\"{model_src}/stats_df.pkl\")\n",
    "# display(check_post_df)\n",
    "# display(check_pre_df)\n",
    "# display(check_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2976fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets     = torch.cat(y_true, dim=0)\n",
    "# predictions = torch.cat(outputs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8695bfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "\n",
    "# predictions = []\n",
    "# targets     = []\n",
    "# val_batch_iter = iter(dls.train)\n",
    "# for n in range(int(len(itemsd) / bs)):\n",
    "#     xb,yb = next(val_batch_iter)\n",
    "#     preds = learn.model(xb.cpu())\n",
    "#     predictions.append(preds)\n",
    "#     targets.append(yb.cpu())\n",
    "#     print(\"next\", n)\n",
    "    \n",
    "#     del xb\n",
    "#     del yb\n",
    "#     del preds\n",
    "    \n",
    "# #predictions, targets = learn.get_preds(dl=dls.train)\n",
    "# elapsed = time.time() - start\n",
    "\n",
    "# print(f\"Elapsed: {elapsed:0.2f} s for {len(itemsd)} items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4beeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 30 sec for 67 test items (2 CPU workers)\n",
    "# do_validate = False # True # False # True\n",
    "# if do_validate:\n",
    "#     start = time.time()\n",
    "#     print(learn.validate(ds_idx=0))\n",
    "#     elapsed = time.time() - start\n",
    "#     print(f\"Elapsed: {elapsed:0.2f} s for {(len(itemsd))} items.\")\n",
    "    \n",
    "# print(\"Pred mask\", predictions.shape, \"Target (x = y = MR)\", targets.shape)\n",
    "# print(\"Pred mask\", predictions[0].shape, \"Target\", targets[0].shape)\n",
    "\n",
    "# do_masks = False # True # False # True\n",
    "# if do_masks:\n",
    "#     from helpers.preprocess import batch_get_bbox\n",
    "\n",
    "#     # Elapsed 65.148959 s\n",
    "#     start = time.time()\n",
    "\n",
    "#     # get masks and probs\n",
    "#     pred_masks = torch.argmax(predictions, dim=1).byte()\n",
    "#     pred_bboxs = batch_get_bbox(pred_masks)\n",
    "#     gt_bboxs   = batch_get_bbox(targets)\n",
    "#     #pred_probs = np.asarray(predictions.softmax(1)[:,1].cpu())\n",
    "\n",
    "#     elapsed = time.time() - start\n",
    "#     print(f\"Elapsed {elapsed:2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8752f8c4",
   "metadata": {},
   "source": [
    "# Test set: Prediction Dice Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191a22d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from monai.losses import DiceLoss\n",
    "\n",
    "# dice_loss = DiceLoss(\n",
    "#     include_background=False, \n",
    "#     to_onehot_y=False, \n",
    "#     sigmoid=False, \n",
    "#     softmax=False, \n",
    "#     other_act=None, \n",
    "#     squared_pred=False, \n",
    "#     jaccard=False, \n",
    "#     reduction=\"none\", \n",
    "#     smooth_nr=0, #1e-05, \n",
    "#     smooth_dr=0, #1e-05, \n",
    "#     batch=False)\n",
    "\n",
    "# # dice_loss_soft = DiceLoss(\n",
    "# #     include_background=False, \n",
    "# #     to_onehot_y=False, \n",
    "# #     sigmoid=True, \n",
    "# #     softmax=False, \n",
    "# #     other_act=None, \n",
    "# #     squared_pred=False, \n",
    "# #     jaccard=False, \n",
    "# #     reduction=\"none\", \n",
    "# #     smooth_nr=0, #1e-05, \n",
    "# #     smooth_dr=0, #1e-05, \n",
    "# #     batch=False)\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# indiv_dices = dice_loss(predictions.argmax(1).unsqueeze(1), targets)\n",
    "# #indiv_dices = dice_loss_soft(predictions[:,1].unsqueeze(1), targets)\n",
    "# indiv_dices = [1-dice_loss for dice_loss in indiv_dices]\n",
    "# elapsed = time.time() - start\n",
    "\n",
    "# print(f\"Elapsed: {elapsed:0.2f} s for {len(targets)} items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbce864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "\n",
    "# # sort dices from low to high\n",
    "# #sorted_dice_idxs  = sorted(range(len(indiv_dices)), key=lambda i:indiv_dices[i].item()) \n",
    "# np_indiv_dices = np.array([indiv_dices[i].item() for i in range(len(indiv_dices))])\n",
    "\n",
    "# # plot\n",
    "# fig1, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, figsize=(12,6))\n",
    "# ax0.hist(np_indiv_dices, bins=\"auto\")\n",
    "# ax1.boxplot(np_indiv_dices)\n",
    "\n",
    "# fig1.suptitle(\"Dice Score (ABIDE test set + Cross label items)\")\n",
    "# plt.show()\n",
    "\n",
    "# # time\n",
    "# elapsed = time.time() - start\n",
    "# print(f\"Elapsed: {elapsed:0.2f} s for {len(targets)} items.\")\n",
    "\n",
    "# test_idxs  = [idx for idx,i in enumerate(items) if \"ABIDE\" in i[0]] \n",
    "# ppmi_idxs  = [idx for idx,i in enumerate(items) if dset_dict[\"PPMI\"] in i[0]]\n",
    "# icmb_idxs  = [idx for idx,i in enumerate(items) if \"ICMB\" in i[1]]\n",
    "# adni_idxs  = [idx for idx,i in enumerate(items) if \"ADNI1_full\" in i[1]]\n",
    "# aibl_idxs  = [idx for idx,i in enumerate(items) if \"AIBL\" in i[1]]\n",
    "# abvib_idxs = [idx for idx,i in enumerate(items) if \"ABVIB\" in i[1]]\n",
    "\n",
    "# # print(len(test_idxs))\n",
    "# # print(len(ppmi_idxs))\n",
    "# # print(len(icmb_idxs))\n",
    "# # print(len(adni_idxs))\n",
    "# # print(len(aibl_idxs))\n",
    "# # print(len(abvib_idxs))\n",
    "# # print(len(test_items), len(valid_items), len(train_items))\n",
    "\n",
    "# names = [\"ABIDE\", \"PPMI\", \"ICMB\", \"ADNI\", \"AIBL\", \"ABVIB\"]\n",
    "# idxs  = [test_idxs, ppmi_idxs, icmb_idxs, adni_idxs, aibl_idxs, abvib_idxs]\n",
    "\n",
    "# df = []\n",
    "\n",
    "# # overall dice\n",
    "# df.append({\n",
    "#     \"dset\":\"overall\",\n",
    "#     \"median_dice\":np.median(np_indiv_dices),\n",
    "#     \"mean_dice\":np_indiv_dices.mean(),\n",
    "#     \"std_dice\":np_indiv_dices.std()\n",
    "# })\n",
    "\n",
    "# for name,name_idxs in zip(names, idxs):\n",
    "#     subset_idxs = np.array([indiv_dices[i].item() for i in name_idxs])\n",
    "#     df.append({\"dset\":name,\"median_dice\":np.median(subset_idxs),\"mean_dice\":subset_idxs.mean(),\"std_dice\":subset_idxs.std()})\n",
    "\n",
    "# import pandas as pd\n",
    "# df = pd.DataFrame(df)\n",
    "\n",
    "# model_src = f\"{run_src}/{model_name}\"\n",
    "# df.to_pickle(f\"{model_src}/test_dices.pkl\")\n",
    "\n",
    "# torch.save(predictions, f\"{model_src}/test_preds.pt\")\n",
    "# torch.save(targets, f\"{model_src}/test_targs.pt\")\n",
    "# torch.save(indiv_dices, f\"{model_src}/test_dices.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559f9689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988717ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = df.plot.bar(x=\"dset\",rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba19b95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8facad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# names = [\"ABIDE\", \"PPMI\", \"ICMB\", \"ADNI\", \"AIBL\", \"ABVIB\"]\n",
    "# idxs  = [test_idxs, ppmi_idxs, icmb_idxs, adni_idxs, aibl_idxs, abvib_idxs]\n",
    "\n",
    "# for name,name_idxs in zip(names, idxs):\n",
    "#     subset_idxs = np.array([indiv_dices[i].item() for i in name_idxs])\n",
    "#     print(name, \": \", \"Median dice: \", np.median(subset_idxs), \"Mean\",subset_idxs.mean(), \"+- std\", subset_idxs.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d93846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.median([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20144e4e",
   "metadata": {},
   "source": [
    "# Shape of Largest connected component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b21d391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lccs = [sitk2torch(get_largest_connected_component(torch2sitk(x.byte()))) for x in pred_masks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c6c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(lccs), lccs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77807888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lccs_all = torch.stack(lccs, dim=0)\n",
    "# print(lccs_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79069387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lccs_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4fab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lccs_all[:20].unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab088e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helpers.isoperim import get_iso_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3ac27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# pred_ratios = get_iso_ratio(predictions)\n",
    "# elapsed = time.time() - start\n",
    "# print(f\"Elapsed: {elapsed:0.2f} s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32e5c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# lcc_ratios = get_iso_ratio(lccs_all.unsqueeze(1))\n",
    "# elapsed = time.time() - start\n",
    "# print(f\"Elapsed: {elapsed:0.2f} s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af733f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c172df7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# target_ratios = get_iso_ratio(targets)\n",
    "# elapsed = time.time() - start\n",
    "# print(f\"Elapsed: {elapsed:0.2f} s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4e72d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(3,2, figsize=(12,12))\n",
    "# axes[0,0].hist(np.asarray(target_ratios))\n",
    "# axes[0,0].set_title(\"Target Isoperimetric ratio\")\n",
    "# axes[0,1].boxplot(np.asarray(target_ratios))\n",
    "\n",
    "# axes[1,0].hist(np.asarray(ratios))\n",
    "# axes[1,0].set_title(\"Largest Connected Component Isoperimetric ratio\")\n",
    "# axes[1,1].boxplot(np.asarray(ratios))\n",
    "\n",
    "# diff = ratios - target_ratios\n",
    "# axes[2,0].hist(np.asarray(diff))\n",
    "# axes[2,0].set_title(\"Difference in Isoperimetric ratio\")\n",
    "# axes[2,1].boxplot(np.asarray(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030e87dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7254cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_ratios = get_isoperimetric_ratio(*get_vol_sa(get_largest_connected_component()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cdac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_ratios     = get_isoperimetric_ratio(*get_vol_sa(targets))\n",
    "# prediction_ratios = get_isoperimetric_ratio(*get_vol_sa(predictions))\n",
    "\n",
    "# _, axes = plt.subplots(1,2)\n",
    "# axes[0].hist(np.asarray(target_ratios))\n",
    "# axes[1].hist(np.asarray(prediction_ratios))\n",
    "# axes[0].set_title(\"Target Isometric Ratio\")\n",
    "# axes[1].set_title(\"Pred Isometric Ratio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9506acb6",
   "metadata": {},
   "source": [
    "# Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75653d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%javascript\n",
    "# IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc5ccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nbconvert import HTMLExporter\n",
    "# import codecs\n",
    "# import nbformat\n",
    "\n",
    "# notebook_name = nb_name\n",
    "# output_file_name = notebook_name[:-6] + \"_viz_probs_BCE_July_31\" + '.html'\n",
    "\n",
    "# exporter = HTMLExporter()\n",
    "# output_notebook = nbformat.read(notebook_name, as_version=4)\n",
    "\n",
    "# output, resources = exporter.from_notebook_node(output_notebook)\n",
    "# codecs.open(output_file_name, 'w', encoding='utf-8').write(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c0ca0b",
   "metadata": {},
   "source": [
    "# Isoperimetric ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f743a27a",
   "metadata": {},
   "source": [
    "# Probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8662bfcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# probs = predictions.softmax(1)[:,1]\n",
    "# print(f\"Probs\", probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3c6d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import colors\n",
    "\n",
    "# prob_cmap  = \"GnBu\" #\"hot\" https://matplotlib.org/stable/tutorials/colors/colormaps.html \n",
    "# bin_cmap1  = colors.ListedColormap(['white', 'yellow'])\n",
    "# bin_cmap2  = colors.ListedColormap(['white', 'red'])\n",
    "\n",
    "# for idx in sorted_dice_idxs[:10]:\n",
    "\n",
    "#     print(f\"Worst idx: {idx}. mr: {items[idx][0][len(data_src)+1:]}\")\n",
    "    \n",
    "#     gt_bbox   = gt_bboxs[idx]\n",
    "#     pred_bbox = pred_bboxs[idx]\n",
    "    \n",
    "#     gt_map    = targets[idx].squeeze()\n",
    "#     prob_map  = probs[idx]\n",
    "#     pred_mask = pred_masks[idx]\n",
    "\n",
    "#     # max difference\n",
    "#     d = torch.abs(gt_map-prob_map)\n",
    "\n",
    "#     # along axis 0,1,2\n",
    "#     a0 = torch.sum(torch.sum(d, dim=2), dim=1)\n",
    "#     a1 = torch.sum(torch.sum(d, dim=2), dim=0)\n",
    "#     a2 = torch.sum(torch.sum(d, dim=1), dim=0)\n",
    "#     a0max, a0_idx = torch.max(a0), torch.argmax(a0)\n",
    "#     a1max, a1_idx = torch.max(a1), torch.argmax(a1)\n",
    "#     a2max, a2_idx = torch.max(a2), torch.argmax(a2)\n",
    "    \n",
    "#     # plot\n",
    "#     fig, axes = plt.subplots(3,4, figsize=(12,12))\n",
    "#     for i in range(3):\n",
    "#         max_diff_idx = [a0_idx, a1_idx, a2_idx][i]\n",
    "        \n",
    "#         gt_slice, prob_slice, pred_slice = [np.take(np.asarray(m), max_diff_idx, axis=i) for m in (gt_map, prob_map, pred_mask)]\n",
    "        \n",
    "#         axes[i,0].imshow(gt_slice,   cmap=bin_cmap1)\n",
    "#         axes[i,0].imshow(pred_slice, cmap=bin_cmap2, alpha=0.5)\n",
    "#         axes[i,1].imshow(gt_slice,   cmap=bin_cmap1)\n",
    "#         im  = axes[i,2].imshow(prob_slice, cmap=prob_cmap, interpolation='nearest')  \n",
    "#         im2 = axes[i,3].imshow(np.log(prob_slice), cmap=prob_cmap, interpolation='nearest')  \n",
    "\n",
    "#         axes[i,0].set_title(f\"Slice {max_diff_idx} (Axis {i})\")\n",
    "#         axes[i,1].set_title(f\"GT map\")\n",
    "#         axes[i,2].set_title(f\"Prob map\")\n",
    "#         axes[i,3].set_title(f\"Log Prob map\")\n",
    "        \n",
    "#         # colorbar\n",
    "#         fig.colorbar(im,  ax=axes[i,2])\n",
    "#         fig.colorbar(im2, ax=axes[i,3])\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d12d69b",
   "metadata": {},
   "source": [
    "# Viz worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554978b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SimpleITK as sitk\n",
    "# from helpers.viz import viz_axis, viz_compare_inputs, viz_compare_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff170c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helpers.general import round_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65e9496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# worst_idx = low_dice_idxs[0]\n",
    "# best_idx  = sorted_dice_idxs[-1]\n",
    "# print(\"Worst. Idx = \", worst_idx, \"Dice: \", indiv_dices[worst_idx], items[worst_idx][0]); print()\n",
    "# print(\"Best. Idx = \", best_idx, \"Dice: \",   indiv_dices[best_idx], items[best_idx][0])\n",
    "\n",
    "# # get dirs\n",
    "# worst_fn = items[worst_idx][0]\n",
    "# best_fn  = items[best_idx][0]\n",
    "\n",
    "# print(f\"Worst fname: {worst_fn[len(data_src):]}\"); print()\n",
    "# print(f\"best fname: {best_fn[len(data_src):]}\")\n",
    "\n",
    "# for fn in (worst_fn, best_fn):\n",
    "#     # get stated direction\n",
    "#     sitk_obj = sitk.ReadImage(fn, sitk.sitkFloat32)\n",
    "#     sitk_dir = sitk_obj.GetDirection()\n",
    "\n",
    "#     # get stated orientation\n",
    "#     orient = sitk.DICOMOrientImageFilter()\n",
    "#     sitk_ori = orient.GetOrientationFromDirectionCosines(sitk_dir)\n",
    "    \n",
    "#     # print\n",
    "#     print(f\"Dir {round_tuple(sitk_dir)}, Ori {sitk_ori}\")\n",
    "\n",
    "# def get_input(idx):\n",
    "#     mr1,mk1 = tls[idx]\n",
    "#     return mr1.squeeze(), mk1.squeeze()\n",
    "\n",
    "# input1 = get_input(worst_idx)\n",
    "# input2 = get_input(best_idx)\n",
    "    \n",
    "# for axis in range(3):\n",
    "#     viz_compare_inputs(input1, input2, axis=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be670745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helpers.viz import get_mid_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a6b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import colors\n",
    "# bin_cmap2  = colors.ListedColormap(['white', 'yellow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27732df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # intensity\n",
    "\n",
    "# worst_idxs = sorted_dice_idxs[:5]\n",
    "# best_idxs  = sorted_dice_idxs[-5:]\n",
    "\n",
    "# _, axes = plt.subplots(10,3, figsize=(6,12))\n",
    "\n",
    "# for i in range(5):\n",
    "#     w_idx = worst_idxs[i]\n",
    "#     b_idx = best_idxs[i]\n",
    "    \n",
    "#     input1 = get_input(w_idx)\n",
    "#     input2 = get_input(b_idx)\n",
    "\n",
    "#     bbox1 = gt_bboxs[w_idx]\n",
    "#     bbox2 = gt_bboxs[b_idx]\n",
    "    \n",
    "#     # plot\n",
    "#     for axis in range(3):\n",
    "#         start_idx1, end_idx1 = get_mid_range(bbox1, axis, nslices=1)\n",
    "#         start_idx2, end_idx2 = get_mid_range(bbox2, axis, nslices=1)\n",
    "        \n",
    "#         # WORST: mid-slice in axis\n",
    "#         axes[2*i, axis].imshow(np.take(np.rot90(input1[0]), start_idx1, axis=axis)) #, cmap=plt.cm.gray)\n",
    "#         #axes[2*i, axis].imshow(np.take(np.rot90(input1[1]), start_idx1, axis=axis), cmap=bin_cmap2, alpha=0.5)\n",
    "        \n",
    "#         # BEST: mid-slice in axis\n",
    "#         axes[2*i+1, axis].imshow(np.take(np.rot90(input2[0]), start_idx2, axis=axis)) #, cmap=plt.cm.gray)\n",
    "#         #axes[2*i+1, axis].imshow(np.take(np.rot90(input2[1]), start_idx2, axis=axis), cmap=bin_cmap2, alpha=0.5)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ce2cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # intensity hist\n",
    "\n",
    "# worst_idxs = sorted_dice_idxs[:5]\n",
    "# best_idxs  = sorted_dice_idxs[-5:]\n",
    "\n",
    "# #fig = plt.figure(constrained_layout=True)\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=5, sharex=True, sharey=True)\n",
    "# fig.suptitle('MR Intensity Histogram')\n",
    "\n",
    "# axes[0,0].set_yscale('log')\n",
    "# axes[0,2].set_title(\"Worst\")\n",
    "# axes[1,2].set_title(\"Best\")\n",
    "# # subfigs = fig.subfigures(nrows=2, ncols=1)\n",
    "# # subfigs[0].suptitle(f'Worst');\n",
    "# # subfigs[1].suptitle(f'Best')\n",
    "\n",
    "# # axs = []\n",
    "# # for subfig in subfigs:\n",
    "# #     # create 1x3 subplots per subfig\n",
    "# #     axs.append(subfig.subplots(nrows=1, ncols=5))\n",
    "# # axs = np.asarray(axs)    \n",
    "# # #, axes = plt.subplots(2,5, figsize=(6,12))\n",
    "\n",
    "# for i in range(5):\n",
    "#     w_idx = worst_idxs[i]\n",
    "#     b_idx = best_idxs[i]\n",
    "    \n",
    "#     input1 = get_input(w_idx)\n",
    "#     input2 = get_input(b_idx)\n",
    "\n",
    "#     mr1, mk1 = input1\n",
    "#     mr2, mk2 = input2\n",
    "    \n",
    "#     mr1, mk1 = np.asarray(mr1), np.asarray(mk1)\n",
    "#     mr2, mk2 = np.asarray(mr2), np.asarray(mk2)\n",
    "    \n",
    "#     # plot\n",
    "    \n",
    "#     axes[0,i].hist(mr1[mr1>0].reshape(-1,))\n",
    "#     axes[1,i].hist(mr2[mr2>0].reshape(-1,))\n",
    "    \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d709b9",
   "metadata": {},
   "source": [
    "# Viz all worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e656ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #for n_worst in range(len(low_dice_idxs)):\n",
    "# for n_worst in range(len(low_dice_idxs)):\n",
    "#     idx = low_dice_idxs[n_worst]\n",
    "\n",
    "#     mr, mk       = get_input(idx)\n",
    "#     pred, target = predictions[idx], targets[idx].squeeze()\n",
    "\n",
    "#     dice = dice_score(pred.unsqueeze(0), target.unsqueeze(0).unsqueeze(0))\n",
    "    \n",
    "#     print(f\"Worst #{n_worst}. Dice {dice:.3f}\")\n",
    "#     print(f\"fn: {items[idx][0][len(data_src)+1:]}\")\n",
    "#     print(f\"*\"*100)\n",
    "    \n",
    "#     print(\"GT bbox and Pred bbox: \", gt_bboxs[idx], pred_bboxs[idx])\n",
    "\n",
    "#     viz_compare_outputs(mr, target, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cb60de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a169cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2817610f",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e684dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af56359",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
