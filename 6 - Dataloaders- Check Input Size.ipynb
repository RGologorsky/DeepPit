{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unable-instruction",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "The goal of this notebook is to train a 3d UNET segmentation model to output binary mask representing the sella turcica ROI.\n",
    "\n",
    "Notes:\n",
    "- With gratitude to https://github.com/kbressem/faimed3d/blob/main/examples/3d_segmentation.md\n",
    "- TODO Augmentations: flip, orientation\n",
    "- TODO Intensity normalization: N4 bias correction, hist bin matching, tissue intensity,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75246242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0 : b'GeForce GTX 1080 Ti'\n",
      "Device 1 : b'GeForce GTX 1080'\n",
      "gpu: 0%, gpu-mem: 0%\n",
      "is cuda available? True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Check GPU stats\n",
    "\n",
    "from pynvml import *\n",
    "nvmlInit()\n",
    "try:\n",
    "    deviceCount = nvmlDeviceGetCount()\n",
    "    for i in range(deviceCount):\n",
    "        handle = nvmlDeviceGetHandleByIndex(i)\n",
    "        print(\"Device\", i, \":\", nvmlDeviceGetName(handle))\n",
    "except NVMLError as error:\n",
    "    print(error)\n",
    "    \n",
    "# https://docs.fast.ai/dev/gpu.html\n",
    "import nvidia_smi\n",
    "\n",
    "nvidia_smi.nvmlInit()\n",
    "handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
    "# card id 0 hardcoded here, there is also a call to get all available card ids, so we could iterate\n",
    "\n",
    "res = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)\n",
    "print(f'gpu: {res.gpu}%, gpu-mem: {res.memory}%')\n",
    "\n",
    "import torch\n",
    "print(\"is cuda available?\", torch.cuda.is_available() )\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# hm\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4774d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU RAM Free: 9450MB | Used: 1728MB | Util  15% | Total 11178MB\n",
      "GPU RAM Free: 7971MB | Used: 145MB | Util   2% | Total 8116MB\n"
     ]
    }
   ],
   "source": [
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "for gpu in GPUs:\n",
    "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d400ed5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  320896 KB |    7392 MB |   42581 MB |   42267 MB |\n",
      "|       from large pool |  260746 KB |    7349 MB |   42457 MB |   42202 MB |\n",
      "|       from small pool |   60149 KB |      61 MB |     123 MB |      65 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  320896 KB |    7392 MB |   42581 MB |   42267 MB |\n",
      "|       from large pool |  260746 KB |    7349 MB |   42457 MB |   42202 MB |\n",
      "|       from small pool |   60149 KB |      61 MB |     123 MB |      65 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    7454 MB |    7454 MB |   30766 MB |   23312 MB |\n",
      "|       from large pool |    7390 MB |    7390 MB |   30670 MB |   23280 MB |\n",
      "|       from small pool |      64 MB |      64 MB |      96 MB |      32 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |    7138 MB |    7225 MB |   71741 MB |   64602 MB |\n",
      "|       from large pool |    7135 MB |    7224 MB |   71602 MB |   64467 MB |\n",
      "|       from small pool |       3 MB |      13 MB |     138 MB |     135 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     765    |     788    |    1802    |    1037    |\n",
      "|       from large pool |      45    |      46    |     111    |      66    |\n",
      "|       from small pool |     720    |     785    |    1691    |     971    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     765    |     788    |    1802    |    1037    |\n",
      "|       from large pool |      45    |      46    |     111    |      66    |\n",
      "|       from small pool |     720    |     785    |    1691    |     971    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      39    |      39    |      77    |      38    |\n",
      "|       from large pool |       7    |       8    |      29    |      22    |\n",
      "|       from small pool |      32    |      32    |      48    |      16    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      28    |      30    |     405    |     377    |\n",
      "|       from large pool |       6    |       6    |      50    |      44    |\n",
      "|       from small pool |      22    |      24    |     355    |     333    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27aa128",
   "metadata": {},
   "source": [
    "# Data Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7031ab",
   "metadata": {},
   "source": [
    "Set path to where data is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "775df797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebc81c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABIDE', 'PPMI', 'ABVIB', 'samir_labels']\n",
      "['50155-50212', '50373-50453', '50002-50153', '50213-50312', '50313-50372']\n"
     ]
    }
   ],
   "source": [
    "# Get path to 4 TB HD\n",
    "\n",
    "# /media/labcomputer/e33f6fe0-5ede-4be4-b1f2-5168b7903c7a/home\n",
    "\n",
    "# wsl: /home/rgologorsky/DeepPit\n",
    "hd_path = \"../\" * 5 + \"/media/labcomputer/e33f6fe0-5ede-4be4-b1f2-5168b7903c7a\" + \"/home/rachel/PitMRdata\"\n",
    "\n",
    "# all folders in HD\n",
    "all_folders = os.listdir(hd_path)\n",
    "\n",
    "print(all_folders)\n",
    "\n",
    "# labels\n",
    "print(os.listdir(f\"{hd_path}/samir_labels\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02841785",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rough-climate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from faimed3d.all import *\n",
    "from fastai import *\n",
    "from torchvision.models.video import r3d_18\n",
    "from fastai.callback.all import SaveModelCallback\n",
    "from torch import nn\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import meshio\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as DF\n",
    "\n",
    "from helpers_preprocess import get_data_dict, paths2objs, folder2objs, seg2mask\n",
    "\n",
    "from helpers_general import sitk2np, print_sitk_info, round_tuple, lrange, lmap, get_roi_range, numbers2groups\n",
    "\n",
    "# imports\n",
    "from helpers_general import sitk2np, np2sitk, round_tuple, lrange, get_roi_range, numbers2groups\n",
    "from helpers_preprocess import mask2bbox, print_bbox, get_bbox_size, print_bbox_size, get_data_dict, folder2objs\n",
    "from helpers_viz import viz_axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959ca43b",
   "metadata": {},
   "source": [
    "# Get Items\n",
    "\n",
    "Item = (path to MR, path to Segmentation obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72985d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data dict: 335 items.\n",
      "Subset data dict: 300 items.\n"
     ]
    }
   ],
   "source": [
    "# get items = (mask_fn, nii_fn)\n",
    "train_path = f\"{hd_path}/samir_labels\"\n",
    "folders = os.listdir(train_path)\n",
    "\n",
    "# get all items\n",
    "data_dict_full = {}\n",
    "for folder in folders:\n",
    "    data_dict_full.update(get_data_dict(f\"{train_path}/{folder}\"))\n",
    "\n",
    "items_full = list(data_dict_full.values())\n",
    "\n",
    "# subset 300 for training/valid; 35 for test\n",
    "rand_idx = torch.randperm(300)\n",
    "items = np.array(items_full)[rand_idx]\n",
    "\n",
    "print(f\"Full data dict: {len(data_dict_full)} items.\")\n",
    "print(f\"Subset data dict: {len(items)} items.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdf8ee3",
   "metadata": {},
   "source": [
    "# Transforms\n",
    "\n",
    "- PathToSITK (*convert paths to SITK obj*)\n",
    "- Resize (*common size, isotropic spacing*)\n",
    "- ToTensor (*convert to Pytorch tensor*)\n",
    "- TensorSlice & Center Crop (*slice 3d tensor to center part containing sella*)\n",
    "- Normalize (*scale image intensities? - diff tissues diff intensities?*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59d5815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoAll(ItemTransform):\n",
    "    \n",
    "    def __init__(self, new_sp = 1):\n",
    "        self.new_sp = new_sp\n",
    "        \n",
    "    def encodes(self, x):\n",
    "        # get sitk objs\n",
    "        im_path, segm_path = x\n",
    "        folder  = Path(segm_path).parent.name\n",
    "        ras_adj = int(folder) in range(50455, 50464)\n",
    "\n",
    "        mr         = sitk.ReadImage(im_path, sitk.sitkFloat32)\n",
    "        segm       = meshio.read(segm_path)\n",
    "        mask_arr   = seg2mask(mr, segm, ras_adj)\n",
    "\n",
    "        # resize so isotropic spacing\n",
    "        orig_sp = mr.GetSpacing()\n",
    "        orig_sz = mr.GetSize()\n",
    "        new_sz = [int(round(osz*ospc/self.new_sp)) for osz,ospc in zip(orig_sz, orig_sp)]\n",
    "\n",
    "        im = torch.swapaxes(torch.tensor(sitk.GetArrayFromImage(mr)), 0, 2)\n",
    "        mk = torch.tensor(mask_arr).float()\n",
    "\n",
    "        while im.ndim < 5: \n",
    "            im = im.unsqueeze(0)\n",
    "            mk = mk.unsqueeze(0)\n",
    "\n",
    "        return F.interpolate(im, size = new_sz, mode = 'trilinear', align_corners=False).squeeze(), \\\n",
    "                F.interpolate(mk, size = new_sz, mode = 'nearest').squeeze().long()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-attitude",
   "metadata": {},
   "source": [
    "# Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe42841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop center\n",
    "class CenterCropTfm(Transform):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        \n",
    "    def encodes(self, arr):\n",
    "        return self.cropND(arr, self.size)\n",
    "    \n",
    "    # https://stackoverflow.com/questions/39382412/crop-center-portion-of-a-numpy-image\n",
    "    @staticmethod\n",
    "    def cropND(img, bounding):\n",
    "        start = tuple(map(lambda a, da: a//2-da//2, img.shape, bounding))\n",
    "        end = tuple(map(operator.add, start, bounding))\n",
    "        slices = tuple(map(slice, start, end))\n",
    "        return img[slices]\n",
    "    \n",
    "# crop by coords\n",
    "class CropBBox(Transform):\n",
    "    def __init__(self, bbox):\n",
    "        self.bbox = bbox\n",
    "    \n",
    "    def encodes(self, arr):\n",
    "        imin, imax, jmin, jmax, kmin, kmax = self.bbox\n",
    "        cropped = arr[imin:imax, jmin:jmax, kmin:kmax]\n",
    "        \n",
    "        # pad if needed\n",
    "        new_size = [imax-imin, jmax-jmin, kmax-kmin]\n",
    "        \n",
    "        pad = [x-y for x,y in zip(new_size, arr.shape)]\n",
    "        pad = [a for amt in pad for a in (amt//2, amt-amt//2)]\n",
    "        pad.reverse()\n",
    "        \n",
    "        return F.pad(arr, pad, mode='constant', value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ef74ed",
   "metadata": {},
   "source": [
    "# Dataloaders\n",
    "\n",
    "TODO augmentations.\n",
    "\n",
    "- dset = tfms applied to items\n",
    "- splits into training/valid\n",
    "- bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54b7336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs  = 1\n",
    "general_bbox = (40, 150, 100, 320, 0, 300)\n",
    "\n",
    "small_bbox = (50,100, 100,150, 50, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f728dc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 240, Valid: 60\n",
      "<class 'tuple'> torch.Size([1, 1, 50, 50, 50]) torch.Size([1, 1, 50, 50, 50])\n",
      "240 60\n"
     ]
    }
   ],
   "source": [
    "# splits\n",
    "splits = RandomSplitter(seed=42)(items)\n",
    "print(f\"Training: {len(splits[0])}, Valid: {len(splits[1])}\")\n",
    "\n",
    "# tfms\n",
    "tfms = [DoAll(), CropBBox(small_bbox)]\n",
    "\n",
    "# tls\n",
    "tls = TfmdLists(items, tfms, splits=splits)\n",
    "\n",
    "# dls\n",
    "dls = tls.dataloaders(bs=bs, after_batch=AddChannel())\n",
    "\n",
    "# GPU\n",
    "dls = dls.cuda()\n",
    "\n",
    "# test get one batch\n",
    "b = dls.one_batch()\n",
    "print(type(b), b[0].shape, b[1].shape)\n",
    "print(len(dls.train), len(dls.valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c96e69",
   "metadata": {},
   "source": [
    "# Metric\n",
    "\n",
    "Linear combination of Dice and Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "entitled-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(input, target):\n",
    "    iflat = input.contiguous().view(-1)\n",
    "    tflat = target.contiguous().view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    return ((2. * intersection) /\n",
    "           (iflat.sum() + tflat.sum()))\n",
    "\n",
    "def dice_score(input, target):\n",
    "    return dice(input.argmax(1), target)\n",
    "\n",
    "def dice_loss(input, target): \n",
    "    return 1 - dice(input.softmax(1)[:, 1], target)\n",
    "\n",
    "def loss(input, target):\n",
    "    return dice_loss(input, target) + nn.CrossEntropyLoss()(input, target[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db375a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipython nbconvert --to python  '6 - Dataloaders- NB - Simple-Copy1.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59acd0f9",
   "metadata": {},
   "source": [
    "# Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d86c1219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8717d790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone = efficientnet_b0 #r3d_18 (pretrained?)\n",
    "# learn    = unet_learner_3d(dls, backbone, n_out=2,  metrics = dice_score,\n",
    "#                           model_dir = \"./models\", cbs = [SaveModelCallback(monitor='dice_score')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "511d80b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = efficientnet_b0 #r3d_18 (pretrained?)\n",
    "learn    = unet_learner_3d(dls, backbone, n_out=2,  metrics = dice_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89be5e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with learn.distrib_ctx():\n",
    "#     learn.fit_one_cycle(1, 3e-1, wd = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e99c97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU\n",
    "n_gpu = torch.cuda.device_count()\n",
    "n_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f557e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = learn.parallel_ctx if gpu is None and n_gpu else learn.distrib_ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8de170fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/labcomputer/anaconda3/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "learn.model = nn.DataParallel(learn.model)\n",
    "learn.model = learn.model.cuda()\n",
    "#learn = learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b946e643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f5d271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2389ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gpu = torch.cuda.device_count()\n",
    "        ctx = learn.parallel_ctx if gpu is None and n_gpu else learn.distrib_ctx\n",
    "\n",
    "        with partial(ctx, gpu)(): # distributed traing requires \"-m fastai2.launch\"\n",
    "            print(f\"Training in {ctx.__name__} context on GPU {gpu if gpu is not None else list(range(n_gpu))}\")\n",
    "            learn.fit_one_cycle(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284eea06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28669a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c345a3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 2.2614049911499023 s\n",
      "Batch: x,y\n",
      "<class 'torch.Tensor'> torch.Size([1, 1, 50, 50, 50]) torch.float32 \n",
      " <class 'torch.Tensor'> torch.Size([1, 1, 50, 50, 50]) torch.int64\n",
      "Pred shape\n",
      "<class 'torch.Tensor'> torch.Size([1, 2, 50, 50, 50]) torch.float32\n",
      "Loss\n",
      "tensor(0.6317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "<faimed3d.models.losses.DiceLoss object at 0x7fb9dc3c07d0>\n"
     ]
    }
   ],
   "source": [
    "# test:\n",
    "\n",
    "#dls.device = \"cpu\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "x,y = dls.one_batch()\n",
    "#x,y = to_cpu(x), to_cpu(y)\n",
    "\n",
    "pred = learn.model(x)\n",
    "loss = learn.loss_func(pred, y)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"Elapsed: {elapsed} s\")\n",
    "print(\"Batch: x,y\")\n",
    "print(type(x), x.shape, x.dtype, \"\\n\", type(y), y.shape, y.dtype)\n",
    "\n",
    "print(\"Pred shape\")\n",
    "print(type(pred), pred.shape, pred.dtype)\n",
    "\n",
    "print(\"Loss\")\n",
    "print(loss)\n",
    "print(learn.loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52f35922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 3            |        cudaMalloc retries: 3         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |    7989 MB |    8562 MB |   39077 MB |   31087 MB |\n",
      "|       from large pool |    7939 MB |    8531 MB |   38808 MB |   30868 MB |\n",
      "|       from small pool |      50 MB |      57 MB |     269 MB |     218 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |    7989 MB |    8562 MB |   39077 MB |   31087 MB |\n",
      "|       from large pool |    7939 MB |    8531 MB |   38808 MB |   30868 MB |\n",
      "|       from small pool |      50 MB |      57 MB |     269 MB |     218 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    8164 MB |    8678 MB |   23800 MB |   15636 MB |\n",
      "|       from large pool |    8110 MB |    8646 MB |   23634 MB |   15524 MB |\n",
      "|       from small pool |      54 MB |      60 MB |     166 MB |     112 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |  178466 KB |    3068 MB |   11177 MB |   11002 MB |\n",
      "|       from large pool |  174733 KB |    3052 MB |   10809 MB |   10639 MB |\n",
      "|       from small pool |    3733 KB |      17 MB |     367 MB |     363 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |    1242    |    1285    |    5603    |    4361    |\n",
      "|       from large pool |     195    |     196    |     363    |     168    |\n",
      "|       from small pool |    1047    |    1258    |    5240    |    4193    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |    1242    |    1285    |    5603    |    4361    |\n",
      "|       from large pool |     195    |     196    |     363    |     168    |\n",
      "|       from small pool |    1047    |    1258    |    5240    |    4193    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      55    |      56    |     134    |      79    |\n",
      "|       from large pool |      28    |      29    |      51    |      23    |\n",
      "|       from small pool |      27    |      30    |      83    |      56    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      29    |      58    |    1172    |    1143    |\n",
      "|       from large pool |      11    |      14    |      86    |      75    |\n",
      "|       from small pool |      18    |      57    |    1086    |    1068    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8962fb76",
   "metadata": {},
   "source": [
    "# LR Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c58b4d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.33113112449646, lr_steep=0.2089296132326126)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fefd197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE learn.fit one cycle\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>dice_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.42% [1/240 00:07<30:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling .backward() or autograd.grad() the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-483d1531d356>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PRE learn.fit one cycle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3e-1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai-2.2.5-py3.7.egg/fastai/callback/schedule.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    110\u001b[0m     scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\n\u001b[1;32m    111\u001b[0m               'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mParamScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai-2.2.5-py3.7.egg/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_end_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai-2.2.5-py3.7.egg/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai-2.2.5-py3.7.egg/fastai/learner.py\u001b[0m in \u001b[0;36m_do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai-2.2.5-py3.7.egg/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai-2.2.5-py3.7.egg/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai-2.2.5-py3.7.egg/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai-2.2.5-py3.7.egg/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai-2.2.5-py3.7.egg/fastai/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai-2.2.5-py3.7.egg/fastai/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_one_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai-2.2.5-py3.7.egg/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai-2.2.5-py3.7.egg/fastai/learner.py\u001b[0m in \u001b[0;36m_do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before_backward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'step'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelStepException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling .backward() or autograd.grad() the first time."
     ]
    }
   ],
   "source": [
    "print(\"PRE learn.fit one cycle\")\n",
    "learn.fit_one_cycle(1, 3e-1, wd = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd633caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unfreeze, learn 50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='11' class='' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      22.00% [11/50 06:30<23:03]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>dice_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.310232</td>\n",
       "      <td>0.328858</td>\n",
       "      <td>0.349853</td>\n",
       "      <td>00:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.305128</td>\n",
       "      <td>0.300676</td>\n",
       "      <td>0.248583</td>\n",
       "      <td>00:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.298281</td>\n",
       "      <td>0.287270</td>\n",
       "      <td>0.341916</td>\n",
       "      <td>00:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.287488</td>\n",
       "      <td>0.266072</td>\n",
       "      <td>0.507983</td>\n",
       "      <td>00:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.271086</td>\n",
       "      <td>0.235373</td>\n",
       "      <td>0.490968</td>\n",
       "      <td>00:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.250404</td>\n",
       "      <td>0.250527</td>\n",
       "      <td>0.367101</td>\n",
       "      <td>00:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.232461</td>\n",
       "      <td>0.233408</td>\n",
       "      <td>0.497551</td>\n",
       "      <td>00:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.214318</td>\n",
       "      <td>0.204818</td>\n",
       "      <td>0.551471</td>\n",
       "      <td>00:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.197701</td>\n",
       "      <td>0.183061</td>\n",
       "      <td>0.597465</td>\n",
       "      <td>00:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.179871</td>\n",
       "      <td>0.158521</td>\n",
       "      <td>0.637779</td>\n",
       "      <td>00:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.166137</td>\n",
       "      <td>0.253356</td>\n",
       "      <td>0.463001</td>\n",
       "      <td>00:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8' class='' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      40.00% [8/20 00:20<00:30 0.1625]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"unfreeze, learn 50\")\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(50, 3e-3, wd = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fdc0b435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=6.309573450380412e-08, lr_steep=6.309573450380412e-07)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7127658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"unfreeze, learn 50\")\n",
    "# learn.unfreeze()\n",
    "# learn.fit_one_cycle(50, 1e-3, wd = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd40f6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4191348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5737f38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testmask = torch.tensor([[[False, False, False], [False, False, False], [True, True, True]],\n",
    "#                        [[False, False, False], [False, False, True], [True, True, True]],\n",
    "#                        [[False, False, False], [False, False, False], [False, False, False]]])\n",
    "# testmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a6a080bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testmaskN = np.array(testmask)\n",
    "# testmaskN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c1383dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maskT = testmask.type(torch.BoolTensor)\n",
    "\n",
    "# iT = torch.any(maskT, dim=(1,2))\n",
    "# jT = torch.any(maskT, dim=(0,2))\n",
    "# kT = torch.any(maskT, dim=(0,1))\n",
    "\n",
    "# iminT, imaxT = torch.where(iT)[0][[0, -1]]\n",
    "# jminT, jmaxT = torch.where(jT)[0][[0, -1]]\n",
    "# kminT, kmaxT = torch.where(kT)[0][[0, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "64d3afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maskN = np.array(testmask).astype(bool)\n",
    "    \n",
    "# iN = np.any(maskN, axis=(1, 2))\n",
    "# jN = np.any(maskN, axis=(0, 2))\n",
    "# kN = np.any(maskN, axis=(0, 1))\n",
    "\n",
    "# iminN, imaxN = np.where(iN)[0][[0, -1]]\n",
    "# jminN, jmaxN = np.where(jN)[0][[0, -1]]\n",
    "# kminN, kmaxN = np.where(kN)[0][[0, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1201e773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maskT.shape, maskN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8611c9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(iT)\n",
    "# print(jT)\n",
    "# print(kT)\n",
    "# print([x for x in (iminT, imaxT, jminT, jmaxT, kminT, kmaxT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7d428ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(iN)\n",
    "# print(jN)\n",
    "# print(kN)\n",
    "# print([int(x) for x in (iminN, imaxN, jminN, jmaxN, kminN, kmaxN)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93e81e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def torch_mask2bbox(mask):\n",
    "#         mask = mask.type(torch.BoolTensor)\n",
    "\n",
    "#         i = torch.any(mask, dim=0)\n",
    "#         j = torch.any(mask, dim=1)\n",
    "#         k = torch.any(mask, dim=2)\n",
    "\n",
    "#         imin, imax = torch.where(i)[0][[0, -1]]\n",
    "#         jmin, jmax = torch.where(j)[0][[0, -1]]\n",
    "#         kmin, kmax = torch.where(k)[0][[0, -1]]\n",
    "\n",
    "#         # inclusive idxs\n",
    "#         return imin, imax+1, jmin, jmax+1, kmin, kmax+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
