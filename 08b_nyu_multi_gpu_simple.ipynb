{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1db8c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATALOADER PARAMS\n",
    "bs          = 20\n",
    "nepochs     = 30\n",
    "num_workers = 2\n",
    "\n",
    "# PREPROCESS (Isotropic, PadResize)\n",
    "iso       = 3\n",
    "maxs      = [87, 90, 90]\n",
    "\n",
    "# Train:Valid:Test = 60:20:20\n",
    "train_pct, valid_pct, test_pct = .60, .20, .20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bab7ac06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#GPU = 0, #CPU = 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# CHECK HARDWARE \n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "gpu_count = torch.cuda.device_count()\n",
    "cpu_count = os.cpu_count()\n",
    "print(\"#GPU = {0:d}, #CPU = {1:d}\".format(gpu_count, cpu_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3321cd55",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "Train hybrid OBELISK-NET/UNET. Tune batch size and presize HWD dimensions.\n",
    "- Preprocess: Smooth, intensity norm (N4 bias, hist bin matching)\n",
    "- Augmentations: flip, orientation, 10 deg\n",
    "- Thanks to: OBELISK, FAIMED3D\n",
    "    - https://github.com/mattiaspaul/OBELISK\n",
    "    -  https://github.com/kbressem/faimed3d/blob/main/examples/3d_segmentation.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd2edd3",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55a9cc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders in data src: ICMB, ABVIB (1).zip, central.xnat.org, ADNI, PPMI, Oasis_long, samir_labels, ACRIN-FMISO-Brain, LGG-1p19qDeletion, REMBRANDT, AIBL, test.txt, CPTAC-GBM, ABIDE-ABIDE-top.txt, TCGA-GBM, TCGA-LGG, ABVIB, ABIDE, AIBL.zip\n",
      "Folders in label src (data w labels): 50155-50212, 50313-50372, 50213-50312, 50373-50453, 50002-50153\n",
      "Folders in ABIDE src (data wo labels) PAD, ABIDE_1, ABIDE\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Paths to (1) code (2) data (3) saved models\n",
    "code_src    = \"/gpfs/home/gologr01\"\n",
    "data_src    = \"/gpfs/data/oermannlab/private_data/DeepPit/PitMRdata\"\n",
    "model_src   = \"/gpfs/data/oermannlab/private_data/DeepPit/saved_models\"\n",
    "\n",
    "# UMich \n",
    "# code src: \"/home/labcomputer/Desktop/Rachel\"\n",
    "# data src: \"../../../../..//media/labcomputer/e33f6fe0-5ede-4be4-b1f2-5168b7903c7a/home/rachel/\"\n",
    "\n",
    "deepPit_src = f\"{code_src}/DeepPit\"\n",
    "obelisk_src = f\"{code_src}/OBELISK\"\n",
    "label_src   = f\"{data_src}/samir_labels\"\n",
    "ABIDE_src   = f\"{data_src}/ABIDE\"\n",
    "\n",
    "# print\n",
    "print(\"Folders in data src: \", end=\"\"); print(*os.listdir(data_src), sep=\", \")\n",
    "print(\"Folders in label src (data w labels): \", end=\"\"); print(*os.listdir(label_src), sep=\", \")\n",
    "print(\"Folders in ABIDE src (data wo labels) \", end=\"\"); print(*os.listdir(ABIDE_src), sep=\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabe2986",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "684b0b85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from transforms import AddChannel, Iso, PadSz\n",
    "\n",
    "# Utilities\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Input IO\n",
    "import SimpleITK as sitk\n",
    "import meshio\n",
    "\n",
    "# Numpy and Pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as DF\n",
    "\n",
    "# Fastai + distributed training\n",
    "from fastai import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.basics import *\n",
    "from fastai.distributed import *\n",
    "\n",
    "# PyTorch\n",
    "from torchvision.models.video import r3d_18\n",
    "from fastai.callback.all import SaveModelCallback\n",
    "from torch import nn\n",
    "\n",
    "# Obelisk\n",
    "sys.path.append(deepPit_src)\n",
    "sys.path.append(obelisk_src)\n",
    "\n",
    "# OBELISK\n",
    "from utils import *\n",
    "from models import obelisk_visceral, obeliskhybrid_visceral\n",
    "\n",
    "# 3D extension to FastAI\n",
    "# from faimed3d.all import *\n",
    "\n",
    "# Helper functions\n",
    "from helpers.preprocess import get_data_dict, paths2objs, folder2objs, seg2mask, mask2bbox, print_bbox, get_bbox_size, print_bbox_size\n",
    "from helpers.general import sitk2np, np2sitk, print_sitk_info, round_tuple, lrange, lmap, get_roi_range, numbers2groups\n",
    "from helpers.viz import viz_axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07e4d4e",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59815d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 335 items in dataset.\n",
      "Train: 215 items.\n",
      "Valid: 53 items.\n",
      "Test: 67 items.\n",
      "Model name: iso_3mm_pad_87_90_90_bs_20_test_sz_67_epochs_10_time_Thu Jun 24 13:39:52 2021\n"
     ]
    }
   ],
   "source": [
    "# Get data dict\n",
    "data = {}\n",
    "folders = os.listdir(label_src)\n",
    "for folder in folders: data.update(get_data_dict(f\"{label_src}/{folder}\"))\n",
    "\n",
    "# Convert data dict => items (path to MR, path to Segm tensor)\n",
    "items = list(data.values())\n",
    "\n",
    "# Split train/valid/test split\n",
    "train_idxs, test_idxs = RandomSplitter(valid_pct=test_pct)(items)\n",
    "train_items = [items[i] for i in train_idxs]\n",
    "test_items  = [items[i] for i in test_idxs]\n",
    "\n",
    "train_idxs, valid_idxs = RandomSplitter(valid_pct=valid_pct)(train_items)\n",
    "train_items = [items[i] for i in train_idxs]\n",
    "valid_items = [items[i] for i in valid_idxs]\n",
    "\n",
    "# print\n",
    "print(f\"Total {len(items)} items in dataset.\")\n",
    "print(f\"Train: {len(train_items)} items.\")\n",
    "print(f\"Valid: {len(valid_items)} items.\")\n",
    "print(f\"Test: {len(test_items)} items.\")\n",
    "\n",
    "# Save test idxs\n",
    "\n",
    "# file name\n",
    "model_time = time.ctime() # 'Mon Oct 18 13:35:29 2010'\n",
    "model_name = f\"iso_{iso}mm_pad_{maxs[0]}_{maxs[1]}_{maxs[2]}_bs_{bs}_test_sz_{len(test_items)}_epochs_{nepochs}_time_{model_time}\"\n",
    "print(f\"Model name: {model_name}\")\n",
    "\n",
    "# save test set indices\n",
    "with open(f\"{model_src}/{model_name}_test_items.pkl\", 'wb') as f:\n",
    "    pickle.dump(list(test_items), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fdd99f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "('/gpfs/data/oermannlab/private_data/DeepPit/PitMRdata/samir_labels/50155-50212/50208/MP-RAGE/2000-01-01_00_00_00.0/S164924/ABIDE_50208_MRI_MP-RAGE_br_raw_20120830192311510_S164924_I328934.nii', '/gpfs/data/oermannlab/private_data/DeepPit/PitMRdata/samir_labels/50155-50212/50208/seg.pt')\n"
     ]
    }
   ],
   "source": [
    "# with open(f\"{model_src}/{model_name}_test_items.pkl\", 'rb') as f:\n",
    "#     check_test_items = pickle.load(f)\n",
    "#     print(check_test_items==test_items)\n",
    "#     print(check_test_items[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c01f18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # unique, for rapid prototyping\n",
    "\n",
    "# # MR files: unique sz, sp, dir\n",
    "# with open(f'{deepPit_src}/saved_metadata/unique_sz_sp_dir.pkl', 'rb') as f:\n",
    "#     unique = pickle.load(f)\n",
    "\n",
    "# # Create (MR path, Segm path) item from MR path\n",
    "# def get_folder_name(s):\n",
    "#     start = s.index(\"samir_labels/\")\n",
    "#     s = s[start + len(\"samir_labels/50373-50453/\"):]\n",
    "#     return s[0:s.index(\"/\")]\n",
    "\n",
    "# def change_prefix(s):\n",
    "#     start = s.index(\"samir_labels/\")\n",
    "#     return f\"{label_src}/{s[start+len('samir_labels/'):]}\"\n",
    "\n",
    "# # get unique\n",
    "# unique = [(change_prefix(mr), data[get_folder_name(mr)][1]) for mr in unique]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129aecee",
   "metadata": {},
   "source": [
    "# Transforms\n",
    "\n",
    "1. Isotropic 3mm or Resize to 50x50x50 dimensions\n",
    "2. Crop/Pad to common dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f61ce3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test\n",
    "\n",
    "# tfms = [Iso(3)]\n",
    "# tls = TfmdLists(unique, tfms)\n",
    "\n",
    "# start = time.time()\n",
    "# iso_szs = [mr.shape for mr,mk in tls]\n",
    "# elapsed = time.time() - start\n",
    "\n",
    "# print(f\"Elapsed: {elapsed} s for {len(unique)} items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65040f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# iso_szs = [mr.shape for mr,mk in tls]\n",
    "# elapsed = time.time() - start\n",
    "\n",
    "# print(f\"Elapsed: {elapsed} s for {len(unique)} items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dcef259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(*[f\"{get_folder_name(mr)}: {tuple(sz)}\" for (mr,mk),sz in zip(unique, iso_szs)], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "594e534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxs = [int(x) for x in torch.max(torch.tensor(iso_szs), dim=0).values]\n",
    "# print(\"Maxs: \", maxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236eb374",
   "metadata": {},
   "source": [
    "# Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11ff1d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test\n",
    "# iso_items = list(tls[0:2])\n",
    "\n",
    "# # tfms\n",
    "# pad_tfms = [PadSz(maxs)]\n",
    "\n",
    "# # tls\n",
    "# pad_tls = TfmdLists(iso_items, pad_tfms)\n",
    "\n",
    "# pad_tls[0][0].shape, pad_tls[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683aaf17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26ba5050",
   "metadata": {},
   "source": [
    "# Dataloaders\n",
    "\n",
    "TODO augmentations.\n",
    "\n",
    "- dset = tfms applied to items\n",
    "- splits into training/valid\n",
    "- bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "702c1a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.21906757354736328 s for 268 items\n",
      "<class 'tuple'> torch.Size([20, 1, 87, 90, 90]) torch.Size([20, 1, 87, 90, 90])\n",
      "10 3\n"
     ]
    }
   ],
   "source": [
    "# time it\n",
    "start = time.time()\n",
    "\n",
    "# splits\n",
    "#splits = RandomSplitter(seed=42)(subset)\n",
    "#print(f\"Training: {len(splits[0])}, Valid: {len(splits[1])}\")\n",
    "\n",
    "# tfms\n",
    "tfms = [Iso(3), PadSz(maxs)]\n",
    "\n",
    "# tls\n",
    "tls = TfmdLists(items, tfms, splits=(train_idxs, valid_idxs))\n",
    "\n",
    "# dls\n",
    "dls = tls.dataloaders(bs=bs, after_batch=AddChannel(), num_workers=num_workers)\n",
    "\n",
    "# GPU\n",
    "dls = dls.cuda()\n",
    "\n",
    "# end timer\n",
    "elapsed = time.time() - start\n",
    "print(f\"Elapsed time: {elapsed} s for {len(train_idxs) + len(valid_idxs)} items\")\n",
    "\n",
    "# test get one batch\n",
    "b = dls.one_batch()\n",
    "print(type(b), b[0].shape, b[1].shape)\n",
    "print(len(dls.train), len(dls.valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba84a0c7",
   "metadata": {},
   "source": [
    "# Metric\n",
    "\n",
    "Linear combination of Dice and Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2499fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(input, target):\n",
    "    iflat = input.contiguous().view(-1)\n",
    "    tflat = target.contiguous().view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    return ((2. * intersection) /\n",
    "           (iflat.sum() + tflat.sum()))\n",
    "\n",
    "def dice_score(input, target):\n",
    "    return dice(input.argmax(1), target)\n",
    "\n",
    "def dice_loss(input, target): \n",
    "    return 1 - dice(input.softmax(1)[:, 1], target)\n",
    "\n",
    "def loss(input, target):\n",
    "    return dice_loss(input, target) + nn.CrossEntropyLoss()(input, target[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b4aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "\n",
    "# segs = torch.cat([tl[1] for tl in dls.train],0)\n",
    "# print(segs.shape)\n",
    "\n",
    "# elapsed = time.time() - start\n",
    "\n",
    "# print(f\"Elapsed time: {elapsed} s for {len(segs)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2e265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weight = torch.sqrt(1.0/(torch.bincount(segs.view(-1)).float()))\n",
    "# class_weight = class_weight/class_weight.mean()\n",
    "# class_weight[0] = 0.5\n",
    "# np.set_printoptions(formatter={'float': '{: 0.2f}'.format})\n",
    "# print('inv sqrt class_weight',class_weight.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415185d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import my_ohem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d12e3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_weight = torch.load(\"saved_metadata/class_weights.pt\")\n",
    "# class_weights = [0, pos_weight]\n",
    "\n",
    "# # inv\n",
    "# class_weights [1.0/x for x in class_wei]\n",
    "# my_criterion = my_ohem(.25,[0, pos_weight]) #.cuda())#0.25 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56920746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obelisk_loss_fn(predict, target): return my_criterion(F.log_softmax(predict,dim=1),target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce2404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipython nbconvert --to python  '6 - Dataloaders- NB - Simple-Copy1.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d7809f",
   "metadata": {},
   "source": [
    "# Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b8faf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "66cc1f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBELISK-NET from github\n",
    "from models import obelisk_visceral, obeliskhybrid_visceral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13fe9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_res = maxs\n",
    "\n",
    "learn = Learner(dls=dls, \\\n",
    "                model=obeliskhybrid_visceral(num_labels=2, full_res=full_res), \\\n",
    "                loss_func= loss, #DiceLoss(), #nn.CrossEntropyLoss(), \\\n",
    "                metrics = dice_score, \\\n",
    "                model_dir = model_src, \\\n",
    "                cbs = [SaveModelCallback(monitor='dice_score', fname=model_name, with_opt=True)])\n",
    "\n",
    "# SaveModelCallback: model_dir = \"./models\", cbs = [SaveModelCallback(monitor='dice_score')]\n",
    "\n",
    "# GPU\n",
    "learn.model = learn.model.cuda()\n",
    "\n",
    "#learn = learn.to_distributed(args.local_rank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8269d3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test:\n",
    "\n",
    "# #dls.device = \"cpu\"\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# x,y = dls.one_batch()\n",
    "# #x,y = to_cpu(x), to_cpu(y)\n",
    "\n",
    "# pred = learn.model(x)\n",
    "# loss = learn.loss_func(pred, y)\n",
    "\n",
    "# elapsed = time.time() - start\n",
    "\n",
    "# print(f\"Elapsed: {elapsed} s\")\n",
    "# print(\"Batch: x,y\")\n",
    "# print(type(x), x.shape, x.dtype, \"\\n\", type(y), y.shape, y.dtype)\n",
    "\n",
    "# print(\"Pred shape\")\n",
    "# print(type(pred), pred.shape, pred.dtype)\n",
    "\n",
    "# print(\"Loss\")\n",
    "# print(loss)\n",
    "# print(learn.loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceedd82",
   "metadata": {},
   "source": [
    "# LR Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b2d803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dcb74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PRE learn.fit one cycle\")\n",
    "with learn.distrib_ctx():\n",
    "    learn.fit_one_cycle(1, 3e-3, wd = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f23ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"unfreeze, learn 50\")\n",
    "learn.unfreeze()\n",
    "with learn.distrib_ctx():\n",
    "    learn.fit_one_cycle(nepochs, 3e-3, wd = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5b84ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.save('iso_3mm_pad_87_90_90_subset_50_epochs_50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb52fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddc310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4975b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"unfreeze, learn 50\")\n",
    "# learn.unfreeze()\n",
    "# learn.fit_one_cycle(50, 1e-3, wd = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfe0865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f079af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae06db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testmask = torch.tensor([[[False, False, False], [False, False, False], [True, True, True]],\n",
    "#                        [[False, False, False], [False, False, True], [True, True, True]],\n",
    "#                        [[False, False, False], [False, False, False], [False, False, False]]])\n",
    "# testmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fb68b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testmaskN = np.array(testmask)\n",
    "# testmaskN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ed8d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maskT = testmask.type(torch.BoolTensor)\n",
    "\n",
    "# iT = torch.any(maskT, dim=(1,2))\n",
    "# jT = torch.any(maskT, dim=(0,2))\n",
    "# kT = torch.any(maskT, dim=(0,1))\n",
    "\n",
    "# iminT, imaxT = torch.where(iT)[0][[0, -1]]\n",
    "# jminT, jmaxT = torch.where(jT)[0][[0, -1]]\n",
    "# kminT, kmaxT = torch.where(kT)[0][[0, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065c9ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maskN = np.array(testmask).astype(bool)\n",
    "    \n",
    "# iN = np.any(maskN, axis=(1, 2))\n",
    "# jN = np.any(maskN, axis=(0, 2))\n",
    "# kN = np.any(maskN, axis=(0, 1))\n",
    "\n",
    "# iminN, imaxN = np.where(iN)[0][[0, -1]]\n",
    "# jminN, jmaxN = np.where(jN)[0][[0, -1]]\n",
    "# kminN, kmaxN = np.where(kN)[0][[0, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520981df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maskT.shape, maskN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c270cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(iT)\n",
    "# print(jT)\n",
    "# print(kT)\n",
    "# print([x for x in (iminT, imaxT, jminT, jmaxT, kminT, kmaxT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ec78a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(iN)\n",
    "# print(jN)\n",
    "# print(kN)\n",
    "# print([int(x) for x in (iminN, imaxN, jminN, jmaxN, kminN, kmaxN)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2842131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def torch_mask2bbox(mask):\n",
    "#         mask = mask.type(torch.BoolTensor)\n",
    "\n",
    "#         i = torch.any(mask, dim=0)\n",
    "#         j = torch.any(mask, dim=1)\n",
    "#         k = torch.any(mask, dim=2)\n",
    "\n",
    "#         imin, imax = torch.where(i)[0][[0, -1]]\n",
    "#         jmin, jmax = torch.where(j)[0][[0, -1]]\n",
    "#         kmin, kmax = torch.where(k)[0][[0, -1]]\n",
    "\n",
    "#         # inclusive idxs\n",
    "#         return imin, imax+1, jmin, jmax+1, kmin, kmax+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
