{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unable-instruction",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "The goal of this notebook is to train a **OBELISK-NET** to output binary mask representing the sella turcica ROI.\n",
    "\n",
    "With gratitude to \n",
    "- https://github.com/mattiaspaul/OBELISK/blob/master/models.py\n",
    "- https://github.com/kbressem/faimed3d/blob/main/examples/3d_segmentation.md\n",
    "\n",
    "TODO\n",
    "- Augmentations: flip, orientation\n",
    "- Intensity normalization: N4 bias correction, hist bin matching, tissue intensity,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae248ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input sz 50\n",
    "# bs 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0187b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBELISK-NET from github\n",
    "import sys\n",
    "sys.path.append('/home/labcomputer/Desktop/Rachel/OBELISK')\n",
    "from models import obelisk_visceral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c149874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0 : b'GeForce GTX 1080 Ti'\n",
      "Device 1 : b'GeForce GTX 1080'\n",
      "gpu: 0%, gpu-mem: 0%\n",
      "is cuda available? True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Check GPU stats\n",
    "\n",
    "from pynvml import *\n",
    "nvmlInit()\n",
    "try:\n",
    "    deviceCount = nvmlDeviceGetCount()\n",
    "    for i in range(deviceCount):\n",
    "        handle = nvmlDeviceGetHandleByIndex(i)\n",
    "        print(\"Device\", i, \":\", nvmlDeviceGetName(handle))\n",
    "except NVMLError as error:\n",
    "    print(error)\n",
    "    \n",
    "# https://docs.fast.ai/dev/gpu.html\n",
    "import nvidia_smi\n",
    "\n",
    "nvidia_smi.nvmlInit()\n",
    "handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
    "# card id 0 hardcoded here, there is also a call to get all available card ids, so we could iterate\n",
    "\n",
    "res = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)\n",
    "print(f'gpu: {res.gpu}%, gpu-mem: {res.memory}%')\n",
    "\n",
    "import torch\n",
    "print(\"is cuda available?\", torch.cuda.is_available() )\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# hm\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81bf7d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27aa128",
   "metadata": {},
   "source": [
    "# Data Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7031ab",
   "metadata": {},
   "source": [
    "Set path to where data is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "775df797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebc81c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABIDE', 'PPMI', 'ABVIB', 'samir_labels']\n",
      "['50155-50212', '50373-50453', '50002-50153', '50213-50312', '50313-50372']\n"
     ]
    }
   ],
   "source": [
    "# Get path to 4 TB HD\n",
    "\n",
    "# /media/labcomputer/e33f6fe0-5ede-4be4-b1f2-5168b7903c7a/home\n",
    "\n",
    "# wsl: /home/rgologorsky/DeepPit\n",
    "hd_path = \"../\" * 5 + \"/media/labcomputer/e33f6fe0-5ede-4be4-b1f2-5168b7903c7a\" + \"/home/rachel/PitMRdata\"\n",
    "\n",
    "# all folders in HD\n",
    "all_folders = os.listdir(hd_path)\n",
    "\n",
    "print(all_folders)\n",
    "\n",
    "# labels\n",
    "print(os.listdir(f\"{hd_path}/samir_labels\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02841785",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rough-climate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from faimed3d.all import *\n",
    "from fastai import *\n",
    "from torchvision.models.video import r3d_18\n",
    "from fastai.callback.all import SaveModelCallback\n",
    "from torch import nn\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import meshio\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as DF\n",
    "\n",
    "from helpers_preprocess import get_data_dict, paths2objs, folder2objs, seg2mask\n",
    "\n",
    "from helpers_general import sitk2np, print_sitk_info, round_tuple, lrange, lmap, get_roi_range, numbers2groups\n",
    "\n",
    "# imports\n",
    "from helpers_general import sitk2np, np2sitk, round_tuple, lrange, get_roi_range, numbers2groups\n",
    "from helpers_preprocess import mask2bbox, print_bbox, get_bbox_size, print_bbox_size, get_data_dict, folder2objs\n",
    "from helpers_viz import viz_axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959ca43b",
   "metadata": {},
   "source": [
    "# Get Items\n",
    "\n",
    "Item = (path to MR, path to Segmentation obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ee44fdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_sz = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "72985d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data dict: 335 items.\n",
      "Subset data dict: 300 items.\n"
     ]
    }
   ],
   "source": [
    "# get items = (mask_fn, nii_fn)\n",
    "train_path = f\"{hd_path}/samir_labels\"\n",
    "folders = os.listdir(train_path)\n",
    "\n",
    "# get all items\n",
    "data_dict_full = {}\n",
    "for folder in folders:\n",
    "    data_dict_full.update(get_data_dict(f\"{train_path}/{folder}\"))\n",
    "\n",
    "items_full = list(data_dict_full.values())\n",
    "\n",
    "# subset 300 for training/valid; 35 for test\n",
    "rand_idx = torch.randperm(subset_sz)\n",
    "items = np.array(items_full)[rand_idx]\n",
    "\n",
    "print(f\"Full data dict: {len(data_dict_full)} items.\")\n",
    "print(f\"Subset data dict: {len(items)} items.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdf8ee3",
   "metadata": {},
   "source": [
    "# Transforms\n",
    "\n",
    "- PathToSITK (*convert paths to SITK obj*)\n",
    "- Resize (*common size, isotropic spacing*)\n",
    "- ToTensor (*convert to Pytorch tensor*)\n",
    "- TensorSlice & Center Crop (*slice 3d tensor to center part containing sella*)\n",
    "- Normalize (*scale image intensities? - diff tissues diff intensities?*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "59d5815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoAll(ItemTransform):\n",
    "    \n",
    "    def __init__(self, new_sp = 1):\n",
    "        self.new_sp = new_sp\n",
    "        \n",
    "    def encodes(self, x):\n",
    "        # get sitk objs\n",
    "        im_path, segm_path = x\n",
    "        folder  = Path(segm_path).parent.name\n",
    "        ras_adj = int(folder) in range(50455, 50464)\n",
    "\n",
    "        mr         = sitk.ReadImage(im_path, sitk.sitkFloat32)\n",
    "        segm       = meshio.read(segm_path)\n",
    "        mask_arr   = seg2mask(mr, segm, ras_adj)\n",
    "\n",
    "        # resize so isotropic spacing\n",
    "        orig_sp = mr.GetSpacing()\n",
    "        orig_sz = mr.GetSize()\n",
    "        new_sz = [int(round(osz*ospc/self.new_sp)) for osz,ospc in zip(orig_sz, orig_sp)]\n",
    "\n",
    "        im = torch.swapaxes(torch.tensor(sitk.GetArrayFromImage(mr)), 0, 2)\n",
    "        mk = torch.tensor(mask_arr).float()\n",
    "\n",
    "        while im.ndim < 5: \n",
    "            im = im.unsqueeze(0)\n",
    "            mk = mk.unsqueeze(0)\n",
    "\n",
    "        return F.interpolate(im, size = new_sz, mode = 'trilinear', align_corners=False).squeeze(), \\\n",
    "                F.interpolate(mk, size = new_sz, mode = 'nearest').squeeze().long()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-attitude",
   "metadata": {},
   "source": [
    "# Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fe42841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop center\n",
    "class CenterCropTfm(Transform):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        \n",
    "    def encodes(self, arr):\n",
    "        return self.cropND(arr, self.size)\n",
    "    \n",
    "    # https://stackoverflow.com/questions/39382412/crop-center-portion-of-a-numpy-image\n",
    "    @staticmethod\n",
    "    def cropND(img, bounding):\n",
    "        start = tuple(map(lambda a, da: a//2-da//2, img.shape, bounding))\n",
    "        end = tuple(map(operator.add, start, bounding))\n",
    "        slices = tuple(map(slice, start, end))\n",
    "        return img[slices]\n",
    "    \n",
    "# crop by coords\n",
    "class CropBBox(Transform):\n",
    "    def __init__(self, bbox):\n",
    "        self.bbox = bbox\n",
    "    \n",
    "    def encodes(self, arr):\n",
    "        imin, imax, jmin, jmax, kmin, kmax = self.bbox\n",
    "        cropped = arr[imin:imax, jmin:jmax, kmin:kmax]\n",
    "        \n",
    "        # pad if needed\n",
    "        new_size = [imax-imin, jmax-jmin, kmax-kmin]\n",
    "        \n",
    "        pad = [x-y for x,y in zip(new_size, arr.shape)]\n",
    "        pad = [a for amt in pad for a in (amt//2, amt-amt//2)]\n",
    "        pad.reverse()\n",
    "        \n",
    "        return F.pad(arr, pad, mode='constant', value=0)\n",
    "    \n",
    "\n",
    "# add padding\n",
    "class Pad(Transform):\n",
    "    def __init__(self, sz):\n",
    "        self.sz = sz\n",
    "        \n",
    "    def encodes(self, arr):\n",
    "        pad = [x-y for x,y in zip(self.sz, arr.shape)]\n",
    "        pad = [a for amt in pad for a in (amt//2, amt-amt//2)]\n",
    "        pad.reverse()\n",
    "        \n",
    "        return F.pad(arr, pad, mode='constant', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ee03ba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from faimed3d 03_transforms.ipynb\n",
    "def resize_3d(t, size, scale_factor=None,\n",
    "              mode='trilinear', align_corners=True, recompute_scale_factor=None):\n",
    "    '''\n",
    "    A function to resize a 3D image using torch.nn.functional.interpolate\n",
    "\n",
    "    Args:\n",
    "        t (Tensor): a 3D or 4D Tensor to be resized\n",
    "        size (int): a tuple with the new x,y,z dimensions of the tensor after resize\n",
    "        scale_factor, mode, align_corners, recompute_scale_factor: args from F.interpolate\n",
    "    Returns:\n",
    "        A new `Tensor` with Tensor.size = size\n",
    "    '''\n",
    "    old_sz = t.shape[-3:]\n",
    "    if hasattr(t, '_metadata'):\n",
    "        spacing = t.get_spacing()\n",
    "        if scale_factor is None:\n",
    "            change_factors = list(map(operator.truediv, old_sz,  size))\n",
    "            change_factors.reverse() # spacing is H x W x D, but tensor is D x H x W. As H and W are symmetrical, it is ok to just reverse.\n",
    "            new_spacing = tuple(map(operator.mul, spacing, change_factors))\n",
    "        else:\n",
    "            new_spacing = tuple([x/scale_factor for x in spacing])\n",
    "        t.set_spacing(new_spacing)\n",
    "\n",
    "    #if isinstance(t, TensorMask3D): mode = 'nearest'\n",
    "    if t.ndim == 3: t=t.unsqueeze(0)   # add fake chanel dim\n",
    "    if t.ndim == 4: t=t.unsqueeze(0)   # add fake batch dim\n",
    "\n",
    "    t = F.interpolate(t.float(), size=size,\n",
    "                         scale_factor=scale_factor,\n",
    "                         mode=mode,\n",
    "                         align_corners=align_corners,\n",
    "                         recompute_scale_factor=recompute_scale_factor).squeeze() #remove fake dims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ef74ed",
   "metadata": {},
   "source": [
    "# Dataloaders\n",
    "\n",
    "TODO augmentations.\n",
    "\n",
    "- dset = tfms applied to items\n",
    "- splits into training/valid\n",
    "- bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "54b7336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs  = 2\n",
    "center_crop_sz = (50, 50, 50)\n",
    "#pad_sz = (150, 150, 150)\n",
    "# general_bbox = (40, 150, 100, 320, 0, 300)\n",
    "# general_bbox = (40, 150, 100, 320, 0, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f728dc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 240, Valid: 60\n",
      "<class 'tuple'> 2 torch.Size([3, 1, 50, 50, 50]) torch.Size([3, 1, 50, 50, 50])\n",
      "80 20\n"
     ]
    }
   ],
   "source": [
    "# splits\n",
    "splits = RandomSplitter(seed=42)(items)\n",
    "print(f\"Training: {len(splits[0])}, Valid: {len(splits[1])}\")\n",
    "\n",
    "# tfms\n",
    "#tfms = [DoAll(), CropBBox(general_bbox)]\n",
    "tfms = [DoAll(), CenterCropTfm(center_crop_sz)]\n",
    "\n",
    "# tls\n",
    "tls = TfmdLists(items, tfms, splits=splits)\n",
    "\n",
    "# dls\n",
    "dls = tls.dataloaders(bs=bs, after_batch=AddChannel())\n",
    "\n",
    "# GPU\n",
    "dls = dls.cuda()\n",
    "\n",
    "# test get one batch\n",
    "b = dls.one_batch()\n",
    "print(type(b), len(b), b[0].shape, b[1].shape)\n",
    "print(len(dls.train), len(dls.valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b52207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipython nbconvert --to python  '6 - Dataloaders- OBELISK.ipynb'\n",
    "# python \"6 - Dataloaders- OBELISK.py\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c96e69",
   "metadata": {},
   "source": [
    "# Metric\n",
    "\n",
    "Linear combination of Dice and Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "entitled-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(input, target):\n",
    "    iflat = input.contiguous().view(-1)\n",
    "    tflat = target.contiguous().view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    return ((2. * intersection) /\n",
    "           (iflat.sum() + tflat.sum()))\n",
    "\n",
    "def dice_score(input, target):\n",
    "    return dice(input.argmax(1), target)\n",
    "\n",
    "def dice_loss(input, target): \n",
    "    return 1 - dice(input.softmax(1)[:, 1], target)\n",
    "\n",
    "def loss(input, target):\n",
    "    return dice_loss(input, target) + nn.CrossEntropyLoss()(input, target[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9fcb4ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mathiaspaul\n",
    "def dice_coeff(outputs, labels, max_label):\n",
    "    \"\"\"\n",
    "    Evaluation function for Dice score of segmentation overlap\n",
    "    \"\"\"\n",
    "    dice = torch.FloatTensor(max_label-1).fill_(0).to(outputs.device)\n",
    "    for label_num in range(1, max_label):\n",
    "        iflat = (outputs==label_num).view(-1).float()\n",
    "        tflat = (labels==label_num).view(-1).float()\n",
    "        intersection = (iflat * tflat).sum()\n",
    "        dice[label_num-1] = (2. * intersection) / (iflat.sum() + tflat.sum())\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "db375a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipython nbconvert --to python  '6 - Dataloaders- NB - Simple-Copy1.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59acd0f9",
   "metadata": {},
   "source": [
    "# Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d86c1219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8717d790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone = efficientnet_b0 #r3d_18 (pretrained?)\n",
    "# learn    = unet_learner_3d(dls, backbone, n_out=2,  metrics = dice_score,\n",
    "#                           model_dir = \"./models\", cbs = [SaveModelCallback(monitor='dice_score')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "511d80b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone = efficientnet_b0 #r3d_18 (pretrained?)\n",
    "# learn    = unet_learner_3d(dls, backbone, n_out=2,  metrics = dice_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7a16e375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unet_learner_3d??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f4c918d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learner(\n",
    "#     dls,\n",
    "#     model,\n",
    "#     loss_func=None,\n",
    "#     opt_func=<function Adam at 0x7f0e60231dd0>,\n",
    "#     lr=0.001,\n",
    "#     splitter=<function trainable_params at 0x7f0e6b4618c0>,\n",
    "#     cbs=None,\n",
    "#     metrics=None,\n",
    "#     path=None,\n",
    "#     model_dir='models',\n",
    "#     wd=None,\n",
    "#     wd_bn_bias=False,\n",
    "#     train_bn=True,\n",
    "#     moms=(0.95, 0.85, 0.95),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7cfcf9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 50, 50, 50])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7dcd58ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_val = b[0]\n",
    "img_val = F.avg_pool3d(img_val,5,stride=1,padding=2)\n",
    "img_val = F.avg_pool3d(img_val,5,stride=1,padding=2)\n",
    "img_val = F.avg_pool3d(img_val,3,stride=1,padding=1)\n",
    "_,_,D_in1,H_in1,W_in1 = img_val.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7ba985f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, 50)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_in1,H_in1,W_in1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0af37e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([50, 50, 50])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_res = torch.tensor(center_crop_sz).long()\n",
    "full_res\n",
    "# full_res = torch.tensor(pad_sz).long()\n",
    "# full_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "874d55df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original OBELISK model as described in MIDL2018 paper\n",
    "#contains around 130k trainable parameters and 1024 binary offsets\n",
    "#most simple Obelisk-Net with one deformable convolution followed by 1x1 Dense-Net\n",
    "class obelisk_visceral_full(nn.Module):\n",
    "    def __init__(self,num_labels,full_res):\n",
    "        super(obelisk_visceral_full, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.full_res = full_res\n",
    "        D_in1 = full_res[0]; H_in1 = full_res[1]; W_in1 = full_res[2];\n",
    "        D_in2 = (D_in1+1)//2; H_in2 = (H_in1+1)//2; W_in2 = (W_in1+1)//2; #half resolution\n",
    "        self.half_res = torch.Tensor([D_in2,H_in2,W_in2]).long(); half_res = self.half_res\n",
    "        D_in4 = (D_in2+1)//2; H_in4 = (H_in2+1)//2; W_in4 = (W_in2+1)//2; #quarter resolution\n",
    "        self.quarter_res = torch.Tensor([D_in4,H_in4,W_in4]).long(); quarter_res = self.quarter_res\n",
    "        \n",
    "        #Obelisk Layer\n",
    "        # sample_grid: 1 x    1     x #samples x 1 x 3\n",
    "        # offsets:     1 x #offsets x     1    x 1 x 3\n",
    "        \n",
    "        self.sample_grid1 = F.affine_grid(torch.eye(3,4).unsqueeze(0),torch.Size((1,1,quarter_res[0],quarter_res[1],quarter_res[2])))\n",
    "        self.sample_grid1.requires_grad = False\n",
    "        \n",
    "        #in this model (binary-variant) two spatial offsets are paired \n",
    "        self.offset1 = nn.Parameter(torch.randn(1,1024,1,2,3)*0.05)\n",
    "        \n",
    "        #Dense-Net with 1x1x1 kernels\n",
    "        self.LIN1 = nn.Conv3d(1024, 256, 1, bias=False, groups=4) #grouped convolutions\n",
    "        self.BN1 = nn.BatchNorm3d(256)\n",
    "        self.LIN2 = nn.Conv3d(256, 128, 1, bias=False)\n",
    "        self.BN2 = nn.BatchNorm3d(128)\n",
    "        \n",
    "        self.LIN3a = nn.Conv3d(128, 32, 1,bias=False)\n",
    "        self.BN3a = nn.BatchNorm3d(128+32)\n",
    "        self.LIN3b = nn.Conv3d(128+32, 32, 1,bias=False)\n",
    "        self.BN3b = nn.BatchNorm3d(128+64)\n",
    "        self.LIN3c = nn.Conv3d(128+64, 32, 1,bias=False)\n",
    "        self.BN3c = nn.BatchNorm3d(128+96)\n",
    "        self.LIN3d = nn.Conv3d(128+96, 32, 1,bias=False)\n",
    "        self.BN3d = nn.BatchNorm3d(256)\n",
    "        \n",
    "        self.LIN4 = nn.Conv3d(256, num_labels,1)\n",
    "\n",
    "        \n",
    "    def forward(self, inputImg, sample_grid=None):\n",
    "    \n",
    "        B,C,D,H,W = inputImg.size()\n",
    "        if(sample_grid is None):\n",
    "            sample_grid = self.sample_grid1\n",
    "        sample_grid = sample_grid.to(inputImg.device)    \n",
    "        #pre-smooth image (has to be done in advance for original models )\n",
    "        #x00 = F.avg_pool3d(inputImg,3,padding=1,stride=1)\n",
    "        \n",
    "        _,D_grid,H_grid,W_grid,_ = sample_grid.size()\n",
    "        input = F.grid_sample(inputImg, (sample_grid.view(1,1,-1,1,3).repeat(B,1,1,1,1) + self.offset1[:,:,:,0:1,:])).view(B,-1,D_grid,H_grid,W_grid)-\\\n",
    "        F.grid_sample(inputImg, (sample_grid.view(1,1,-1,1,3).repeat(B,1,1,1,1) + self.offset1[:,:,:,1:2,:])).view(B,-1,D_grid,H_grid,W_grid)\n",
    "        \n",
    "        x1 = F.relu(self.BN1(self.LIN1(input)))\n",
    "        x2 = self.BN2(self.LIN2(x1))\n",
    "        \n",
    "        x3a = torch.cat((x2,F.relu(self.LIN3a(x2))),dim=1)\n",
    "        x3b = torch.cat((x3a,F.relu(self.LIN3b(self.BN3a(x3a)))),dim=1)\n",
    "        x3c = torch.cat((x3b,F.relu(self.LIN3c(self.BN3b(x3b)))),dim=1)\n",
    "        x3d = torch.cat((x3c,F.relu(self.LIN3d(self.BN3c(x3c)))),dim=1)\n",
    "\n",
    "        x4 = self.LIN4(self.BN3d(x3d))\n",
    "        #return half-resolution segmentation/prediction \n",
    "        \n",
    "        #return x4\n",
    "        return F.interpolate(x4, size=[self.full_res[0], self.full_res[1], self.full_res[2]], mode='trilinear',align_corners=False)\n",
    "        #return F.interpolate(x4, size=[self.half_res[0],self.half_res[1],self.half_res[2]], mode='trilinear',align_corners=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4269a3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import obeliskhybrid_visceral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "913a35d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D_in1 = imgs.size(2); H_in1 = imgs.size(3); W_in1 = imgs.size(4); #full resolution\n",
    "# full_res = torch.Tensor([D_in1,H_in1,W_in1]).long()\n",
    "\n",
    "# _,_,D_in1,H_in1,W_in1 = img_val.size()\n",
    "# full_res = torch.Tensor([D_in1,H_in1,W_in1]).long()\n",
    "\n",
    "learn = Learner(dls=dls, \\\n",
    "                model=obeliskhybrid_visceral(num_labels=2, full_res=full_res), \\\n",
    "                loss_func= DiceLoss(), #nn.CrossEntropyLoss(), \\\n",
    "                metrics = dice_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "89be5e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with learn.distrib_ctx():\n",
    "#     learn.fit_one_cycle(1, 3e-1, wd = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8de170fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU\n",
    "#learn.model = nn.DataParallel(learn.model)\n",
    "learn.model = learn.model.cuda()\n",
    "#learn = learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c345a3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 4.05573582649231 s\n",
      "Batch: x,y\n",
      "<class 'torch.Tensor'> torch.Size([3, 1, 50, 50, 50]) torch.float32 \n",
      " <class 'torch.Tensor'> torch.Size([3, 1, 50, 50, 50]) torch.int64\n",
      "Pred shape\n",
      "<class 'torch.Tensor'> torch.Size([3, 2, 50, 50, 50]) torch.float32\n",
      "Loss\n",
      "tensor(0.4693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "<faimed3d.models.losses.DiceLoss object at 0x7f6e14229dd0>\n"
     ]
    }
   ],
   "source": [
    "# test:\n",
    "\n",
    "#dls.device = \"cpu\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "x,y = dls.one_batch()\n",
    "#x,y = to_cpu(x), to_cpu(y)\n",
    "\n",
    "pred = learn.model(x)\n",
    "loss = learn.loss_func(pred, y)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"Elapsed: {elapsed} s\")\n",
    "print(\"Batch: x,y\")\n",
    "print(type(x), x.shape, x.dtype, \"\\n\", type(y), y.shape, y.dtype)\n",
    "\n",
    "print(\"Pred shape\")\n",
    "print(type(pred), pred.shape, pred.dtype)\n",
    "\n",
    "print(\"Loss\")\n",
    "print(loss)\n",
    "print(learn.loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ed7aa715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1, 50, 50, 50]),\n",
       " torch.Size([3, 1, 50, 50, 50]),\n",
       " torch.Size([3, 2, 50, 50, 50]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape, pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9b92fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "52f35922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8962fb76",
   "metadata": {},
   "source": [
    "# LR Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c58b4d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4fefd197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE learn.fit one cycle\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>dice_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/80 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 453256) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/signal_handling.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 453256) is killed by signal: Killed. ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-483d1531d356>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PRE learn.fit one cycle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3e-1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai-2.2.5-py3.7.egg/fastai/callback/schedule.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    110\u001b[0m     scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\n\u001b[1;32m    111\u001b[0m               'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mParamScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai-2.2.5-py3.7.egg/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_end_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai-2.2.5-py3.7.egg/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai-2.2.5-py3.7.egg/fastai/learner.py\u001b[0m in \u001b[0;36m_do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai-2.2.5-py3.7.egg/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai-2.2.5-py3.7.egg/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai-2.2.5-py3.7.egg/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai-2.2.5-py3.7.egg/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai-2.2.5-py3.7.egg/fastai/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai-2.2.5-py3.7.egg/fastai/data/load.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__idxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_idxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# called in context of main process (not workers/subprocesses)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    997\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 453256) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "print(\"PRE learn.fit one cycle\")\n",
    "learn.fit_one_cycle(1, 3e-1, wd = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd633caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"unfreeze, learn 50\")\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(50, 3e-3, wd = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc0b435",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7127658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"unfreeze, learn 50\")\n",
    "# learn.unfreeze()\n",
    "# learn.fit_one_cycle(50, 1e-3, wd = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd40f6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4191348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5737f38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testmask = torch.tensor([[[False, False, False], [False, False, False], [True, True, True]],\n",
    "#                        [[False, False, False], [False, False, True], [True, True, True]],\n",
    "#                        [[False, False, False], [False, False, False], [False, False, False]]])\n",
    "# testmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a6a080bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testmaskN = np.array(testmask)\n",
    "# testmaskN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c1383dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maskT = testmask.type(torch.BoolTensor)\n",
    "\n",
    "# iT = torch.any(maskT, dim=(1,2))\n",
    "# jT = torch.any(maskT, dim=(0,2))\n",
    "# kT = torch.any(maskT, dim=(0,1))\n",
    "\n",
    "# iminT, imaxT = torch.where(iT)[0][[0, -1]]\n",
    "# jminT, jmaxT = torch.where(jT)[0][[0, -1]]\n",
    "# kminT, kmaxT = torch.where(kT)[0][[0, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "64d3afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maskN = np.array(testmask).astype(bool)\n",
    "    \n",
    "# iN = np.any(maskN, axis=(1, 2))\n",
    "# jN = np.any(maskN, axis=(0, 2))\n",
    "# kN = np.any(maskN, axis=(0, 1))\n",
    "\n",
    "# iminN, imaxN = np.where(iN)[0][[0, -1]]\n",
    "# jminN, jmaxN = np.where(jN)[0][[0, -1]]\n",
    "# kminN, kmaxN = np.where(kN)[0][[0, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1201e773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maskT.shape, maskN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8611c9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(iT)\n",
    "# print(jT)\n",
    "# print(kT)\n",
    "# print([x for x in (iminT, imaxT, jminT, jmaxT, kminT, kmaxT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7d428ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(iN)\n",
    "# print(jN)\n",
    "# print(kN)\n",
    "# print([int(x) for x in (iminN, imaxN, jminN, jmaxN, kminN, kmaxN)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93e81e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def torch_mask2bbox(mask):\n",
    "#         mask = mask.type(torch.BoolTensor)\n",
    "\n",
    "#         i = torch.any(mask, dim=0)\n",
    "#         j = torch.any(mask, dim=1)\n",
    "#         k = torch.any(mask, dim=2)\n",
    "\n",
    "#         imin, imax = torch.where(i)[0][[0, -1]]\n",
    "#         jmin, jmax = torch.where(j)[0][[0, -1]]\n",
    "#         kmin, kmax = torch.where(k)[0][[0, -1]]\n",
    "\n",
    "#         # inclusive idxs\n",
    "#         return imin, imax+1, jmin, jmax+1, kmin, kmax+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
