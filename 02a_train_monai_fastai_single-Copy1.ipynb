{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3321cd55",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "Train model\n",
    "\n",
    "Thanks to: OBELISK, FAIMED3D, MONAI\n",
    "- https://github.com/mattiaspaul/OBELISK\n",
    "-  https://github.com/kbressem/faimed3d/blob/main/examples/3d_segmentation.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493866e5",
   "metadata": {},
   "source": [
    "# Setup parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e07c233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "kwargs = dict(arg.split(\"=\") for arg in sys.argv if \"=\" in arg)\n",
    "print(kwargs)\n",
    "\n",
    "do_reload = \"model_type\" not in kwargs # True #True #True #False\n",
    "if do_reload:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    \n",
    "    model_type = \"UNET3D\" # VNET, UNET3D, UNETR, SegResNetVAE, OBELISKHYBRID\n",
    "    loss_type  = \"BCE_loss\" # DICE_loss\n",
    "    pixdim     = tuple(1.5 for _ in range(3))\n",
    "    full_res   = tuple(96 for _ in range(3))\n",
    "    do_flip    = True\n",
    "    do_simple  = True\n",
    "    do_test    = False # False\n",
    "\n",
    "else:\n",
    "    model_type = kwargs[\"model_type\"]\n",
    "    loss_type  = kwargs[\"loss_type\"]\n",
    "    pixdim     = kwargs[\"pixdim\"]\n",
    "    full_res   = kwargs[\"full_res\"]\n",
    "    do_flip    = kwargs[\"do_flip\"]\n",
    "    do_simple  = kwargs[\"do_simple\"]\n",
    "    do_test    = False\n",
    "\n",
    "    # tuple\n",
    "    pixdim   = tuple(float(pixdim) for _ in range(3))\n",
    "    full_res = tuple(int(full_res) for _ in range(3))\n",
    "\n",
    "    print(f\"Model: {model_type}\")\n",
    "    print(f\"Loss : {loss_type}\")\n",
    "    print(f\"Pixd : {pixdim}\")\n",
    "    print(f\"Fullres : {full_res}\")\n",
    "    print(f\"Do flip: {do_flip}\")\n",
    "    print(f\"Do simple: {do_simple}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "667c8e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_type = \"UNETR\" # VNET, UNET3D, UNETR, SegResNetVAE, OBELISKHYBRID\n",
    "# loss_type  = \"BCE_loss\" # DICE_loss\n",
    "# pixdim     = tuple(1.5 for _ in range(3))\n",
    "# full_res   = tuple(96 for _ in range(3))\n",
    "# do_flip    = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95658af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# try:\n",
    "#     taskid = int(os.getenv('SLURM_ARRAY_TASK_ID'))\n",
    "# except:\n",
    "#     taskid = 0\n",
    "\n",
    "# taskid = 1\n",
    "# print(f\"Taskid: {taskid}\")\n",
    "\n",
    "# if taskid == 0:\n",
    "#     # MODEL & LOSS\n",
    "#     model_type = \"UNET3D\" #\"SegResNetVAE\" # \"UNET3D\" #\"OBELISKHYBRID\" #\"VNET\" # \"UNET3D\" \"OBELISKHYBRID\"\n",
    "#     loss_type  = \"BCE_loss\" #\"log_cosh_dice_loss\" #\"vae_loss\" #\"perim_loss\" #\"log_cosh_dice_loss\" # DICE\n",
    "# elif taskid == 1:\n",
    "#     # MODEL & LOSS\n",
    "#     model_type = \"UNET3D\" #\"SegResNetVAE\" # \"UNET3D\" #\"OBELISKHYBRID\" #\"VNET\" # \"UNET3D\" \"OBELISKHYBRID\"\n",
    "#     loss_type  = \"log_cosh_dice_loss\" #\"log_cosh_dice_loss\" #\"vae_loss\" #\"perim_loss\" #\"log_cosh_dice_loss\" # DICE\n",
    "# else:\n",
    "#     print(\"Taskid {taskid} not recognized.\")\n",
    "    \n",
    "# print(f\"Model: {model_type}\")\n",
    "# print(f\"Loss : {loss_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1db8c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL & LOSS\n",
    "# model_type = \"UNET3D\" #\"SegResNetVAE\" # \"UNET3D\" #\"OBELISKHYBRID\" #\"VNET\" # \"UNET3D\" \"OBELISKHYBRID\"\n",
    "# loss_type  = \"BCE_loss\" #\"log_cosh_dice_loss\" #\"vae_loss\" #\"perim_loss\" #\"log_cosh_dice_loss\" # DICE\n",
    "\n",
    "# DATALOADER PARAMS\n",
    "bs          = 2\n",
    "nepochs     = 60\n",
    "num_workers = 2\n",
    "\n",
    "# full_res      = (96,96,96)\n",
    "#full_res      = (144,144,144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2eb7395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.model_loss_choices import get_model, get_loss\n",
    "\n",
    "model   = get_model(model_type, full_res)\n",
    "loss_fn = get_loss(loss_type) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4e07993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62388ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6efb1ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.7.dev2131\n",
      "Numpy version: 1.19.5\n",
      "Pytorch version: 1.7.1+cu101\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: 57467c75bff90e6c9da74461f7da3a828a39626b\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.5\n",
      "Nibabel version: 3.2.1\n",
      "scikit-image version: 0.17.2\n",
      "Pillow version: 8.3.1\n",
      "Tensorboard version: 2.5.0\n",
      "gdown version: 3.13.0\n",
      "TorchVision version: 0.8.2+cu101\n",
      "tqdm version: 4.62.0\n",
      "lmdb version: 1.2.1\n",
      "psutil version: 5.8.0\n",
      "pandas version: 1.1.5\n",
      "einops version: 0.3.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNETR\n",
    "\n",
    "from monai.data import (\n",
    "    DataLoader,\n",
    "    CacheDataset,\n",
    "    load_decathlon_datalist,\n",
    "    decollate_batch,\n",
    ")\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebb6ff2",
   "metadata": {},
   "source": [
    "# Items as dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f15ac03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 20, val: 20\n"
     ]
    }
   ],
   "source": [
    "from helpers.items_constants import *\n",
    "train_itemsd = getd(train_items[:20])\n",
    "val_itemsd   = getd(valid_items[:20])\n",
    "print(f\"train: {len(train_itemsd)}, val: {len(val_itemsd)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8683e5",
   "metadata": {},
   "source": [
    "# Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "120f8324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.transforms import UndoDict, get_train_valid_transforms, get_train_valid_transforms_simple, monai_tfms2str\n",
    "\n",
    "if do_simple:\n",
    "    train_tfms, val_tfms = get_train_valid_transforms_simple(pixdim=pixdim, full_res=full_res)\n",
    "else:\n",
    "    train_tfms, val_tfms = get_train_valid_transforms(pixdim=pixdim, full_res=full_res, do_flip=do_flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "556411d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fastai + distributed training\n",
    "from fastai              import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.basics       import *\n",
    "from fastai.distributed  import *\n",
    "from fastai.callback.all import SaveModelCallback, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6ff595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tls, dls, cuda\n",
    "train_dl = TfmdDL(train_itemsd, after_item=train_tfms, after_batch=[], bs=bs)\n",
    "val_dl   = TfmdDL(val_itemsd,   after_item=val_tfms,   after_batch=[], bs=bs)\n",
    "\n",
    "# tls, dls, cuda\n",
    "if do_test:\n",
    "    train_dl = TfmdDL(train_itemsd[:10], after_item=train_tfms, after_batch=[], bs=bs)\n",
    "    val_dl   = TfmdDL(val_itemsd[:10],   after_item=val_tfms,   after_batch=[], bs=bs)\n",
    "    nepochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e2d0bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(train_dl, val_dl)\n",
    "dls = dls.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1ccc08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7930b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Viz\n",
    "\n",
    "# from helpers.viz        import viz_axis, viz_compare_inputs, viz_compare_outputs\n",
    "# from helpers.preprocess import mask2bbox\n",
    "# from helpers.general    import lrange\n",
    "\n",
    "# train_dl = TfmdDL(train_itemsd, after_item=train_tfms, after_batch=[], bs=3)\n",
    "\n",
    "# b = train_dl.one_batch()\n",
    "\n",
    "# xb,yb = b\n",
    "\n",
    "# print(\"shape xb yb\", xb.shape, yb.shape)\n",
    "\n",
    "# i = 2\n",
    "# mr = np.array(xb[i].squeeze().cpu())\n",
    "# mk = np.array(yb[i].squeeze().cpu())\n",
    "\n",
    "# bbox = mask2bbox(mk)\n",
    "\n",
    "# viz_axis(np_arr = mr, \\\n",
    "#     bin_mask_arr   = mk,     color1 = \"yellow\",  alpha1=0.3, \\\n",
    "#     slices=lrange(*bbox[0:2]), fixed_axis=0, \\\n",
    "#     axis_fn = np.rot90, \\\n",
    "#     title   = \"Axis 0\", \\\n",
    "\n",
    "#     np_arr_b = mr, \\\n",
    "#     bin_mask_arr_b   = mk,     color1_b = \"yellow\",  alpha1_b=0.3, \\\n",
    "#     slices_b = lrange(*bbox[2:4]), fixed_axis_b=1, \\\n",
    "#     title_b  = \"Axis 1\", \\\n",
    "\n",
    "#     np_arr_c = mr, \\\n",
    "#     bin_mask_arr_c   = mk,     color1_c = \"yellow\",  alpha1_c=0.3, \\\n",
    "#     slices_c = lrange(*bbox[4:6]), fixed_axis_c=2, \\\n",
    "#     title_c = \"Axis 2\", \\\n",
    "  \n",
    "# ncols = 5, hspace=0.3, fig_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "684b0b85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Utilities\n",
    "import os, sys, gc, time, pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Fastai + distributed training\n",
    "from fastai              import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.basics       import *\n",
    "from fastai.distributed  import *\n",
    "from fastai.callback.all import SaveModelCallback, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19bbc228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length  = len(items)\n",
    "# indices = np.arange(length)\n",
    "# np.random.shuffle(indices)\n",
    "# #rank0_first(lambda: np.random.shuffle(indices))\n",
    "\n",
    "# test_split   = int(test_frac  * length)\n",
    "# valid_split  = int(valid_frac * length) + test_split\n",
    "\n",
    "# test_idxs    = indices[:test_split] \n",
    "# valid_idxs   = indices[test_split:valid_split]\n",
    "# train_idxs   = indices[valid_split:]\n",
    "\n",
    "# train_items = [items[i] for i in train_idxs]\n",
    "# valid_items = [items[i] for i in valid_idxs]\n",
    "# test_items  = [items[i] for i in test_idxs]\n",
    "\n",
    "# # print\n",
    "# print(f\"Total  {len(items)} items in dataset.\")\n",
    "# print(f\"Train: {len(train_items)} items.\")\n",
    "# print(f\"Valid: {len(valid_items)} items.\")\n",
    "# print(f\"Test:  {len(test_items)} items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7501063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save test set indices\n",
    "# with open(f\"{data_src}/saved_dset_metadata/split_train_valid_test.pkl\", 'wb') as f:\n",
    "#     pickle.dump([train_idxs, valid_idxs, test_idxs, train_items, valid_items, test_items], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "702c1a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test get one batch\n",
    "# time_one_batch(dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3351ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: model_UNET3D_loss_BCE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1627953225_Mon_Aug_02_2021_hr_21_min_13\n"
     ]
    }
   ],
   "source": [
    "# Save test idxs + model + runs\n",
    "from helpers.time       import time_one_batch, get_time_id\n",
    "\n",
    "# file name\n",
    "model_time = rank0_first(lambda:get_time_id()) # 'Mon Oct 18 13:35:29 2010'\n",
    "model_name = f\"model_{model_type}_loss_{loss_type}_full_res_{full_res[0]}_pixdim_{pixdim[0]}_do_simple_{do_simple}_do_flip_{do_flip}_bs_{bs}_epochs_{nepochs}_time_{model_time}\"\n",
    "print(f\"Model name: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5808b4",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f241a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dir\n",
    "model_src = f\"{run_src}/{model_name}\"\n",
    "fig_src = f\"{model_src}/figs\"\n",
    "Path(fig_src).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72b6d492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "Model name: model_UNET3D_loss_BCE_loss_full_res_96_pixdim_1.5_do_simple_True_do_flip_True_bs_2_epochs_60_time_1627953225_Mon_Aug_02_2021_hr_21_min_13\n",
      "train: 20, val: 20\n"
     ]
    }
   ],
   "source": [
    "if not do_test:\n",
    "    old_stdout = sys.stdout\n",
    "    log_file = open(f\"{model_name}.log\",\"w\")\n",
    "    print(kwargs)\n",
    "    print(f\"Model name: {model_name}\")\n",
    "    print(f\"train: {len(train_itemsd)}, val: {len(val_itemsd)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac990b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test set indices\n",
    "# with open(f\"{model_src}/test_items.pkl\", 'wb') as f:\n",
    "#     rank0_first(lambda:pickle.dump(list(test_items), f))\n",
    "\n",
    "# save data augs\n",
    "with open(f\"{model_src}/data_augs.txt\", 'w') as f:\n",
    "    def print_data_augs():\n",
    "        print(\"Train Tfms: \", file=f); print(monai_tfms2str(train_tfms), file=f)\n",
    "        print(\"Val   Tfms: \", file=f); print(monai_tfms2str(val_tfms), file=f)\n",
    "        \n",
    "    rank0_first(print_data_augs)\n",
    "\n",
    "#     s = \"\\n\".join([str(tfm) for tfm in train_tfms.transforms] + [f\"Pixdim: 1.5\"])\n",
    "#     rank0_first(lambda: print(s, file=f))\n",
    "    \n",
    "# with open(f\"{model_src}/{model_name}_test_items.pkl\", 'wb') as f:\n",
    "#     rank0_first(lambda:pickle.dump(list(test_items), f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9116b3e9",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5456e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = [\n",
    "    rank0_first(lambda: Recorder(train_metrics=False)),\n",
    "    rank0_first(lambda: SaveModelCallback(monitor='dice_score', with_opt=True)), \n",
    "    rank0_first(lambda: CSVLogger(fname=f\"{fig_src}/history.csv\"))\n",
    "]\n",
    "\n",
    "#no more metrics\n",
    "# rank0_first(lambda: SaveModelCallback(monitor='valid_dice_score', with_opt=True)), \n",
    "\n",
    "\n",
    "# class PerimLossMidway(Callback):\n",
    "#     def before_epoch(self): \n",
    "#         if self.epoch == self.n_epoch//2:\n",
    "#             self.learn.loss_func = perim_loss\n",
    "#             print(\"Changed \", self.learn.loss_func, \"at epoch \", self.n_epoch//2)\n",
    "            \n",
    "# cbs = [SaveModelCallback(monitor='dice_score', with_opt=True), CSVLogger(fname=f\"{fig_src}/history.csv\")]\n",
    "\n",
    "# if loss_type == \"perim_loss\":\n",
    "#     print(\"added PerimLoss callback\")\n",
    "#     cbs.append(PerimLossMidway())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d7809f",
   "metadata": {},
   "source": [
    "# Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3b8faf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#GPU = 1, #CPU = 40\n",
      "GPU Tesla V100-SXM2-16GB RAM Free: 16157MB | Used: 3MB | Util   0% | Total 16160MB\n"
     ]
    }
   ],
   "source": [
    "# clear cache\n",
    "from helpers.general import print_hardware_stats\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "rank0_first(lambda: print_hardware_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9acf1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.losses import dice_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a13fe9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = rank0_first(lambda:\n",
    "            Learner(dls   = dls, \\\n",
    "                model     = model, \\\n",
    "                loss_func = loss_fn, \\\n",
    "                metrics   = dice_score, \\\n",
    "                model_dir = model_src, \\\n",
    "                cbs       = cbs)\n",
    "        )\n",
    "\n",
    "# cbs TensorBoardCallback(Path(run_src)/model_name, trace_model=True)\n",
    "# GPU\n",
    "learn.model = rank0_first(lambda:learn.model.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ce240e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check\n",
    "# print(\"Check\")\n",
    "# b = dls.one_batch()\n",
    "# xb,yb = b #b[\"image\"], b[\"label\"]\n",
    "# print(f\"Batch: {len(b)}. xb: {xb.shape}, yb: {yb.shape}\")\n",
    "# predb = learn.model(xb)\n",
    "# print(f\"Pred batch: {predb.shape}\")\n",
    "# loss = loss_fn(predb, yb)\n",
    "# print(f\"Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fd54581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(predb[0].shape, predb[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceedd82",
   "metadata": {},
   "source": [
    "# LR Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7ff83a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"PRE learn.fit one cycle\")\n",
    "# with learn.distrib_ctx():\n",
    "#     learn.fit_one_cycle(2, 3e-3, wd = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b7b2d803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SuggestedLRs(valley=tensor(0.0229))\n",
    "# learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2aa4f647",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE learn.fit one cycle\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_dice_score</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_dice_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.256638</td>\n",
       "      <td>0.235021</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>02:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.256638</td>\n",
       "      <td>0.016869</td>\n",
       "      <td>0.235021</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>02:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.181015</td>\n",
       "      <td>0.162880</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.181015</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.162880</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.113963</td>\n",
       "      <td>0.099075</td>\n",
       "      <td>nan</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.113963</td>\n",
       "      <td>0.006423</td>\n",
       "      <td>0.099075</td>\n",
       "      <td>nan</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.067309</td>\n",
       "      <td>0.053746</td>\n",
       "      <td>nan</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.067309</td>\n",
       "      <td>0.006955</td>\n",
       "      <td>0.053746</td>\n",
       "      <td>nan</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.041605</td>\n",
       "      <td>0.032711</td>\n",
       "      <td>nan</td>\n",
       "      <td>02:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.041605</td>\n",
       "      <td>0.023709</td>\n",
       "      <td>0.032711</td>\n",
       "      <td>nan</td>\n",
       "      <td>02:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.032373</td>\n",
       "      <td>0.025225</td>\n",
       "      <td>nan</td>\n",
       "      <td>02:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.032373</td>\n",
       "      <td>0.040266</td>\n",
       "      <td>0.025225</td>\n",
       "      <td>nan</td>\n",
       "      <td>02:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.028005</td>\n",
       "      <td>0.022031</td>\n",
       "      <td>nan</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.028005</td>\n",
       "      <td>0.053238</td>\n",
       "      <td>0.022031</td>\n",
       "      <td>nan</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.025079</td>\n",
       "      <td>0.018736</td>\n",
       "      <td>nan</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.025079</td>\n",
       "      <td>0.083936</td>\n",
       "      <td>0.018736</td>\n",
       "      <td>nan</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.024971</td>\n",
       "      <td>0.021303</td>\n",
       "      <td>nan</td>\n",
       "      <td>02:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.024971</td>\n",
       "      <td>0.154507</td>\n",
       "      <td>0.021303</td>\n",
       "      <td>nan</td>\n",
       "      <td>02:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.023533</td>\n",
       "      <td>0.020306</td>\n",
       "      <td>0.383204</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.023533</td>\n",
       "      <td>0.186017</td>\n",
       "      <td>0.020306</td>\n",
       "      <td>0.383204</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.023142</td>\n",
       "      <td>0.018395</td>\n",
       "      <td>0.469444</td>\n",
       "      <td>02:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.023142</td>\n",
       "      <td>0.237699</td>\n",
       "      <td>0.018395</td>\n",
       "      <td>0.469444</td>\n",
       "      <td>02:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.023298</td>\n",
       "      <td>0.017333</td>\n",
       "      <td>0.333294</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.023298</td>\n",
       "      <td>0.250827</td>\n",
       "      <td>0.017333</td>\n",
       "      <td>0.333294</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.021345</td>\n",
       "      <td>0.016414</td>\n",
       "      <td>0.524592</td>\n",
       "      <td>02:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.021345</td>\n",
       "      <td>0.264477</td>\n",
       "      <td>0.016414</td>\n",
       "      <td>0.524592</td>\n",
       "      <td>02:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.023142</td>\n",
       "      <td>0.018620</td>\n",
       "      <td>0.210540</td>\n",
       "      <td>02:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.023142</td>\n",
       "      <td>0.261627</td>\n",
       "      <td>0.018620</td>\n",
       "      <td>0.210540</td>\n",
       "      <td>02:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.022420</td>\n",
       "      <td>0.018555</td>\n",
       "      <td>0.288358</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.022420</td>\n",
       "      <td>0.238614</td>\n",
       "      <td>0.018555</td>\n",
       "      <td>0.288358</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.022614</td>\n",
       "      <td>0.019744</td>\n",
       "      <td>0.310093</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.022614</td>\n",
       "      <td>0.258692</td>\n",
       "      <td>0.019744</td>\n",
       "      <td>0.310093</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.021140</td>\n",
       "      <td>0.016256</td>\n",
       "      <td>nan</td>\n",
       "      <td>02:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.021140</td>\n",
       "      <td>0.267719</td>\n",
       "      <td>0.016256</td>\n",
       "      <td>nan</td>\n",
       "      <td>02:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.019147</td>\n",
       "      <td>0.017195</td>\n",
       "      <td>0.393791</td>\n",
       "      <td>02:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.019147</td>\n",
       "      <td>0.345212</td>\n",
       "      <td>0.017195</td>\n",
       "      <td>0.393791</td>\n",
       "      <td>02:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.019675</td>\n",
       "      <td>0.015488</td>\n",
       "      <td>0.478162</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.019675</td>\n",
       "      <td>0.322538</td>\n",
       "      <td>0.015488</td>\n",
       "      <td>0.478162</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.019851</td>\n",
       "      <td>0.018213</td>\n",
       "      <td>0.254825</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.019851</td>\n",
       "      <td>0.336872</td>\n",
       "      <td>0.018213</td>\n",
       "      <td>0.254825</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.019814</td>\n",
       "      <td>0.017391</td>\n",
       "      <td>0.330345</td>\n",
       "      <td>02:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.019814</td>\n",
       "      <td>0.317859</td>\n",
       "      <td>0.017391</td>\n",
       "      <td>0.330345</td>\n",
       "      <td>02:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.019523</td>\n",
       "      <td>0.016861</td>\n",
       "      <td>0.377711</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.019523</td>\n",
       "      <td>0.331952</td>\n",
       "      <td>0.016861</td>\n",
       "      <td>0.377711</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.019937</td>\n",
       "      <td>0.016894</td>\n",
       "      <td>nan</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.019937</td>\n",
       "      <td>0.364592</td>\n",
       "      <td>0.016894</td>\n",
       "      <td>nan</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.018351</td>\n",
       "      <td>0.013867</td>\n",
       "      <td>0.522151</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.018351</td>\n",
       "      <td>0.355722</td>\n",
       "      <td>0.013867</td>\n",
       "      <td>0.522151</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.017549</td>\n",
       "      <td>0.014801</td>\n",
       "      <td>0.509252</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.017549</td>\n",
       "      <td>0.396956</td>\n",
       "      <td>0.014801</td>\n",
       "      <td>0.509252</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.017783</td>\n",
       "      <td>0.014035</td>\n",
       "      <td>0.489360</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.017783</td>\n",
       "      <td>0.408508</td>\n",
       "      <td>0.014035</td>\n",
       "      <td>0.489360</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.015685</td>\n",
       "      <td>0.443875</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.395954</td>\n",
       "      <td>0.015685</td>\n",
       "      <td>0.443875</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.017623</td>\n",
       "      <td>0.015537</td>\n",
       "      <td>0.456589</td>\n",
       "      <td>02:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.017623</td>\n",
       "      <td>0.400460</td>\n",
       "      <td>0.015537</td>\n",
       "      <td>0.456589</td>\n",
       "      <td>02:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.017162</td>\n",
       "      <td>0.014392</td>\n",
       "      <td>0.481854</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.017162</td>\n",
       "      <td>0.401776</td>\n",
       "      <td>0.014392</td>\n",
       "      <td>0.481854</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.016525</td>\n",
       "      <td>0.014099</td>\n",
       "      <td>0.485817</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.016525</td>\n",
       "      <td>0.436638</td>\n",
       "      <td>0.014099</td>\n",
       "      <td>0.485817</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.016090</td>\n",
       "      <td>0.015023</td>\n",
       "      <td>0.485343</td>\n",
       "      <td>02:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.016090</td>\n",
       "      <td>0.461111</td>\n",
       "      <td>0.015023</td>\n",
       "      <td>0.485343</td>\n",
       "      <td>02:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.016927</td>\n",
       "      <td>0.015014</td>\n",
       "      <td>0.455797</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.016927</td>\n",
       "      <td>0.439161</td>\n",
       "      <td>0.015014</td>\n",
       "      <td>0.455797</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.016487</td>\n",
       "      <td>0.014171</td>\n",
       "      <td>0.462592</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.016487</td>\n",
       "      <td>0.417133</td>\n",
       "      <td>0.014171</td>\n",
       "      <td>0.462592</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.018361</td>\n",
       "      <td>0.013181</td>\n",
       "      <td>0.543870</td>\n",
       "      <td>02:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.018361</td>\n",
       "      <td>0.407484</td>\n",
       "      <td>0.013181</td>\n",
       "      <td>0.543870</td>\n",
       "      <td>02:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.017101</td>\n",
       "      <td>0.014556</td>\n",
       "      <td>0.396765</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.017101</td>\n",
       "      <td>0.439328</td>\n",
       "      <td>0.014556</td>\n",
       "      <td>0.396765</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.016534</td>\n",
       "      <td>0.017056</td>\n",
       "      <td>0.423364</td>\n",
       "      <td>02:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.016534</td>\n",
       "      <td>0.439958</td>\n",
       "      <td>0.017056</td>\n",
       "      <td>0.423364</td>\n",
       "      <td>02:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.015968</td>\n",
       "      <td>0.013709</td>\n",
       "      <td>0.557907</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.015968</td>\n",
       "      <td>0.453631</td>\n",
       "      <td>0.013709</td>\n",
       "      <td>0.557907</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.015763</td>\n",
       "      <td>0.013487</td>\n",
       "      <td>0.504330</td>\n",
       "      <td>02:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.015763</td>\n",
       "      <td>0.481402</td>\n",
       "      <td>0.013487</td>\n",
       "      <td>0.504330</td>\n",
       "      <td>02:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.014790</td>\n",
       "      <td>0.012549</td>\n",
       "      <td>0.539749</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.014790</td>\n",
       "      <td>0.495989</td>\n",
       "      <td>0.012549</td>\n",
       "      <td>0.539749</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.015456</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.546614</td>\n",
       "      <td>02:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.015456</td>\n",
       "      <td>0.490525</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.546614</td>\n",
       "      <td>02:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.014474</td>\n",
       "      <td>0.012737</td>\n",
       "      <td>0.534945</td>\n",
       "      <td>02:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.014474</td>\n",
       "      <td>0.497225</td>\n",
       "      <td>0.012737</td>\n",
       "      <td>0.534945</td>\n",
       "      <td>02:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.014693</td>\n",
       "      <td>0.012668</td>\n",
       "      <td>0.568254</td>\n",
       "      <td>02:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.014693</td>\n",
       "      <td>0.509300</td>\n",
       "      <td>0.012668</td>\n",
       "      <td>0.568254</td>\n",
       "      <td>02:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.014532</td>\n",
       "      <td>0.012838</td>\n",
       "      <td>0.577172</td>\n",
       "      <td>02:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.014532</td>\n",
       "      <td>0.494476</td>\n",
       "      <td>0.012838</td>\n",
       "      <td>0.577172</td>\n",
       "      <td>02:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.014690</td>\n",
       "      <td>0.012622</td>\n",
       "      <td>0.542161</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.014690</td>\n",
       "      <td>0.518969</td>\n",
       "      <td>0.012622</td>\n",
       "      <td>0.542161</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.013736</td>\n",
       "      <td>0.012076</td>\n",
       "      <td>0.565978</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.013736</td>\n",
       "      <td>0.498865</td>\n",
       "      <td>0.012076</td>\n",
       "      <td>0.565978</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.014330</td>\n",
       "      <td>0.012320</td>\n",
       "      <td>0.554484</td>\n",
       "      <td>02:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.014330</td>\n",
       "      <td>0.522214</td>\n",
       "      <td>0.012320</td>\n",
       "      <td>0.554484</td>\n",
       "      <td>02:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.012090</td>\n",
       "      <td>0.605762</td>\n",
       "      <td>02:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.537750</td>\n",
       "      <td>0.012090</td>\n",
       "      <td>0.605762</td>\n",
       "      <td>02:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.013995</td>\n",
       "      <td>0.012205</td>\n",
       "      <td>0.575060</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.013995</td>\n",
       "      <td>0.536526</td>\n",
       "      <td>0.012205</td>\n",
       "      <td>0.575060</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.013782</td>\n",
       "      <td>0.012218</td>\n",
       "      <td>0.598194</td>\n",
       "      <td>02:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.013782</td>\n",
       "      <td>0.527089</td>\n",
       "      <td>0.012218</td>\n",
       "      <td>0.598194</td>\n",
       "      <td>02:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.013108</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.603354</td>\n",
       "      <td>02:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.013108</td>\n",
       "      <td>0.544855</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.603354</td>\n",
       "      <td>02:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.013545</td>\n",
       "      <td>0.011961</td>\n",
       "      <td>0.587008</td>\n",
       "      <td>02:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.013545</td>\n",
       "      <td>0.537412</td>\n",
       "      <td>0.011961</td>\n",
       "      <td>0.587008</td>\n",
       "      <td>02:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.013171</td>\n",
       "      <td>0.011974</td>\n",
       "      <td>0.608604</td>\n",
       "      <td>02:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.013171</td>\n",
       "      <td>0.556466</td>\n",
       "      <td>0.011974</td>\n",
       "      <td>0.608604</td>\n",
       "      <td>02:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.013282</td>\n",
       "      <td>0.011959</td>\n",
       "      <td>0.581774</td>\n",
       "      <td>02:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.013282</td>\n",
       "      <td>0.536702</td>\n",
       "      <td>0.011959</td>\n",
       "      <td>0.581774</td>\n",
       "      <td>02:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.014127</td>\n",
       "      <td>0.011887</td>\n",
       "      <td>0.573038</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.014127</td>\n",
       "      <td>0.538031</td>\n",
       "      <td>0.011887</td>\n",
       "      <td>0.573038</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.012629</td>\n",
       "      <td>0.011822</td>\n",
       "      <td>0.583363</td>\n",
       "      <td>02:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.012629</td>\n",
       "      <td>0.549484</td>\n",
       "      <td>0.011822</td>\n",
       "      <td>0.583363</td>\n",
       "      <td>02:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.012975</td>\n",
       "      <td>0.011821</td>\n",
       "      <td>0.590396</td>\n",
       "      <td>02:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.012975</td>\n",
       "      <td>0.552222</td>\n",
       "      <td>0.011821</td>\n",
       "      <td>0.590396</td>\n",
       "      <td>02:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.012679</td>\n",
       "      <td>0.011833</td>\n",
       "      <td>0.583988</td>\n",
       "      <td>02:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.012679</td>\n",
       "      <td>0.572325</td>\n",
       "      <td>0.011833</td>\n",
       "      <td>0.583988</td>\n",
       "      <td>02:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.012798</td>\n",
       "      <td>0.011829</td>\n",
       "      <td>0.587973</td>\n",
       "      <td>02:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.012798</td>\n",
       "      <td>0.560127</td>\n",
       "      <td>0.011829</td>\n",
       "      <td>0.587973</td>\n",
       "      <td>02:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.013594</td>\n",
       "      <td>0.011835</td>\n",
       "      <td>0.588556</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.013594</td>\n",
       "      <td>0.556932</td>\n",
       "      <td>0.011835</td>\n",
       "      <td>0.588556</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.012732</td>\n",
       "      <td>0.011835</td>\n",
       "      <td>0.588590</td>\n",
       "      <td>02:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.012732</td>\n",
       "      <td>0.566177</td>\n",
       "      <td>0.011835</td>\n",
       "      <td>0.588590</td>\n",
       "      <td>02:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_dice_score value: 0.003745168913155794.\n",
      "Better model found at epoch 9 with valid_dice_score value: 0.3832036852836609.\n",
      "Better model found at epoch 10 with valid_dice_score value: 0.46944355964660645.\n",
      "Better model found at epoch 12 with valid_dice_score value: 0.5245916247367859.\n",
      "Better model found at epoch 33 with valid_dice_score value: 0.5438696146011353.\n",
      "Better model found at epoch 36 with valid_dice_score value: 0.5579066276550293.\n",
      "Better model found at epoch 41 with valid_dice_score value: 0.5682535171508789.\n",
      "Better model found at epoch 42 with valid_dice_score value: 0.5771719217300415.\n",
      "Better model found at epoch 46 with valid_dice_score value: 0.6057624220848083.\n",
      "Better model found at epoch 51 with valid_dice_score value: 0.6086040735244751.\n"
     ]
    }
   ],
   "source": [
    "print(\"PRE learn.fit one cycle\")\n",
    "\n",
    "with learn.distrib_ctx():\n",
    "    learn.fit_one_cycle(nepochs, 3e-3, wd = 1e-4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "55dcb74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     if loss_type == \"perim_loss\":\n",
    "#         learn.loss_func = perim_loss\n",
    "#         print(\"switched loss at epoch \", nepochs//2)\n",
    "    \n",
    "#     learn.fit_one_cycle(nepochs//2, 3e-3, wd = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8e51a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "570ba8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot_loss(self, skip_start=5, with_valid=True):\n",
    "        plt.plot(list(range(skip_start, len(self.losses))), self.losses[skip_start:], label='train')\n",
    "        if with_valid:\n",
    "            idx = (np.array(self.iters)<skip_start).sum()\n",
    "            plt.plot(self.iters[idx:], L(self.values[idx:]).itemgot(1), label='valid')\n",
    "            plt.legend()\n",
    "        plt.savefig(f'{fig_src}/loss.png', bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2bc8b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_plot_loss(learn.recorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "51f52e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self = learn.recorder\n",
    "# nrows=None \n",
    "# ncols=None\n",
    "# figsize=None,\n",
    "# metrics = np.stack(self.values)\n",
    "# names = self.metric_names[1:-1]\n",
    "# n = len(names) - 1\n",
    "# if nrows is None and ncols is None:\n",
    "#     nrows = int(math.sqrt(n))\n",
    "#     ncols = int(np.ceil(n / nrows))\n",
    "# elif nrows is None: nrows = int(np.ceil(n / ncols))\n",
    "# elif ncols is None: ncols = int(np.ceil(n / nrows))\n",
    "# figsize = (ncols * 6, nrows * 4)\n",
    "# fig, axs = subplots(nrows, ncols, figsize=figsize)\n",
    "# axs = [ax if i < n else ax.set_axis_off() for i, ax in enumerate(axs.flatten())][:n]\n",
    "# for i, (name, ax) in enumerate(zip(names, [axs[0]] + axs)):\n",
    "#     ax.plot(metrics[:, i], color='#1f77b4' if i == 0 else '#ff7f0e', label='valid' if i > 0 else 'train')\n",
    "#     ax.set_title(name if i > 1 else 'losses')\n",
    "#     ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "828ffcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "@delegates(subplots)\n",
    "def save_plot_metrics(self: Recorder, nrows=None, ncols=None, figsize=None, **kwargs):\n",
    "    metrics = np.stack(self.values)\n",
    "    names = self.metric_names[1:-1]\n",
    "    n = len(names) - 1\n",
    "    if nrows is None and ncols is None:\n",
    "        nrows = int(math.sqrt(n))\n",
    "        ncols = int(np.ceil(n / nrows))\n",
    "    elif nrows is None: nrows = int(np.ceil(n / ncols))\n",
    "    elif ncols is None: ncols = int(np.ceil(n / nrows))\n",
    "    figsize = figsize or (ncols * 6, nrows * 4)\n",
    "    fig, axs = subplots(nrows, ncols, figsize=figsize, **kwargs)\n",
    "    axs = [ax if i < n else ax.set_axis_off() for i, ax in enumerate(axs.flatten())][:n]\n",
    "    for i, (name, ax) in enumerate(zip(names, [axs[0]] + axs)):\n",
    "        ax.plot(metrics[:, i], color='#1f77b4' if i == 0 else '#ff7f0e', label='valid' if i > 0 else 'train')\n",
    "        ax.set_title(name if i > 1 else 'losses')\n",
    "        ax.legend(loc='best')\n",
    "    #plt.show()\n",
    "    plt.savefig(f'{fig_src}/metrics.png', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5f5f1c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if do_test:\n",
    "#     self = learn.recorder\n",
    "#     nrows =None; ncols=None; figsize=None\n",
    "\n",
    "#     metrics = np.stack(self.values)\n",
    "#     # 'train_loss', 'train_dice_score', 'valid_loss', 'valid_dice_score'\n",
    "#     names = self.metric_names[1:-1]\n",
    "#     print(\"Metric names: \", names)\n",
    "\n",
    "#     names_train = [n for n in names if n.startswith(\"train\")]\n",
    "#     n = len(names_train)\n",
    "#     if nrows is None and ncols is None:\n",
    "#         nrows = int(math.sqrt(n))\n",
    "#         ncols = int(np.ceil(n / nrows))\n",
    "#     elif nrows is None: nrows = int(np.ceil(n / ncols))\n",
    "#     elif ncols is None: ncols = int(np.ceil(n / nrows))\n",
    "#     figsize = (ncols * 6, nrows * 4)\n",
    "#     fig, axs = subplots(nrows, ncols, figsize=figsize)\n",
    "#     for i, ax in enumerate(axs):\n",
    "#         name = names_train[i]\n",
    "#         n = name[name.index(\"_\")+1:]\n",
    "#         valid_name = f\"valid_{n}\"\n",
    "#         valid_idx = names.index(valid_name)\n",
    "#         print(i, valid_idx, name, valid_name)\n",
    "#         ax.plot(metrics[:, i], color='#1f77b4',  label='train')\n",
    "#         ax.plot(metrics[:, valid_idx], color = '#ff7f0e', label='valid')\n",
    "#         ax.set_title(n)\n",
    "#         ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "37f41385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @delegates(subplots)\n",
    "# def save_plot_metrics(self: Recorder, nrows=None, ncols=None, figsize=None, **kwargs):\n",
    "#     metrics = np.stack(self.values)\n",
    "#     # 'train_loss', 'train_dice_score', 'valid_loss', 'valid_dice_score'\n",
    "#     names = self.metric_names[1:-1]\n",
    "#     print(\"Metric names: \", names)\n",
    "    \n",
    "#     names_train = [n for n in names if n.startswith(\"train\")]\n",
    "#     n = len(names_train)\n",
    "#     if nrows is None and ncols is None:\n",
    "#         nrows = int(math.sqrt(n))\n",
    "#         ncols = int(np.ceil(n / nrows))\n",
    "#     elif nrows is None: nrows = int(np.ceil(n / ncols))\n",
    "#     elif ncols is None: ncols = int(np.ceil(n / nrows))\n",
    "#     figsize = (ncols * 6, nrows * 4)\n",
    "#     fig, axs = subplots(nrows, ncols, figsize=figsize)\n",
    "#     for i, ax in enumerate(axs):\n",
    "#         name = names_train[i]\n",
    "#         n = name[name.index(\"_\")+1:]\n",
    "#         valid_name = f\"valid_{n}\"\n",
    "#         valid_idx = names.index(valid_name)\n",
    "#         print(i, valid_idx, name, valid_name)\n",
    "#         ax.plot(metrics[:, i], color='#1f77b4',  label='train')\n",
    "#         ax.plot(metrics[:, valid_idx], color = '#ff7f0e', label='valid')\n",
    "#         ax.set_title(n)\n",
    "#         ax.legend(loc='best')\n",
    "#     #plt.show()\n",
    "#     plt.savefig(f'{fig_src}/metrics.png', bbox_inches='tight')\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ec814eaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric names:  ['train_loss', 'train_dice_score', 'valid_loss', 'valid_dice_score']\n",
      "0 2 train_loss valid_loss\n",
      "1 3 train_dice_score valid_dice_score\n"
     ]
    }
   ],
   "source": [
    "save_plot_metrics(learn.recorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0c0836bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_UNETR_loss_BCE_loss_full_res_96_pixdim_1.5_do_flip_True_bs_1_epochs_60_time_1627918222_Mon_Aug_02_2021_hr_11_min_30\n"
     ]
    }
   ],
   "source": [
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b27d2017",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_test:\n",
    "    sys.stdout = old_stdout\n",
    "    log_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4c295b",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "683aaf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_tfms = [\n",
    "#     # normalize mean/std of foreground pixels\n",
    "#     ZScale(),\n",
    "#     # affine + flips\n",
    "#     RandomAffine(p=0.5, degrees=35, translate=0.1, scale=0.1),\n",
    "#     RandDihedral(p=0.5),\n",
    "#     # lighting\n",
    "#     RandBright(p=0.5),\n",
    "#     RandContrast(p=0.5),\n",
    "#     # noise for generalizability\n",
    "#     GNoise(p=0.5),\n",
    "#     GBlur(p=0.5),\n",
    "#     # add channel dim\n",
    "#     AddChannel()\n",
    "\n",
    "# UMich \n",
    "# code src: \"/home/labcomputer/Desktop/Rachel\"\n",
    "# data src: \"../../../../..//media/labcomputer/e33f6fe0-5ede-4be4-b1f2-5168b7903c7a/home/rachel/\"\n",
    "\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d1c877",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "87db8dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Test\")\n",
    "# xb, yb = dls.one_batch()\n",
    "# xb, yb = xb.cpu(), yb.cpu()\n",
    "\n",
    "# pb = model.cpu()(xb)\n",
    "# print(xb.shape, pb.shape)\n",
    "# print(f\"logcosh dice loss {log_cosh_dice_loss(pb,yb)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cb367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test:\n",
    "\n",
    "# #dls.device = \"cpu\"\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# x,y = dls.one_batch()\n",
    "# #x,y = to_cpu(x), to_cpu(y)\n",
    "\n",
    "# pred = learn.model(x)\n",
    "# loss = learn.loss_func(pred, y)\n",
    "\n",
    "# elapsed = time.time() - start\n",
    "\n",
    "# print(f\"Elapsed: {elapsed} s\")\n",
    "# print(\"Batch: x,y\")\n",
    "# print(type(x), x.shape, x.dtype, \"\\n\", type(y), y.shape, y.dtype)\n",
    "\n",
    "# print(\"Pred shape\")\n",
    "# print(type(pred), pred.shape, pred.dtype)\n",
    "\n",
    "# print(\"Loss\")\n",
    "# print(loss)\n",
    "# print(learn.loss_func)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
