{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7d2b951a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3321cd55",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "Train model\n",
    "\n",
    "Thanks to: OBELISK, FAIMED3D, MONAI\n",
    "- https://github.com/mattiaspaul/OBELISK\n",
    "-  https://github.com/kbressem/faimed3d/blob/main/examples/3d_segmentation.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493866e5",
   "metadata": {},
   "source": [
    "# Setup parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1db8c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "model_type = \"Regressor\" #\"SegResNetVAE\" # \"UNET3D\" #\"OBELISKHYBRID\" #\"VNET\" # \"UNET3D\" \"OBELISKHYBRID\"\n",
    "loss_type  = \"mse_loss\" #\"vae_loss\" #\"perim_loss\" #\"log_cosh_dice_loss\" # DICE\n",
    "\n",
    "# DATALOADER PARAMS\n",
    "bs          = 2\n",
    "nepochs     = 300\n",
    "num_workers = 2\n",
    "\n",
    "# PREPROCESS (Isotropic, PadResize)\n",
    "iso_sz    = 2\n",
    "maxs      = [144, 144, 144]\n",
    "\n",
    "# iso_sz    = 3\n",
    "# maxs      = [96, 96, 96]\n",
    "\n",
    "# Train:Valid:Test = 60:20:20\n",
    "valid_frac, test_frac = .20, .20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd2edd3",
   "metadata": {},
   "source": [
    "# Setup paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55a9cc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders in data src: saved_landmarks, saved_models, sample_other_dsets, Labels, saved_dset_metadata, runs, saved_preds, PitMRdata\n",
      "Folders in label src (data w labels): 50155-50212, PPMI_3107-3326, 50313-50372, 50213-50312, 50373-50453, 50002-50153, AIBL_2-263, ICMB_1005-1297, ADNI1_002_0023, ABVIB_49_235\n",
      "Folders in ABIDE src (data wo labels) PAD, ABIDE_1, ABIDE\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Paths to (1) code (2) data\n",
    "code_src    = \"/gpfs/home/gologr01\"\n",
    "data_src    = \"/gpfs/data/oermannlab/private_data/DeepPit\"\n",
    "\n",
    "# stored code\n",
    "deepPit_src = f\"{code_src}/DeepPit\"\n",
    "obelisk_src = f\"{code_src}/OBELISK\"\n",
    "\n",
    "# stored data\n",
    "model_src   = f\"{data_src}/saved_models\"\n",
    "label_src   = f\"{data_src}/PitMRdata/samir_labels\"\n",
    "ABIDE_src   = f\"{data_src}/PitMRdata/ABIDE\"\n",
    "\n",
    "# stored runs Tensorboard\n",
    "run_src     = f\"{data_src}/runs\"\n",
    "\n",
    "# print\n",
    "print(\"Folders in data src: \", end=\"\"); print(*os.listdir(data_src), sep=\", \")\n",
    "print(\"Folders in label src (data w labels): \", end=\"\"); print(*os.listdir(label_src), sep=\", \")\n",
    "print(\"Folders in ABIDE src (data wo labels) \", end=\"\"); print(*os.listdir(ABIDE_src), sep=\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabe2986",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b2455a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "684b0b85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imports (# Piece)\n",
    "from transforms import AddChannel, Iso, PadSz,\\\n",
    "                       ZScale, \\\n",
    "                       GNoise, GBlur,\\\n",
    "                       RandBright, RandContrast, \\\n",
    "                       RandDihedral, MattAff\n",
    "        \n",
    "        \n",
    "from helpers.losses import dice, dice_score, dice_loss, dice_ce_loss, log_cosh_dice_loss, perim_loss\n",
    "\n",
    "# MONAI\n",
    "from monai.losses        import DiceLoss\n",
    "from monai.metrics       import DiceMetric\n",
    "from monai.networks.nets import VNet, UNet, SegResNetVAE, HighResNet, UNETR, Regressor\n",
    "\n",
    "# Utilities\n",
    "import os, sys, gc, time, pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Input IO\n",
    "import SimpleITK as sitk\n",
    "import meshio\n",
    "\n",
    "# Numpy and Pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as DF\n",
    "\n",
    "# Fastai + distributed training\n",
    "from fastai              import *\n",
    "from fastai.torch_basics import *\n",
    "from fastai.basics       import *\n",
    "from fastai.distributed  import *\n",
    "from fastai.callback.all import SaveModelCallback, CSVLogger\n",
    "\n",
    "# PyTorch\n",
    "from torch import nn\n",
    "\n",
    "# Obelisk\n",
    "sys.path.append(deepPit_src)\n",
    "sys.path.append(obelisk_src)\n",
    "\n",
    "# OBELISK\n",
    "from utils  import *\n",
    "from models import obelisk_visceral, obeliskhybrid_visceral\n",
    "\n",
    "# Helper functions\n",
    "from helpers.preprocess import get_data_dict_n4, mask2bbox, print_bbox, get_bbox_size, print_bbox_size, batch_get_bbox\n",
    "from helpers.general    import sitk2np, np2sitk, print_sitk_info, lrange, lmap, numbers2groups, print_hardware_stats\n",
    "from helpers.viz        import viz_axis, viz_compare_inputs, viz_compare_outputs\n",
    "from helpers.time       import time_one_batch, get_time_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07e4d4e",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9bcf84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross\n",
      "/gpfs/data/oermannlab/private_data/DeepPit/PitMRdata/samir_labels/PPMI_3107-3326\n",
      "/gpfs/data/oermannlab/private_data/DeepPit/PitMRdata/samir_labels/ICMB_1005-1297\n",
      "/gpfs/data/oermannlab/private_data/DeepPit/PitMRdata/samir_labels/AIBL_2-263\n",
      "/gpfs/data/oermannlab/private_data/DeepPit/PitMRdata/samir_labels/ADNI1_002_0023\n",
      "/gpfs/data/oermannlab/private_data/DeepPit/PitMRdata/samir_labels/ABVIB_49_235\n",
      "**************************************************\n",
      "Abide\n",
      "/gpfs/data/oermannlab/private_data/DeepPit/PitMRdata/samir_labels/50373-50453\n",
      "/gpfs/data/oermannlab/private_data/DeepPit/PitMRdata/samir_labels/50313-50372\n",
      "/gpfs/data/oermannlab/private_data/DeepPit/PitMRdata/samir_labels/50213-50312\n",
      "/gpfs/data/oermannlab/private_data/DeepPit/PitMRdata/samir_labels/50155-50212\n",
      "/gpfs/data/oermannlab/private_data/DeepPit/PitMRdata/samir_labels/50002-50153\n"
     ]
    }
   ],
   "source": [
    "folders = sorted(Path(label_src).iterdir(), key=os.path.getmtime, reverse=True)\n",
    "# print(*[Path(f).name for f in folders], sep=\"\\n\")\n",
    "\n",
    "cross_lbl_folders = folders[:5]\n",
    "abide_lbl_folders = folders[5:]\n",
    "\n",
    "print(\"Cross\", *cross_lbl_folders, sep=\"\\n\"); print(\"*\"*50)\n",
    "print(\"Abide\", *abide_lbl_folders, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ae1812e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full: 335\n"
     ]
    }
   ],
   "source": [
    "# Get data dict\n",
    "data = {}\n",
    "folders = abide_lbl_folders\n",
    "for folder in folders: data.update(get_data_dict_n4(folder))\n",
    "\n",
    "# Convert data dict => items (path to MR, path to Segm tensor)\n",
    "items = list(data.values())\n",
    "print(f\"Full: {len(items)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e65f6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 2 weird, new total: 333\n"
     ]
    }
   ],
   "source": [
    "# remove bad label 50132\n",
    "weird_lbls = [50132, 50403]\n",
    "def is_weird(fn): return any([str(lbl) in fn for lbl in weird_lbls])\n",
    "   \n",
    "items = [o for o in items if not is_weird(o[0])]\n",
    "print(f\"Removed {len(weird_lbls)} weird, new total: {len(items)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abba66c",
   "metadata": {},
   "source": [
    "# Split train/valid/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0934d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, valid, test 201 66 66 total 333\n"
     ]
    }
   ],
   "source": [
    "# save test set indices\n",
    "with open(f\"{data_src}/saved_dset_metadata/split_train_valid_test.pkl\", 'rb') as f:\n",
    "    train_idxs, valid_idxs, test_idxs, train_items, valid_items, test_items = pickle.load(f)\n",
    "    tr_len, va_len, te_len =  len(train_items), len(valid_items), len(test_items)\n",
    "    print(\"train, valid, test\", tr_len, va_len, te_len, \"total\", tr_len + va_len + te_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19bbc228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# items = items[:30]\n",
    "\n",
    "# length  = len(items)\n",
    "# indices = np.arange(length)\n",
    "# np.random.shuffle(indices)\n",
    "# #rank0_first(lambda: np.random.shuffle(indices))\n",
    "\n",
    "# test_split   = int(test_frac  * length)\n",
    "# valid_split  = int(valid_frac * length) + test_split\n",
    "\n",
    "# test_idxs    = indices[:test_split] \n",
    "# valid_idxs   = indices[test_split:valid_split]\n",
    "# train_idxs   = indices[valid_split:]\n",
    "\n",
    "# train_items = [items[i] for i in train_idxs]\n",
    "# valid_items = [items[i] for i in valid_idxs]\n",
    "# test_items  = [items[i] for i in test_idxs]\n",
    "\n",
    "# # print\n",
    "# print(f\"Total  {len(items)} items in dataset.\")\n",
    "# print(f\"Train: {len(train_items)} items.\")\n",
    "# print(f\"Valid: {len(valid_items)} items.\")\n",
    "# print(f\"Test:  {len(test_items)} items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7501063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save test set indices\n",
    "# with open(f\"{data_src}/saved_dset_metadata/split_train_valid_test.pkl\", 'wb') as f:\n",
    "#     pickle.dump([train_idxs, valid_idxs, test_idxs, train_items, valid_items, test_items], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c1df11",
   "metadata": {},
   "source": [
    "# Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c5e481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.8\n",
    "\n",
    "# removed MattAff(p=p, strength=0.05)\n",
    "\n",
    "item_tfms  = [Iso(iso_sz), PadSz(maxs)]\n",
    "batch_tfms = [ZScale(), AddChannel(), MattAff(p=p, strength=0.05)]\n",
    "\n",
    "# batch_tfms = [\n",
    "#     # normalize mean/std of foreground pixels\n",
    "#     ZScale(),\n",
    "#     # flip\n",
    "#     RandDihedral(p=p),\n",
    "#     # noise\n",
    "#     GNoise(p=p, std_range=[0.01, 0.1]),\n",
    "#     #GBlur(p=p,  kernel_size_range=[5, 11], sigma=0.5),\n",
    "#     AddChannel(),\n",
    "#     # affine\n",
    "#     MattAff(p=p, strength=0.05)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ba5050",
   "metadata": {},
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b9bec60",
   "metadata": {},
   "outputs": [],
   "source": [
    " # tls, dls, cuda\n",
    "tls = TfmdLists(items, item_tfms, splits=(train_idxs, valid_idxs))\n",
    "dls = tls.dataloaders(bs=bs, after_batch=batch_tfms, num_workers=num_workers)\n",
    "dls = dls.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "702c1a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test get one batch\n",
    "# time_one_batch(dls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fe98f3",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9d788af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full res: [144, 144, 144]\n"
     ]
    }
   ],
   "source": [
    "full_res = maxs\n",
    "print(f\"Full res: {full_res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70e6f87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model = Regressor(\n",
    "    in_shape   = (1,*full_res), \n",
    "    out_shape  = (3), \n",
    "    channels   = (16, 32, 64, 128, 256),\n",
    "    strides    = (2, 2, 2, 2), \n",
    "    kernel_size=3, \n",
    "    num_res_units=2, \n",
    "    act='PRELU', \n",
    "    norm='INSTANCE', \n",
    "    dropout=None, \n",
    "    bias=True\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102371e4",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8547dda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xb,yb = dls.one_batch()\n",
    "# predb = model(xb)\n",
    "# bboxs = batch_get_bbox(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9298efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(yb)):\n",
    "#     print(mask2bbox(np.asarray(yb[i].cpu().squeeze())))\n",
    "    \n",
    "# # convert to probs\n",
    "# zeros = torch.where(yb == 1, 0, 1)\n",
    "# probs = torch.cat((zeros, yb),dim=1)\n",
    "# bboxs = [tuple([a.item() for a in bbox]) for bbox in bboxs]\n",
    "# for i in range(len(yb)):\n",
    "#     print(bboxs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ca6e194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # bbox2mask\n",
    "# def bbox2mask(bbox, sz=full_res):\n",
    "#     # float bbox -> integer\n",
    "#     a,b,c,d,e,f = torch.round(bbox).int()\n",
    "#     arr = torch.zeros(full_res)\n",
    "#     arr[a:b, c:d, e:f] = 1\n",
    "#     return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b5629e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # metric\n",
    "# def dice_score_regression(preds, targets):\n",
    "#     pred_masks = torch.stack([bbox2mask(bbox) for bbox in preds], dim=0).to(preds.get_device())\n",
    "    \n",
    "#     dice_loss = dice(pred_masks, targets.squeeze())\n",
    "#     #loss = Variable(dice_loss, requires_grad = True)\n",
    "#     return dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbbb6bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.losses import MSELossFlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "917a5e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_range(x, lo, hi): return torch.sigmoid(x) * (hi-lo) + lo\n",
    "\n",
    "def mse_centroid_loss(preds, targets):\n",
    "    preds = sigmoid_range(preds, lo=0, hi=full_res[0])\n",
    "    targets = targets.squeeze() # BCDHW -> BDWH\n",
    "    centroids = torch.stack([torch.nonzero(tgt).float().mean(dim=0) for tgt in targets], dim=0)\n",
    "    return MSELossFlat()(preds, centroids)#/100.0 # scale it down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "36a80676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from fastai\n",
    "# def sigmoid_range(x, lo, hi): return torch.sigmoid(x) * (hi-lo) + lo\n",
    "\n",
    "# def mse_bin_mask_loss(preds, targets):\n",
    "#     \"\"\"\n",
    "#     preds   = Bx6 coords\n",
    "#     targets = BCDHW, where C = 1\n",
    "#     -> target_bbox = Bx6\n",
    "#     -> preds scaled to be [0,144]\n",
    "#     -> MSE(preds, target_bbox)\n",
    "#     \"\"\"\n",
    "#     # get bbox B x (imin imax jmin jmax kmin kmax)\n",
    "#     target_bbox = batch_get_bbox(targets).to(targets.get_device())\n",
    "    \n",
    "#     # scale preds between 0-size\n",
    "#     preds = sigmoid_range(preds, lo=0, hi=full_res[0])\n",
    "\n",
    "#     # print debug\n",
    "#     #print(target_bbox.dtype, preds.dtype)\n",
    "    \n",
    "# #     print(\"Preds: \", preds)\n",
    "# #     print(\"Target bbox: \", target_bbox)\n",
    "# #     print(f\"MSE: {torch.nn.MSELoss()(preds.float(), target_bbox.float()):.2f}\")\n",
    "          \n",
    "#     # get MSE between prediction and target bbox\n",
    "#     return torch.nn.MSELoss(reduction='sum')(preds.float(), target_bbox.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "36aefc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse_bin_mask_loss(predb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a58bed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if loss_type == \"log_cosh_dice_loss\":\n",
    "    loss_function = log_cosh_dice_loss\n",
    "elif loss_type == \"DICE\":\n",
    "    loss_function = dice_loss\n",
    "    \n",
    "elif loss_type == \"perim_loss\":\n",
    "    loss_function = log_cosh_dice_loss\n",
    "    #loss_function = perim_loss\n",
    "    \n",
    "elif loss_type == \"vae_loss\":\n",
    "    loss_function = vae_loss\n",
    "    \n",
    "elif loss_type == \"mse_loss\":\n",
    "    loss_function = mse_centroid_loss\n",
    "else:\n",
    "    loss_function = DiceLoss(to_onehot_y=False, sigmoid=True, squared_pred=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e3351ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: model_Regressor_loss_mse_loss_iso_2mm_pad_144_144_144_bs_2_epochs_300_time_1627072951_Fri_Jul_07_2021_hr_16_min_42\n"
     ]
    }
   ],
   "source": [
    "# Save test idxs + model + runs\n",
    "\n",
    "# file name\n",
    "model_time = rank0_first(lambda:get_time_id()) # 'Mon Oct 18 13:35:29 2010'\n",
    "model_name = f\"model_{model_type}_loss_{loss_type}_iso_{iso_sz}mm_pad_{maxs[0]}_{maxs[1]}_{maxs[2]}_bs_{bs}_epochs_{nepochs}_time_{model_time}\"\n",
    "print(f\"Model name: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5808b4",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f241a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dir\n",
    "model_src = f\"{run_src}/{model_name}\"\n",
    "fig_src = f\"{model_src}/figs\"\n",
    "Path(fig_src).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3a482a",
   "metadata": {},
   "source": [
    "# Metrics & Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f95fa9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == \"Regressor\":\n",
    "    metrics = []# [dice_score_regression]\n",
    "    cbs = [SaveModelCallback(monitor='valid_loss', with_opt=True), CSVLogger(fname=f\"{fig_src}/history.csv\")]\n",
    "else:\n",
    "    metrics = [dice_score]\n",
    "    cbs = [SaveModelCallback(monitor='dice_score', with_opt=True), CSVLogger(fname=f\"{fig_src}/history.csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2c067125",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerimLossMidway(Callback):\n",
    "    def before_epoch(self): \n",
    "        if self.epoch == self.n_epoch//2:\n",
    "            self.learn.loss_func = perim_loss\n",
    "            print(\"Changed \", self.learn.loss_func, \"at epoch \", self.n_epoch//2)    \n",
    "            \n",
    "if loss_type == \"perim_loss\":\n",
    "    print(\"added PerimLoss callback\")\n",
    "    cbs.append(PerimLossMidway())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ac990b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test set indices\n",
    "with open(f\"{model_src}/test_items.pkl\", 'wb') as f:\n",
    "    rank0_first(lambda:pickle.dump(list(test_items), f))\n",
    "   \n",
    "# save data augs\n",
    "with open(f\"{model_src}/data_augs.txt\", 'w') as f:\n",
    "    s = \"\\n\".join([model_name] + [str(tfm) for tfm in item_tfms + batch_tfms])\n",
    "    rank0_first(lambda: print(s, file=f))\n",
    "    \n",
    "# with open(f\"{model_src}/{model_name}_test_items.pkl\", 'wb') as f:\n",
    "#     rank0_first(lambda:pickle.dump(list(test_items), f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d7809f",
   "metadata": {},
   "source": [
    "# Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d3b8faf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#GPU = 2, #CPU = 40\n",
      "GPU Tesla V100-SXM2-16GB RAM Free: 14860MB | Used: 1300MB | Util   8% | Total 16160MB\n",
      "GPU Tesla V100-SXM2-16GB RAM Free: 16157MB | Used: 3MB | Util   0% | Total 16160MB\n"
     ]
    }
   ],
   "source": [
    "# clear cache\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print_hardware_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a13fe9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = rank0_first(lambda:\n",
    "            Learner(dls   = dls, \\\n",
    "                model     = model, \\\n",
    "                loss_func = loss_function, \\\n",
    "                metrics   = metrics, \\\n",
    "                model_dir = model_src, \\\n",
    "                cbs       = cbs)\n",
    "        )\n",
    "\n",
    "# cbs TensorBoardCallback(Path(run_src)/model_name, trace_model=True)\n",
    "# GPU\n",
    "learn.model = rank0_first(lambda:learn.model.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "99926f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sz: 144 -> 72 -> 36 -> 18 -> 9 -> 6\n",
    "# ft: 16 -> 32 -> 64 -> 128 -> 256\n",
    "# print(learn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ce240e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check\n",
    "# print(\"Check\")\n",
    "# b = dls.one_batch()\n",
    "# xb,yb = b\n",
    "# print(f\"Batch: {len(b)}. xb: {xb.shape}, yb: {yb.shape}\")\n",
    "# predb = learn.model(xb)\n",
    "# print(f\"Pred batch: {predb.shape}\")\n",
    "# loss = learn.loss_func(predb, yb)\n",
    "# print(f\"Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fd54581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(predb[0].shape, predb[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceedd82",
   "metadata": {},
   "source": [
    "# LR Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7ff83a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"PRE learn.fit one cycle\")\n",
    "# with learn.distrib_ctx():\n",
    "#     learn.fit_one_cycle(2, 3e-3, wd = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b7b2d803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=tensor(8.3176e-06))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAzJ0lEQVR4nO3dd3Rc5bXw4d9Wr5at4ibZyHLBNu4IY9PB9EAooRi4MQlOHEiAFEKAe9eXtlJvCoFQTUgghOAYAxeT0KsNBtxtMK6SXCSrjHpvo/39MUdGNurSaNp+1po1M+85Z86eY1lb562iqhhjjDHHCvN1AMYYY/yTJQhjjDGdsgRhjDGmU5YgjDHGdMoShDHGmE5ZgjDGGNOpCF8HMBCpqamamZnp6zCMMSagbNq0qVRV03raL6ATRGZmJhs3bvR1GMYYE1BE5EBv9rMqJmOMMZ2yBGGMMaZTliCMMcZ0KqDbIDrT0tJCfn4+jY2Nvg7FZ2JiYsjIyCAyMtLXoRhjAljQJYj8/HwSExPJzMxERHwdzpBTVcrKysjPz2fChAm+DscYE8CCroqpsbGRlJSUkEwOACJCSkpKSN9BGWMGR9AlCCBkk0O7UP/+xgS713YUkeuq9fp5gjJBBJKEhAQA9u/fz4wZM3wcjTHG37W627j1n5t5dlO+189lCWL7Srh3Bvx0uOd5+0pfR2SMMV0qqGygxa1MSI33+rlCO0FsXwkv3Q5VhwD1PL90+4CSxN13382DDz545P1Pf/pTfvGLX7Bo0SLmzZvHzJkzefHFF7v9DLfbzZ133slJJ53ErFmzePTRRwFYsmQJ//d//3dkvxtuuKHHzzLGBJfc0joAsixBeNlbP4eWhqPLWho85f107bXXsnLl5wlm5cqV3Hjjjbzwwgts3ryZd955hzvuuIPulnp9/PHHSUpKYsOGDWzYsIHHHnuMvLw8li5dyhNPPAFAVVUV69at40tf+lK/YzXGBJ48lydBDMUdRNB1c+2Tqi7q8Loq74W5c+dSUlLC4cOHcblcjBgxgtGjR/P973+fNWvWEBYWRkFBAcXFxYwePbrTz3j99dfZvn07q1at8oRTVcXevXs5//zz+fa3v43L5eK5557jK1/5ChERof1PaEyoySutY1hMBMnxUV4/V2j/dknKcKqXOikfgKuvvppVq1ZRVFTEtddey9NPP43L5WLTpk1ERkaSmZnZbTdUVeXPf/4zF1xwwRe2LVmyhH/84x+sWLGCv/3tbwOK0xgTeHJLa5mQljAkvRW9WsUkIsNFZJWI7BKRnSKyUESSReQNEdnrPI9w9hURuV9E9onIdhGZ583YAFj0Y4iMPbosMtZTPgDXXnstK1asYNWqVVx99dVUVVUxcuRIIiMjeeeddzhwoPuJFC+44AIefvhhWlpaANizZw91dZ7byq997Wv86U9/AmD69OkDitMYE3jyXHVD0v4A3r+DuA94VVWvEpEoIA74b+AtVf2NiNwN3A3cBVwETHYeJwMPO8/eM+saz/NbP/dUKyVleJJDe3k/nXDCCdTU1JCens6YMWO44YYbuPTSS5k5cybZ2dlMnTq12+O/8Y1vsH//fubNm4eqkpaWdqRxetSoUUybNo3LL798QDEaYwJPQ7Obw1WNQ9L+ACDdNZYO6INFkoCtQJZ2OImI7AbOUtVCERkDvKuqx4vIo87rZ47dr6tzZGdn67HrQezcuZNp06YN/hfyE/X19cycOZPNmzeTlJTU5X7Bfh2MCUU7C6u56L61/Pm6uVw6e2y/P0dENqlqdk/7ebOKaQLgAv4mIltE5C8iEg+M6vBLvwgY5bxOBzo2COQ7Zcbx5ptvMm3aNG677bZuk4MxJjjllQ5dDybwbhVTBDAPuE1VPxaR+/BUJx2hqioifbqFEZFlwDKA8ePHD1asAeHcc8/tsf3CGBO8hjpBePMOIh/IV9WPnfer8CSMYqdqCee5xNleAIzrcHyGU3YUVV2uqtmqmp2W1uOSqsYYEzRyXXWMGhZNfPTQdED1WoJQ1SLgkIgc7xQtAj4DVgM3OmU3Au1DgVcDS5zeTAuAqu7aH3o4d/8DDwKh/v2NCVZ5pbVDdvcA3u/FdBvwtNODKRf4Op6ktFJElgIHgPYuQy8DFwP7gHpn3z6LiYmhrKwsZKf8bl8PIiYmxtehGGMGWV5pHRfNHDNk5/NqglDVrUBnLeWLOtlXge8M9JwZGRnk5+fjcrkG+lEBq31FOWNM8Kioa6aivmXIxkBAEI6kjoyMtJXUjDFBJ69saBuoIdQn6zPGmAAxlJP0tbMEYYwxASCvtI7wMGFcctyQndMShDHGBIDc0lrGJ8cRGT50v7YtQRhjTADIddUNafUSWIIwxhi/19am7C+zBGGMMeYYRdWNNLa0WYIwxhhztLwhXIe6I0sQxhjj53LbJ+lLswRhjDGmgzxXHbGR4YxKHNopdCxBGGOMn8srrSUzNZ6wsKGdX84ShDHG+Lm80qFbh7ojSxDGGOPHmlvbOFTRQNYQtz+AJQhjjPFrhyrqcbfpkHdxBUsQxhjj13wxSV87SxDGGOPHhnod6o4sQRhjjB/LLa0jOT6K4XFRQ35uSxDGGOPHcl1Duw51R5YgjDHGj+WVDv0kfe28miBEZL+IfCIiW0Vko1P2UxEpcMq2isjFHfa/R0T2ichuEbnAm7EZY4y/q21qpaSmyWcJYijWpD5bVUuPKbtXVX/fsUBEpgOLgROAscCbIjJFVd1DEKMxxvid/T6apK+dP1UxXQasUNUmVc0D9gHzfRyTMcb4jK8m6Wvn7QShwOsisklElnUov1VEtovIX0VkhFOWDhzqsE++U3YUEVkmIhtFZKPL5fJe5MYY42PtYyAyU4IzQZymqvOAi4DviMgZwMPARGAOUAj8oS8fqKrLVTVbVbPT0tIGO15jjPEbeaW1pA+PJSYy3Cfn92qCUNUC57kEeAGYr6rFqupW1TbgMT6vRioAxnU4PMMpM8aYkOTLHkzgxQQhIvEiktj+Gjgf+FRExnTY7QrgU+f1amCxiESLyARgMrDeW/EZY4w/U1VyfZwgvNmLaRTwgoi0n+efqvqqiDwlInPwtE/sB74FoKo7RGQl8BnQCnzHejAZY0JVWV0zNY2tPpnFtZ3XEoSq5gKzOyn/ajfH/BL4pbdiMsaYQJHb3kAdjFVMxhhj+i/HVQvApLQEn8VgCcIYY/xQTkkt0RFhpA+P9VkMliCMMcYP5bhqyUpLGPJ1qDuyBGGMMX4ox1XHRB82UIMlCGOM8TuNLW4OVdQz0YftD2AJwhhj/M7+sjpUYeJISxDGGGM6aO/i6qtZXNtZgjDGGD+TU+Lp4urLQXJgCcIYY/xOjsszSV9c1FAs2dM1SxDGGONnclx1Pr97AEsQxhjjV1SVHFetz3swgSUIY4zxK0XVjdQ3u33egwksQRhjjF/JKfH0YPL1IDmwBGGMMX7FHybpa2cJwhhj/EiOq5bE6AjSEqN9HYolCGOM8Sc5rlqyRibgLLbmU5YgjDHGj+SU+H6SvnaWIIwxxk/UNrVSVN3oF11cwRKEMcb4jTxXew+mEEgQIrJfRD4Rka0istEpSxaRN0Rkr/M8wikXEblfRPaJyHYRmefN2Iwxxt8c6cE0MnSqmM5W1Tmqmu28vxt4S1UnA2857wEuAiY7j2XAw0MQmzHG+I0cVy3hYcL45NBJEMe6DHjSef0kcHmH8r+rx0fAcBEZ44P4jDHGJ3JctYxPjiMqwj9q/70dhQKvi8gmEVnmlI1S1ULndREwynmdDhzqcGy+U3YUEVkmIhtFZKPL5fJW3MYYM+T8qQcTeD9BnKaq8/BUH31HRM7ouFFVFU8S6TVVXa6q2aqanZaWNoihGmOM77jblLzSOr9poAYvJwhVLXCeS4AXgPlAcXvVkfNc4uxeAIzrcHiGU2aMMUEvv6KeZndbaCQIEYkXkcT218D5wKfAauBGZ7cbgRed16uBJU5vpgVAVYeqKGOMCWrtPZgm+kkPJgBvLlc0CnjBGS4eAfxTVV8VkQ3AShFZChwArnH2fxm4GNgH1ANf92JsxhjjV9pncc1K9Z87CK8lCFXNBWZ3Ul4GLOqkXIHveCseY4zxZzmuWlLioxgRH+XrUI7wj75UxhgT4nJd/tVADZYgjDHGL+S4av2q/QEsQRhjjM9V1DVTVtdsdxDGGGOOllvq9GCyBGGMMaajz9ehtgRhjDGmgxxXLVERYaSPiPV1KEexBGGMMT6W46olKzWe8DDfLzPakSUIY4zxsRw/7OIKliCMMcanmlrdHCyvJ8uPZnFtZwnCGGN86GBZPe42tTsIY4wxRzsySZ8lCGOMMR0dLK8H4LjUOB9H8kWWIIwxxocOVzaSGBPBsJhIX4fyBZYgjDHGh/IrGkgf7l/jH9pZgjDGGB86XGkJwhhjTCcOVzUw1hKEMcaYjuqaWqmsb7EEYYwx5miHKxsA/G4OpnaWIIwxxkcK2hPE8BgfR9I5rycIEQkXkS0i8m/n/RMikiciW53HHKdcROR+EdknIttFZJ63YzPGGF9qTxD+WsUU0ZudRCQeaFDVNhGZAkwFXlHVll4c/l1gJzCsQ9mdqrrqmP0uAiY7j5OBh51nY4wJSocrG4gIE0YmBvYdxBogRkTSgdeBrwJP9HSQiGQAXwL+0otzXAb8XT0+AoaLyJhexmeMMQHncGUjo5Ni/G6a73a9TRCiqvXAlcBDqno1cEIvjvsT8COg7ZjyXzrVSPeKSLRTlg4c6rBPvlN2dCAiy0Rko4hsdLlcvQzfGGP8T0GF/3ZxhT4kCBFZCNwA/McpC+/hgEuAElXddMyme/BUUZ0EJAN39T5cUNXlqpqtqtlpaWl9OdQYY/xKQWUDGUGQIL6H5xf7C6q6Q0SygHd6OOZU4Msish9YAZwjIv9Q1UKnGqkJ+Bsw39m/ABjX4fgMp8wYY4JOq7uNourGwL+DUNX3VPXLqvpbEQkDSlX19h6OuUdVM1Q1E1gMvK2q/9XeriAiAlwOfOocshpY4vRmWgBUqWph/76WMcb4t5KaJtxtGvgJQkT+KSLDnN5MnwKficid/Tzn0yLyCfAJkAr8wil/GcgF9gGPAd/u5+cbY4zf8/dBctDLbq7AdFWtFpEbgFeAu4FNwO96c7Cqvgu867w+p4t9FPhOL+MZcg+8vZcTxiZx9tSRvg7FGBME/H2QHPS+DSJSRCLxVAmtdsY/qNei8jOt7jbue2svd67aTl1Tq6/DMcYEAX8fJAe9TxCPAvuBeGCNiBwHVHsrKH9zqKKBFrdSWtvEX9bm+TocY0wQOFzZwIi4SOKieluRM/R620h9v6qmq+rFTg+kA8DZXo7Nb+Q6a8ZOSI1n+ZocSmubfByRMSbQ+fsYCOh9I3WSiPyxfYCaiPwBz91ESGhfVPyP18ymsbWN+9/a6+OIjDGB7nClf3dxhd5XMf0VqAGucR7VeMYwhIRcVx0p8VHMHT+C6+aP458fHySvtK7bY+qbW4/ceRhjzLH8eSW5dr1NEBNV9Seqmus8fgZkeTMwf5LrqiMrzXPD9N1FU4iKCOP3r+3ucv/yumaufuRDLrxvLZX1zUMVpjEmQFQ1tFDT1Bo0CaJBRE5rfyMipwIN3gnJ/+SW1pKVmgBAWmI03zw9i/98UsiWgxVf2NdV08R1yz9iZ2E1za1tfLCvbKjDNcb4ucMB0IMJep8gbgYeFJH9ztQZDwDf8lpUfqSqvoXS2mYmjvy8yeWbZ2SRmhDFr1/ZhWf4hkdRVSPXLv+Qg+X1PPH1+STGRLBmj00oaIw5WiAMkoPe92LapqqzgVnALFWdC3Q64C3Y5JR62hHa7yAAEqIj+O65U1ifV87bu0oAyK+o59rlH1JS3cTfl87njClpnDoxlbV7XUclEWOM+XwMhP8OkoM+riinqtWq2j7+4QdeiMfv5Lo8jdHtbRDtFp80jqzUeH776i7ySuu49tGPKK9r5qml8zkpMxmA06ekcriqkRxX9w3axpjQUlDZQFR4GKnx0T3v7EMDWXLUP1e4GGQ5rloiw4VxyXFHlUeGh3HnBcezp7iWi+9bS11zK898cwFzx484ss8Zkz3TkVs1kzGmI08X1xjC/HShoHYDSRAhUW+S66plfHIckeFfvFQXzhjNSZkjiIsKZ8WyBcxITzpq+7jkOCakxrN2ryUIY8znCirq/b6BGnqYrE9Eaug8EQjg/99uEHi6uCZ0uk1EePKm+bjblMSYyE73OX1yKs9uzKep1U10RLdrLBljQsThykZOn5zq6zB61O0dhKomquqwTh6Jquq/E4gMklZ3GwfK6r/Q/tBRXFREl8kBPNVMDS1uNu3/YpdYY0zoaXG3UVzj/6OoYWBVTEEvv6KBZncbE7u4g+iNBRNTiAgT1uwtHcTIjDGBqqiqEVX8fpAcWILoVq7TxXViN3cQPUmIjmDecSOsHcIYA3RYB8LPx0CAJYhuHenimtr/OwiAM6ekseNwtc0Ca4wJmFHUYAmiWzmuWpLjoxgRHzWgz2lvjHrfqpmMCXkFFZ4EMSbJvwfJgSWIbuW46shKHfis5ieMTWJEXCRrrJrJmJB3uKqB1IRoYiL9v1ej1xOEiISLyBYR+bfzfoKIfCwi+0TkXyIS5ZRHO+/3OdszvR1bTzrO4joQ4WHCaZPTWLu31KbdMCbEFVQ2+vU61B0NxR3Ed4GdHd7/FrhXVScBFcBSp3wpUOGU3+vs5zNVDS2U1jZ1OQair06fnIqrpoldRTWD8nnGmMAUKIPkwMsJQkQygC8Bf3HeC55J/lY5uzwJXO68vsx5j7N9kbP/oKusb+a5Tfm0tXX913z7Yj8D6eLaUXs7hPVmMiZ0qSqHKxsDoosreP8O4k/Aj4A2530KUKmqrc77fCDdeZ0OHAJwtlc5+x9FRJa1L33qcvXvl+27u13c8ew2NneynkO7ribp668xSbFMGZXAWmuoNiZkVda30NDitjsIEbkEKFHVTYP5uaq6XFWzVTU7LS2tX59x7vRRREeE8dK2w13uk1taS0SYMP6YSfoG4vTJaXycV05Ds3vQPtMYEzgKAqiLK3j3DuJU4MvOAkMr8FQt3QcMF5H2aToygALndQEwDsDZngR4ZTm2hOgIFk0byX8+KaTV3dbpPrmuOsandD5JX3+dMSWN5tY21u8vH7TPNMYEjvYEkREAg+TAiwlCVe9R1QxVzQQWA2+r6g3AO8BVzm43Ai86r1c773G2v61e7PJz6ayxlNY283Fe57+sc1y1Ax4gd6z5mclERYSx1qb/NiYkBdIgOfDNOIi7gB+IyD48bQyPO+WPAylO+Q+Au70ZxNlTRxIfFd5pNZO7TdlfVj+gKTY6ExsVzvzMZBsPYUyIKqhoICYyjBFxXU/w6U+GJEGo6ruqeonzOldV56vqJFW9WlWbnPJG5/0kZ3uuN2OKiQzn/BNG88qnRTS3Hl3NVFDRQHNr26A1UHd0xpRU9hTXUlTVOOifbYzxb4erGkgfHouXOmgOupAeSX3p7DFUNbTw/r6j/6LPGeQurh2dOsnT3XVdjvVmMibUFFQGxjTf7UI6QZw2KY2k2Ehe2lZ4VHl7ghisQXIdTRs9jOFxkXyY45X2d2OMHyuoaAiYMRAQ4gkiKiKMi2aM5vUdRTS2fN71NLe0juFxkSQPcJK+zoSFCSdPSOajPEsQxoSSxhY3pbVNliACyaWzx1LX7OadXSVHynJdtV6pXmq3MCuFQ+UN5FfUe+0cxhj/0t7uaFVMAWRBVgqpCdG8tP3z3kyDNYtrl+ec6BkgbtVMxoSOQBskB5YgCA8TvjRzNG/tLKG2qZWaxhZcNYM3SV9npoxMJDk+ig9zLUEYEyoCbZAcWIIAPNVMTa1tvPlZ8aDPwdSZsDBhQVYyH+eW2/TfxoSIw5UNiMCoYYEx1TdYggBg3vgRjE2K4aVth73axbWjhVkpFFQ2cKi8wavnMcb4h88OVzM2KZaoiMD5tRs4kXpRWJhwyeyxrNnrYsvBSsIHeZK+zizIctohcm08hDHBrrK+mXd2l3DhjNG+DqVPLEE4Lp01lha3snLjIcYnx3k9y08amUBqQrQ1VBsTAl7aXkiLW7lyXnrPO/sRSxCOGenDyEyJo6m1bdDnYOqMiKcd4sPcMmuHMCbIPbcpn6mjE5k+ZpivQ+kTSxAOEeHS2WMB74yg7szCiSkUVzexv8zGQxgTrHJctWw9VMlX5mUEzBxM7SxBdPDl2WMJE4Ysyx9ph7BqJmOC1gubCwgTuGzOWF+H0meWIDqYPCqRt+4468idhLdlpcYzMjHaxkMYE6Ta2pQXthRw+uQ0RgZQ99Z2liCOMSE1nvCwobkNFBEWTkzhwxxrhzAmGH2UV0ZBZUPANU63swThYwuyUiitbSLHGaBnjAkez28uIDE6ggtOCKzure0sQfjYwiPjIayayZhgUt/cyiufFHLxzDHERIb7Opx+sQThY8elxDEmKYaPrKHamKDy+o5i6prdAVu9BF5MECISIyLrRWSbiOwQkZ855U+ISJ6IbHUec5xyEZH7RWSfiGwXkXneis2fiAgLs1L4yMZDGBNUntucT8aIWE7KTPZ1KP3mzTuIJuAcVZ0NzAEuFJEFzrY7VXWO89jqlF0ETHYey4CHvRibX1mQlUJZXTN7S2p9HYoxZhAUVTXy/r5SrpyXQdgQdXrxhghvfbB6/hxu/40X6Ty6+xP5MuDvznEfichwERmjqoXdHBMUFnZYH2LKqEQfR2OMAcivqGfD/nJ2FtYQFxVOSnwUKQnRJMdHkZoQRUp8NCO6WHXy/7YWoApXzg3c6iXwYoIAEJFwYBMwCXhQVT8WkVuAX4rIj4G3gLtVtQlIBw51ODzfKQv6BDEuOY704bF8mFPGjadk+jocY0LSvpIaPs4rZ0NeORv2VxxZvyEqPIxmd1unx8zOSOKrCzO5ZNbnDdGqynOb8jnxuBFkenHhsaHg1QShqm5gjogMB14QkRnAPUAREAUsB+4Cft7bzxSRZXiqoBg/fvxgh+wzCyem8ObOYtraNKBvSY0JRM9tyueOZ7cBkJoQzfwJI/jm6RM4aUIyU0cPo02VivpmymqbKa9rpqyumYKKBp7bnM8Pn93Gr17eybUnjeOGk8dTUdfC3pJafnnFDB9/q4HzaoJop6qVIvIOcKGq/t4pbhKRvwE/dN4XAOM6HJbhlB37WcvxJBays7ODplV3QVYKqzbls7u4hmkBNqGXMYFuxYaDTBqZwGNLsslMifvCnEnhCCMTYxiZePRo6JvPzOLDnDL+/uEBHn0vh0ffy2GMs+bDJTMDb2qNY3mzF1Oac+eAiMQC5wG7RGSMUybA5cCnziGrgSVOb6YFQFUotD+0a2+HeGtnsY8jMSa0FFc3svFABZfNHsuE1Pg+TagnIpwyKZVHvnoia+86h1vOmkhji5vL54wlKS7Si1EPDW/eQYwBnnTaIcKAlar6bxF5W0TSAAG2Ajc7+78MXAzsA+qBr3sxNr+TPjyW0yen8sS6A3zj9KyAHVhjTKB5bUcRqnDRzIGNdk4fHsudF0zlzgumDlJkvufNXkzbgbmdlJ/Txf4KfMdb8QSCW86cyPV/+ZjnNudzw8nH+TocY0LCy58UMnlkApNGWg/CY9lIaj+ycGIKs8cN59H3cmntoteEMWbwlNY2sT6vnItmjvF1KH7JEoQfERFuOXMiB8vreeXTIl+HY0zQe31HMW0KFw+weilYWYLwM+dPH0VWWjwPv5tjU28Y42WvfFrIhNR4jrcBqp2yBOFnwsKEm8+cyGeF1azZW+rrcIwJWhV1zazLKeOiGaMDbinQoWIJwg9dPied0cNiePjdfb4OZdAcLKtn8fIP2bi/3NehGAPAG58V425TLrb2hy5ZgvBDURFhfOP0CXyUW87mgxW+DmfAmlrd3PrMZj7KLef7K7dS19Tq65CM4ZVPCxmXHMsJY21galcsQfip6+aPJyk2koffzfF1KAP2m1d2sT2/ilvOmkh+RQO/eWWXr0MyIa6qoYX395Vy8YwxVr3UDUsQfio+OoIbT8nkjc+K2Vtc4+tw+u21HUX87YP9fO2UTO66cCo3nTqBpz46wLp91r5ifOetncW0uJULZ1jvpe5YgvBjXzslk5jIMB55L9fXofTLofJ67nx2GzPTk7jnYs/o0h+efzwTUuP50XPbrarJ+MzLnxQxNimGOeOG+zoUv2YJwo8lx0ex+KTxvLi14MjUw4GiubWN257Zgio8eP08oiM8U4fERoXzu6tmUVDZwK9f2enjKE0oqm1qZc1eFxda9VKPhmQ2V9N/3zh9Av/46AAX3ruG6Mhw2tdcah8iMXf8CB64fq7fzd30u9d2sfVQJQ/dMI/xKXFHbcvOTGbpqRP4y/t5XDRjDKdOSvVRlCYUvb2rhObWNhsc1wuWIPxcxog4fn3lTLYcqgQ8MxwCiEBjSxurNuVzz/Of8MdrZvvNX0Nv7SzmsbV5fHXBcV12IfzhBcfz9q4SfrRqO699/wwSou1H0QyNVz4pZGRiNPPGj/B1KH7P/lcGgKuzx3F19rhOtx2XHMcf3tjDlFGJ3HLWxCGLqbqxhfW55dQ1t9LQ7Ka+2U1Di5v65lae/vgg08cM43++NK3L42Miw/nd1bO5+pF1/OrlnfzqiplDFrsJXfXNrbyzu4RrssfZwly9YAkiwN16ziT2lNTyv6/tYtLIBM6bPsrr5yypbmTxYx+R66r7wrbwMCFjRCwP3jCvx2qvE48bwTdOz2L5mlwumjGa0yeneStkYwB4d7eLxpY2Lpphg+N6wxJEgBMRfnfVLA6W1fHdFVt47pZT+rQiXau7jWc35bN8TS7nTB3J3RdNJTK8674L7cmhqKqRR/7rRCaNjCc2KoL4qHBio8KJCg/rU1XXD86bwtu7Srhj5TZe/d4ZJHexCLwxA9XqbuOJD/aTmhDF/AnJvg4nIFgvpiAQExnO8iXZJMZE8I0nN1Ja29TjMW1tykvbDnPevWu45/lPAHj8/Tyuf+wjSqobOz2muLqRxcs9yeGJr8/nwhmjmTQykfThsQyPiyI6IrzP7SAxkeHcv3gulfUt/GjVNpug0HjNH9/Yw/r95dx90TTCrXqpVyxBBIlRw2J4bEk2ZXVN3PzUJppa3Z3up6q8s7uESx94n9ue2UJUeBiPLcnm7TvO5L7Fc/i0oJov/fl91ucdPWdScXUj1y3/iOLqRp68af6g/gU2feww7rl4Km/uLOHvHx4YtM81pt0bnxXz0Ls5XDd/PFedmOHrcAKGBPJfbNnZ2bpx40Zfh+FX/r39MLf+cwvnThvF7IwkGlvdNDS30dDiprHFTV5pHVsPVTIuOZYfnDeFL89OP+qvqd1FNdz8j00cLK/nvy+exk2nZlJc3cR1zp3FkzfNJztz8G/PVZWlT27k/X2lvPidU/tUTWZMd/aX1nHpA++TmRLPszcv9Lsu4b4gIptUNbvH/SxBBJ8H3t7LH97Yg6qn0TguMpzoyHBio8JIjI5k8fxxLD5pPFERnd9AVje28MOV23j9s2IunjmanYU1uGqaePKmkzjxOO/V3ZbVNnHhfWsZHhvJ6ltPIzbK/iObgWlodnPFQx9QWNXIv287jXHJcT0fFAJ8niBEJAZYA0TjaQxfpao/EZEJwAogBdgEfFVVm0UkGvg7cCJQBlyrqvu7O4cliK41NLuJCJduG5y7o6o88l4uv3ttF3FRETx503xOPM77/cbX7nXx1cfXc/3J463rqxkQVeWHz27n+S35/PVrJ3H28SN9HZLf6G2C8GYvpibgHFWtFZFI4H0ReQX4AXCvqq4QkUeApcDDznOFqk4SkcXAb4FrvRhfUBvoX98iwi1nTeTUSSnERUUwaWTCIEXWvdMnp/GtM7N49L1czpicyoXWHdH004oNh3hucz63L5psyaGfvNZIrR61zttI56HAOcAqp/xJ4HLn9WXOe5zti8RfhgaHsFkZw4csObS747zjmZWRxF3PfcLhAJuDyviH7fmV/OTFHZwxJY3vLprs63AClld7MYlIuIhsBUqAN4AcoFJV26fxzAfSndfpwCEAZ3sVnmooE2KiIsK4f/FcWt1tfOupTZTXNfs6JBNACqsauPmpTaQlRvOna+dYl9YB8GqCUFW3qs4BMoD5wNSBfqaILBORjSKy0eVyDfTjjJ/KTI3nz9fPZU9xDVc9so78inpfh2QCQGV9M0seX091YyuPfvVEG3g5QEMyDkJVK4F3gIXAcBFpb/vIAAqc1wXAOABnexKexupjP2u5qmaranZamk3NEMzOmTqKp5aeTGlNE195eB27iwJ34STjfQ3Nbm56YgMHyupZvuREZqQn+TqkgOe1BCEiaSIy3HkdC5wH7MSTKK5ydrsReNF5vdp5j7P9bQ3kPrhmUMyfkMzKmxcCcPUj69iwv7yHI0woanG38e2nN7HlUCX3LZ7DKRNtCvnB4M1urrPwNDqH40lEK1X15yKShaebazKwBfgvVW1yusU+BcwFyoHFqtrtUmrWzTV05FfUs+Sv6ymoaOCB6+cNyaSExjdqGlvYU1zD7qJa9hTXsKuompKaJi6aMZobTj6OscNjj9q/rU354aptPL+5gF9eMYMbTj7OR5EHDp+PgxgKliBCS3ldM19/YgOf5Ffymytncc1JnU+Bfqyq+hZ+9tIOblhw3JCM5TB9V1LdyF/ez+M/2wuPWj0xPiqcKaMTSYiO4IN9pYgI508fxZKFmSzISkZE+NXLO1m+JpfvnzuF755rPZZ6wx/GQRgzqJLjo/jnN07mlqc3c9fz2xkWG9njovPuNuW2FVtYs8fFe3tcvHTbaV/4C9T4Tn5FPY++l8u/Nh6i1d3GudNGcf3J4zl+VCLHj/ZMBNm+bsOh8nr+8fEB/rXhEK98WsTxoxKZlZHEs5vyWbLwOG5fNMnH3yb42B2ECTiNLW4WL/+I3UU1PHvzwm4bI//31V089G4Ot5w1kac+PMCEVJuPZ6i0tSkKnXYzzXXV8vC7ObywpQAR+Mq8DG4+cyKZqfE9fm5ji5vVWw/zxLr9fFZYzZdmjuH+6+Zad9Y+sComE9RKahq5/IEPcKuy+tbTGDUs5gv7vPxJId9+ejPXzR/Pr6+cyRufFfPNv2/kynnp/OFq/1miNZi0utv4MLeM1VsP8+qOImoaW4kMF2IiwomODCM6IpzoiDD2l9URGR7GdfPHs+yMrH7d1akqOa46MlPiiOjnlDKhyhKECXo7C6u56uF1ZKUlsPJbC4+aXmR3UQ1XPPQBU0cn8syyBURHeLb96c09/OnNvfz4kuncdNoEX4Xul1SVNz4rZtOBCuKjI0iIjiAxJoLEmEjnub3M8z46wrM4lKqy5VAlq7ce5t/bCymtbSIhOoLzTxjFccnxNLa6aWppO/Lc1OomMyWeG0/JJC0x2tdfOyRZG4QJetPGDOO+xXP55lMb+cHKrTx4/TzCwoSq+haWPbWR+OgIHv6vE48kB4Dbz5nMjsPV/PLlnUwdk2jdIfFUBb3+WRH3vbWPnYXVRIYLLe6e/3CMCBMSYiIIE6G8rpmoiDDOOX4kl80Zy9lTR1o1XhCwOwgT8P6yNpdf/Gcnt549ie+fN4WbntjAupxSVixb0On05DWNLVzx0DrKaptYfWvoTgHd1qa8uqOI+9/ay66iGrJS47n1nEl8efZYFKhtbKWmsZWaphbPc2MrtU0tnvKmVmobW6ltaqWh2c3JWSmcf8IohsVE+vprmV6wKiYTMlSVe57/hBUbDnHqpBQ+2FfGr66YyfUnj+/ymFxXLZc9+AHjRsTx3C2nhNzaE2/vKua3r+xmd3ENWWnx3H7OZC6dPdYaekNEbxOEteyYgCci/PyyGSzM8iSH6+aP6zY5AGSlJXD/4rnsLKrmxr+uD5m5nlrdbfz65Z3c9MRGWtvauG/xHN74/plcPjfdkoP5AruDMEGjqqGF1z4t4rK5Y49qd+jOi1sL+J8XPkWAn3z5BL4yL92nvZsOldfz4Dv7KK1tYulpWSycOHgTGpfWNnH7M1tYl1PGDSeP58eXTu/1dTLBxaqYjOmlQ+X13PHsNtbnlXPBCaP41RUzSUkY2t41hVUNPPD2Pv614RBhYcKwmEhKa5uYPyGZ7y2azMKJKQNKXFsOVvDtpzdTXtfMLy6fwdXZvRuFboKTJQhj+sDdpjz+fi6/f20Pw2Ij+O1XZrFomvfne3LVNPHQu/t4+uODqCqLTxrPd86exPC4SFasP8jD7+VQXN3ESZkj+O6iKZw6qW+JQlX55/qD/Gz1Z4wcFs0j/2WznBpLEMb0y66iar7/r23sLKzm5AnJjBwWQ1JsBMNiIhkWG8mwmEjGJ8f1+Rc1eOaEOlhez4HyOg6W15PrquM/2wtpdrfxlXnp3HbO5C/0qGpscbNy4yEeeieHoupGZo8bznnTRnLa5DRmpid12W5QUt3Ix3nlvPxJIa98WsSZU9K4b/EchsfZ+gjGEoQx/dbU6ubBt/fx7h4XNY2tVDe0UNXQQmvb5/9XFmal8LPLTmDKqMQuP0dVeWd3CY++l8uuohqqGlqO2p4SH8UZU9K4fdFkJvQwxURTq5uVGw7xzPpDfFZYDcCwmAgWTkzhtEmpzBk3gr0lNazPK+fjvHLySusAz2R33zwji9vOmWyN0OYISxDGDCJVpaHFTXVDK2/sLOb3r+2mrqmVr52SyR1jthG75pdQlQ9JGeiiH/N+7Nn84fU9bD1UybjkWM6cksb45DjGJ8d7nlPiSIju3zjVstom1uWU8f7eUt7fV3rU7KfDYiKYPyGZ+ROSOXlCCieMHWbTUJgvsARhjBeV1zXzv6/uomHzM/wm8nFiaTqyrZFoftS8lI2J53LboslcdWIGkV76Ja2qHCirZ1t+JZNGJjB19DC7UzA9sgRhzBBo/t10ouoKvlBeGzOGyB/usG6kxi/ZXEzGDIGousOdlic0FoElBxPgrHLSmIFIyuhbuTEBxBKEMQOx6McQecxaBpGxnnJjApzXEoSIjBORd0TkMxHZISLfdcp/KiIFIrLVeVzc4Zh7RGSfiOwWkQu8FZsxg2bWNXDp/ZA0DhDP86X3e8qNCXDebINoBe5Q1c0ikghsEpE3nG33qurvO+4sItOBxcAJwFjgTRGZoqpuL8ZozMDNusYSgglKXruDUNVCVd3svK4BdgLp3RxyGbBCVZtUNQ/YB8z3VnzGGGO6NyRtECKSCcwFPnaKbhWR7SLyVxEZ4ZSlA4c6HJZP9wnFGGOMF3k9QYhIAvAc8D1VrQYeBiYCc4BC4A99/LxlIrJRRDa6XK7BDtcYY4zDqwlCRCLxJIenVfV5AFUtVlW3qrYBj/F5NVIB0HEO4gyn7CiqulxVs1U1Oy0tzZvhG2NMSPNmLyYBHgd2quofO5SP6bDbFcCnzuvVwGIRiRaRCcBkYL234jPGGNM9r021ISKnAWuBT4A2p/i/gevwVC8psB/4lqoWOsf8D3ATnh5Q31PVV3o4hws44LxNAqqO2eXYso7vU4HSPn6tvugsnsE6pqf9utrem2vUWdlQXbf+XLO+HNfdfn25Zp2V9/Q+UK9bsP6sdRXPYB3jzes2GD9rx6lqz1UwqhoUD2B5T2Ud3wMbhzqewTqmp/262t6ba+TL69afazZY160v16yna9TF+4C8bsH6s9bf6+YP/0eH8mctmEZSv9SLss728Zb+nKu3x/S0X1fbe3ONOisbquvW3/MMxnXryzXrrDzQftZ6e1yw/qz191z+8H90yK5ZQM/mOhAislF7MZuhOZpdt/6x69Z3ds36ZzCvWzDdQfTVcl8HEKDsuvWPXbe+s2vWP4N23UL2DsIYY0z3QvkOwhhjTDcsQRhjjOmUJQhjjDGdsgTRCRE5XUQeEZG/iMg6X8cTKEQkTER+KSJ/FpEbfR1PIBCRs0RkrfPzdpav4wkkIhLvzMt2ia9jCRQiMs35WVslIrf0tH/QJQhnhtgSEfn0mPILnYWI9onI3d19hqquVdWbgX8DT3ozXn8xGNcNz5TtGUALntl4g9ogXTMFaoEYQuCawaBdN4C7gJXeidL/DNLvtp3O77ZrgFN7PGew9WISkTPw/If7u6rOcMrCgT3AeXj+E27AM+VHOPDrYz7iJlUtcY5bCSxVz3oWQW0wrpvzqFDVR0VklapeNVTx+8IgXbNSVW0TkVHAH1X1hqGK31cG6brNBlLwJNZSVf330ETvO4P1u01EvgzcAjylqv/s7pzeXFHOJ1R1jbP+REfzgX2qmgsgIiuAy1T110Cnt6ciMh6oCoXkAINz3UQkH2h23gb9SoCD9bPmqACivRKonxmkn7WzgHhgOtAgIi+rZ4booDVYP2+quhpYLSL/AUIrQXShs8WITu7hmKXA37wWUWDo63V7HviziJwOrPFmYH6sT9dMRK4ELgCGAw94NTL/1qfrpqr/AyAiX8O5C/NqdP6rrz9vZwFX4vlj5OWePjxUEkSfqepPfB1DoFHVejyJ1fSSetZJed7XcQQqVX3C1zEEElV9F3i3t/sHXSN1F3q1GJH5ArtufWfXrH/suvWPV69bqCSIDcBkEZkgIlHAYjwLFJnu2XXrO7tm/WPXrX+8et2CLkGIyDPAh8DxIpIvIktVtRW4FXgN2AmsVNUdvozT39h16zu7Zv1j161/fHHdgq6bqzHGmMERdHcQxhhjBoclCGOMMZ2yBGGMMaZTliCMMcZ0yhKEMcaYTlmCMMYY0ylLECboiEjtEJ9vUNYMcdaGqBKRrSKyS0R+34tjLheR6YNxfmOOZQnCmB6ISLdzlqnqKYN4urWqOgeYC1wiIj3N2X85nhlNjRl0liBMSBCRiSLyqohsclZwm+qUXyoiH4vIFhF501mXARH5qYg8JSIfAE857/8qIu+KSK6I3N7hs2ud57Oc7aucO4CnRUScbRc7ZZtE5H4R6Xb9AlVtALbima0TEfmmiGwQkW0i8pyIxInIKcCXgd85dx0Tu/qexvSHJQgTKpYDt6nqicAPgYec8veBBao6F1gB/KjDMdOBc1X1Ouf9VDxTc88HfiIikZ2cZy7wPefYLOBUEYkBHgUucs6f1lOwIjICmMzn06Y/r6onqepsPFMqLFXVdXjm3blTVeeoak4339OYPrPpvk3QE5EE4BTgWecPevh8cZ4M4F8iMgaIAvI6HLra+Uu+3X9UtQloEpESYBRfXCZ0varmO+fdCmTiWQUsV1XbP/sZYFkX4Z4uItvwJIc/qWqRUz5DRH6BZ92IBDxz7/TlexrTZ5YgTCgIAyqduv1j/RnPUp+rncVUftphW90x+zZ1eO2m8/8/vdmnO2tV9RIRmQB8JCIrVXUr8ARwuapucxbJOauTY7v7nsb0mVUxmaCnqtVAnohcDSAes53NSXw+f/6NXgphN5DVYbnIa3s6wLnb+A1wl1OUCBQ61Vod162ucbb19D2N6TNLECYYxTnTIbc/foDnl+pSp/pmB3CZs+9P8VTJbAJKvRGMU031beBV5zw1QFUvDn0EOMNJLP8P+Bj4ANjVYZ8VwJ1OI/tEuv6exvSZTfdtzBAQkQRVrXV6NT0I7FXVe30dlzHdsTsIY4bGN51G6x14qrUe9W04xvTM7iCMMcZ0yu4gjDHGdMoShDHGmE5ZgjDGGNMpSxDGGGM6ZQnCGGNMpyxBGGOM6dT/BzeWXwt5MwTKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# learn.lr_find() SuggestedLRs(valley=tensor(8.3176e-06))\n",
    "# SuggestedLRs(valley=tensor(1.2023e-05))\n",
    "# SuggestedLRs(valley=tensor(1.4454e-05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a6741ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nepochs 300\n"
     ]
    }
   ],
   "source": [
    "print(f\"nepochs {nepochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa4f647",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE learn.fit one cycle\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='122' class='' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      40.67% [122/300 1:25:23<2:04:35]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>201.828629</td>\n",
       "      <td>193.827011</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>181.950607</td>\n",
       "      <td>186.774170</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>165.299515</td>\n",
       "      <td>178.430573</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>153.802505</td>\n",
       "      <td>177.824448</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>164.742386</td>\n",
       "      <td>180.345886</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>163.094727</td>\n",
       "      <td>165.814667</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>154.069778</td>\n",
       "      <td>152.792999</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>143.254898</td>\n",
       "      <td>163.348709</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>145.322433</td>\n",
       "      <td>160.146210</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>136.471069</td>\n",
       "      <td>155.120651</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>127.118423</td>\n",
       "      <td>139.638748</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>139.267776</td>\n",
       "      <td>137.155365</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>141.804825</td>\n",
       "      <td>139.495712</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>122.041252</td>\n",
       "      <td>131.065689</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>120.171440</td>\n",
       "      <td>136.575317</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>124.694260</td>\n",
       "      <td>134.843307</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>126.102776</td>\n",
       "      <td>129.189484</td>\n",
       "      <td>00:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>115.196190</td>\n",
       "      <td>134.804001</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>114.065331</td>\n",
       "      <td>115.942451</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>110.886787</td>\n",
       "      <td>109.448921</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>104.729187</td>\n",
       "      <td>141.047211</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>102.215256</td>\n",
       "      <td>111.603004</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>100.865509</td>\n",
       "      <td>103.546005</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>102.119362</td>\n",
       "      <td>111.855347</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>94.914642</td>\n",
       "      <td>126.141617</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>97.006805</td>\n",
       "      <td>107.573669</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>88.991371</td>\n",
       "      <td>115.833511</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>85.701118</td>\n",
       "      <td>120.329201</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>87.455933</td>\n",
       "      <td>90.965240</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>76.935303</td>\n",
       "      <td>106.513016</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>65.765442</td>\n",
       "      <td>91.563805</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>68.496712</td>\n",
       "      <td>121.832153</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>65.929955</td>\n",
       "      <td>69.616264</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>66.460968</td>\n",
       "      <td>76.650322</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>61.449402</td>\n",
       "      <td>61.188034</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>57.806046</td>\n",
       "      <td>71.253777</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>49.161304</td>\n",
       "      <td>59.918827</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>59.212090</td>\n",
       "      <td>68.378242</td>\n",
       "      <td>00:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>45.133938</td>\n",
       "      <td>46.685394</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>46.003128</td>\n",
       "      <td>53.779877</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>46.449677</td>\n",
       "      <td>49.029816</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>44.368542</td>\n",
       "      <td>35.716209</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>41.053539</td>\n",
       "      <td>41.957024</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>29.435444</td>\n",
       "      <td>44.711975</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>37.171803</td>\n",
       "      <td>40.594139</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>36.058201</td>\n",
       "      <td>39.726246</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>33.565006</td>\n",
       "      <td>36.825623</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>32.679813</td>\n",
       "      <td>47.332386</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>29.601490</td>\n",
       "      <td>31.191561</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>33.096256</td>\n",
       "      <td>32.293949</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>28.422157</td>\n",
       "      <td>24.532091</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>24.364292</td>\n",
       "      <td>32.011536</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>24.713524</td>\n",
       "      <td>26.562145</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>21.637772</td>\n",
       "      <td>24.248404</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>21.870909</td>\n",
       "      <td>36.606125</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>23.810143</td>\n",
       "      <td>37.599998</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>19.559959</td>\n",
       "      <td>42.585190</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>21.886461</td>\n",
       "      <td>34.036209</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>17.027252</td>\n",
       "      <td>35.652378</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>21.849747</td>\n",
       "      <td>21.968754</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>18.063967</td>\n",
       "      <td>24.765892</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>16.063108</td>\n",
       "      <td>35.642818</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>13.524604</td>\n",
       "      <td>21.400072</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>16.377460</td>\n",
       "      <td>30.594204</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>14.874683</td>\n",
       "      <td>20.883240</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>27.807539</td>\n",
       "      <td>28.554152</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>15.871312</td>\n",
       "      <td>18.151623</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>14.153879</td>\n",
       "      <td>29.562092</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>12.010862</td>\n",
       "      <td>19.227213</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>10.041789</td>\n",
       "      <td>16.813152</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>12.285267</td>\n",
       "      <td>19.934601</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>15.529262</td>\n",
       "      <td>19.165134</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>10.539931</td>\n",
       "      <td>17.661652</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>9.774236</td>\n",
       "      <td>30.484434</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>9.697969</td>\n",
       "      <td>17.217073</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>8.977545</td>\n",
       "      <td>18.418201</td>\n",
       "      <td>00:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>8.215638</td>\n",
       "      <td>18.439804</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>10.854531</td>\n",
       "      <td>17.609104</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>8.509762</td>\n",
       "      <td>17.896856</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>8.071556</td>\n",
       "      <td>14.377829</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>11.107491</td>\n",
       "      <td>18.578022</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>7.800127</td>\n",
       "      <td>16.403393</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>6.447579</td>\n",
       "      <td>16.404560</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>8.432169</td>\n",
       "      <td>20.640423</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>8.010144</td>\n",
       "      <td>13.266126</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>7.694789</td>\n",
       "      <td>13.370885</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>5.800148</td>\n",
       "      <td>12.924994</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>5.638751</td>\n",
       "      <td>14.192830</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>6.487597</td>\n",
       "      <td>13.002650</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>6.907486</td>\n",
       "      <td>13.854276</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>5.073908</td>\n",
       "      <td>16.026735</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>5.014767</td>\n",
       "      <td>13.438663</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>6.953727</td>\n",
       "      <td>14.552423</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>5.416658</td>\n",
       "      <td>16.062908</td>\n",
       "      <td>00:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>4.696843</td>\n",
       "      <td>13.293660</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>4.821003</td>\n",
       "      <td>11.908367</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>4.009068</td>\n",
       "      <td>11.293293</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>4.154293</td>\n",
       "      <td>10.806485</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>4.756038</td>\n",
       "      <td>11.400497</td>\n",
       "      <td>00:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>5.896911</td>\n",
       "      <td>18.939394</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.183641</td>\n",
       "      <td>11.487593</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>5.205488</td>\n",
       "      <td>14.484060</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>5.233177</td>\n",
       "      <td>12.845784</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>5.002591</td>\n",
       "      <td>12.612316</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>3.936658</td>\n",
       "      <td>12.368490</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>3.909857</td>\n",
       "      <td>15.516194</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>3.391731</td>\n",
       "      <td>12.988441</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>4.142088</td>\n",
       "      <td>12.557788</td>\n",
       "      <td>00:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>3.372952</td>\n",
       "      <td>16.944868</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>3.838719</td>\n",
       "      <td>13.530653</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.966707</td>\n",
       "      <td>13.983452</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>4.862603</td>\n",
       "      <td>12.963160</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>3.858246</td>\n",
       "      <td>13.633423</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>3.486937</td>\n",
       "      <td>13.877130</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>3.040793</td>\n",
       "      <td>11.569653</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>3.144384</td>\n",
       "      <td>12.975057</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>2.979428</td>\n",
       "      <td>11.286256</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>3.697281</td>\n",
       "      <td>12.166432</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>3.168082</td>\n",
       "      <td>11.619642</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>3.637689</td>\n",
       "      <td>13.813413</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.949972</td>\n",
       "      <td>12.729337</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>3.499720</td>\n",
       "      <td>12.612769</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='21' class='' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      63.64% [21/33 00:07<00:04 3.1439]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 193.82701110839844.\n",
      "Better model found at epoch 1 with valid_loss value: 186.774169921875.\n",
      "Better model found at epoch 2 with valid_loss value: 178.43057250976562.\n",
      "Better model found at epoch 3 with valid_loss value: 177.82444763183594.\n",
      "Better model found at epoch 5 with valid_loss value: 165.81466674804688.\n",
      "Better model found at epoch 6 with valid_loss value: 152.79299926757812.\n",
      "Better model found at epoch 10 with valid_loss value: 139.6387481689453.\n",
      "Better model found at epoch 11 with valid_loss value: 137.15536499023438.\n",
      "Better model found at epoch 13 with valid_loss value: 131.06568908691406.\n",
      "Better model found at epoch 16 with valid_loss value: 129.18948364257812.\n",
      "Better model found at epoch 18 with valid_loss value: 115.94245147705078.\n",
      "Better model found at epoch 19 with valid_loss value: 109.44892120361328.\n",
      "Better model found at epoch 22 with valid_loss value: 103.54600524902344.\n",
      "Better model found at epoch 28 with valid_loss value: 90.96524047851562.\n",
      "Better model found at epoch 32 with valid_loss value: 69.61626434326172.\n",
      "Better model found at epoch 34 with valid_loss value: 61.18803405761719.\n",
      "Better model found at epoch 36 with valid_loss value: 59.918827056884766.\n",
      "Better model found at epoch 38 with valid_loss value: 46.685394287109375.\n",
      "Better model found at epoch 41 with valid_loss value: 35.716209411621094.\n",
      "Better model found at epoch 48 with valid_loss value: 31.191560745239258.\n",
      "Better model found at epoch 50 with valid_loss value: 24.53209114074707.\n",
      "Better model found at epoch 53 with valid_loss value: 24.248403549194336.\n",
      "Better model found at epoch 59 with valid_loss value: 21.968753814697266.\n",
      "Better model found at epoch 62 with valid_loss value: 21.40007209777832.\n",
      "Better model found at epoch 64 with valid_loss value: 20.88323974609375.\n",
      "Better model found at epoch 66 with valid_loss value: 18.151622772216797.\n",
      "Better model found at epoch 69 with valid_loss value: 16.813152313232422.\n",
      "Better model found at epoch 79 with valid_loss value: 14.377828598022461.\n",
      "Better model found at epoch 84 with valid_loss value: 13.266125679016113.\n",
      "Better model found at epoch 86 with valid_loss value: 12.924994468688965.\n",
      "Better model found at epoch 95 with valid_loss value: 11.908367156982422.\n",
      "Better model found at epoch 96 with valid_loss value: 11.293292999267578.\n",
      "Better model found at epoch 97 with valid_loss value: 10.806485176086426.\n"
     ]
    }
   ],
   "source": [
    "print(\"PRE learn.fit one cycle\")\n",
    "\n",
    "with learn.distrib_ctx():\n",
    "    learn.fit_one_cycle(nepochs, 1e-5, wd = 1e-4)\n",
    "    #learn.fit_one_cycle(nepochs, 3e-3, wd = 1e-4)\n",
    "    #learn.fit_one_cycle(nepochs, 6e-5, wd = 1e-4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dcb74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     if loss_type == \"perim_loss\":\n",
    "#         learn.loss_func = perim_loss\n",
    "#         print(\"switched loss at epoch \", nepochs//2)\n",
    "    \n",
    "#     learn.fit_one_cycle(nepochs//2, 3e-3, wd = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e51a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570ba8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot_loss(self, skip_start=5, with_valid=True):\n",
    "        plt.plot(list(range(skip_start, len(self.losses))), self.losses[skip_start:], label='train')\n",
    "        if with_valid:\n",
    "            idx = (np.array(self.iters)<skip_start).sum()\n",
    "            plt.plot(self.iters[idx:], L(self.values[idx:]).itemgot(1), label='valid')\n",
    "            plt.legend()\n",
    "        plt.savefig(f'{fig_src}/loss.png', bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc8b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_plot_loss(learn.recorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828ffcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "@delegates(subplots)\n",
    "def save_plot_metrics(self: Recorder, nrows=None, ncols=None, figsize=None, **kwargs):\n",
    "    metrics = np.stack(self.values)\n",
    "    names = self.metric_names[1:-1]\n",
    "    n = len(names) - 1\n",
    "    if nrows is None and ncols is None:\n",
    "        nrows = int(math.sqrt(n))\n",
    "        ncols = int(np.ceil(n / nrows))\n",
    "    elif nrows is None: nrows = int(np.ceil(n / ncols))\n",
    "    elif ncols is None: ncols = int(np.ceil(n / nrows))\n",
    "    figsize = figsize or (ncols * 6, nrows * 4)\n",
    "    fig, axs = subplots(nrows, ncols, figsize=figsize, **kwargs)\n",
    "    axs = [ax if i < n else ax.set_axis_off() for i, ax in enumerate(axs.flatten())][:n]\n",
    "    for i, (name, ax) in enumerate(zip(names, [axs[0]] + axs)):\n",
    "        ax.plot(metrics[:, i], color='#1f77b4' if i == 0 else '#ff7f0e', label='valid' if i > 0 else 'train')\n",
    "        ax.set_title(name if i > 1 else 'losses')\n",
    "        ax.legend(loc='best')\n",
    "    #plt.show()\n",
    "    plt.savefig(f'{fig_src}/metrics.png', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec814eaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_plot_metrics(learn.recorder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4c295b",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683aaf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_tfms = [\n",
    "#     # normalize mean/std of foreground pixels\n",
    "#     ZScale(),\n",
    "#     # affine + flips\n",
    "#     RandomAffine(p=0.5, degrees=35, translate=0.1, scale=0.1),\n",
    "#     RandDihedral(p=0.5),\n",
    "#     # lighting\n",
    "#     RandBright(p=0.5),\n",
    "#     RandContrast(p=0.5),\n",
    "#     # noise for generalizability\n",
    "#     GNoise(p=0.5),\n",
    "#     GBlur(p=0.5),\n",
    "#     # add channel dim\n",
    "#     AddChannel()\n",
    "\n",
    "# UMich \n",
    "# code src: \"/home/labcomputer/Desktop/Rachel\"\n",
    "# data src: \"../../../../..//media/labcomputer/e33f6fe0-5ede-4be4-b1f2-5168b7903c7a/home/rachel/\"\n",
    "\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d1c877",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87db8dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Test\")\n",
    "# xb, yb = dls.one_batch()\n",
    "# xb, yb = xb.cpu(), yb.cpu()\n",
    "\n",
    "# pb = model.cpu()(xb)\n",
    "# print(xb.shape, pb.shape)\n",
    "# print(f\"logcosh dice loss {log_cosh_dice_loss(pb,yb)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cb367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test:\n",
    "\n",
    "# #dls.device = \"cpu\"\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# x,y = dls.one_batch()\n",
    "# #x,y = to_cpu(x), to_cpu(y)\n",
    "\n",
    "# pred = learn.model(x)\n",
    "# loss = learn.loss_func(pred, y)\n",
    "\n",
    "# elapsed = time.time() - start\n",
    "\n",
    "# print(f\"Elapsed: {elapsed} s\")\n",
    "# print(\"Batch: x,y\")\n",
    "# print(type(x), x.shape, x.dtype, \"\\n\", type(y), y.shape, y.dtype)\n",
    "\n",
    "# print(\"Pred shape\")\n",
    "# print(type(pred), pred.shape, pred.dtype)\n",
    "\n",
    "# print(\"Loss\")\n",
    "# print(loss)\n",
    "# print(learn.loss_func)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
